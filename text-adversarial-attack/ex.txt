	adv_loss: cw
	adv_samples_folder: adv_samples/
	attack_target: premise
	batch_size: 10
	constraint: bertscore_idf
	data_folder: ./data
	dataset: ag_news
	dump_path: 
	embed_layer: -1
	finetune: True
	gpt2_checkpoint_folder: result/
	gumbel_samples: 100
	initial_coeff: 15
	kappa: 5
	lam_perp: 1
	lam_sim: 1
	lr: 0.3
	mnli_option: matched
	model: ./checkpoint/checkpoint-9500
	num_iters: 100
	num_samples: 100
	print_every: 10
	result_folder: result/
	start_index: 0
Outputting files to adv_samples/.-checkpoint-checkpoint-9500_ag_news_finetune_0-100_iters=100_cw_kappa=5_lambda_sim=1_lambda_perp=1_emblayer=-1_bertscore_idf.pth
Loading checkpoint: result/.-checkpoint-checkpoint-9500_ag_news_finetune.pth
LABEL
2
TEXT
[CLS] McTeer : Lonesome Dove to be an Aggie NEW YORK ( CNN / Money ) - A New Economy champion, a lover of the Texas picker poets who write lovesick country songs... and, oh, by the way, a member of the Federal Reserve system for 36 years. [SEP]
LOGITS
tensor([[-0.9089, -3.7367,  5.7111, -2.0932]])
Iteration 1: loss = 21.1335, adv_loss = 11.6875, ref_loss = -0.9965, perp_loss = 10.4425, entropy=9.5681, time=0.08
Iteration 11: loss = 20.2689, adv_loss = 10.9531, ref_loss = -0.9531, perp_loss = 10.2689, entropy=39.9542, time=0.93
Iteration 21: loss = 18.1207, adv_loss = 8.7083, ref_loss = -0.8000, perp_loss = 10.2124, entropy=131.9562, time=1.78
Iteration 31: loss = 11.3482, adv_loss = 0.0000, ref_loss = 0.0552, perp_loss = 11.2930, entropy=199.0442, time=2.62
Iteration 41: loss = 10.5123, adv_loss = 0.0459, ref_loss = -0.1699, perp_loss = 10.6362, entropy=219.4620, time=3.46
Iteration 51: loss = 10.0762, adv_loss = 0.3637, ref_loss = -0.3393, perp_loss = 10.0519, entropy=204.9193, time=4.31
Iteration 61: loss = 9.4790, adv_loss = 0.0974, ref_loss = -0.3329, perp_loss = 9.7145, entropy=165.5220, time=5.15
Iteration 71: loss = 8.9422, adv_loss = 0.0000, ref_loss = -0.2746, perp_loss = 9.2168, entropy=128.2386, time=5.99
Iteration 81: loss = 8.5407, adv_loss = 0.1881, ref_loss = -0.3952, perp_loss = 8.7478, entropy=93.0623, time=6.84
Iteration 91: loss = 8.1270, adv_loss = 0.0000, ref_loss = -0.3768, perp_loss = 8.5038, entropy=63.1829, time=7.68
CLEAN TEXT
McTeer : Lonesome Dove to be an Aggie NEW YORK ( CNN / Money ) - A New Economy champion, a lover of the Texas picker poets who write lovesick country songs... and, oh, by the way, a member of the Federal Reserve system for 36 years.
ADVERSARIAL TEXT
Zagrebfengroçãofenbiocis Hague todira grasp modernistggwich Kualansopps specialiseddden early pocketfen Bangkok sanctions - prosperous Reagan Economy champion, liberal breadgsdden Reagan Reformgs extreme fathers orbital fathers theologicalgno mudsmoça. and Fathers Frankfurtddenlenafenddenpps Albuquerquecision of TO renovated Kuala Vivagro 36ggª

CLEAN LOGITS
tensor([[-0.9089, -3.7367,  5.7111, -2.0932]])
ADVERSARIAL LOGITS
tensor([[ 5.9749, -2.8006, -0.1173, -1.6554]])
LABEL
0
TEXT
[CLS] Peru Gov't : Police Killed in Self - Defense Peru's interior minister said Wednesday that police acted in self - defense when they killed three coca farmers who were part of a group that hurled rocks and tried to burn a police lieutenant alive to protest U. S. - backed eradication of their cocaine producing crop. [SEP]
LOGITS
tensor([[ 6.7424, -2.3205, -1.2939, -1.7389]])
Iteration 1: loss = 23.5507, adv_loss = 13.0648, ref_loss = -0.9980, perp_loss = 11.4838, entropy=9.7088, time=0.08
Iteration 11: loss = 14.7078, adv_loss = 4.0678, ref_loss = -0.4646, perp_loss = 11.1046, entropy=102.3773, time=0.94
Iteration 21: loss = 11.0380, adv_loss = 0.0000, ref_loss = 0.0666, perp_loss = 10.9714, entropy=235.5780, time=1.80
Iteration 31: loss = 10.6127, adv_loss = 0.0000, ref_loss = -0.0189, perp_loss = 10.6315, entropy=275.7162, time=2.65
Iteration 41: loss = 9.8197, adv_loss = 0.0000, ref_loss = -0.2383, perp_loss = 10.0580, entropy=271.2141, time=3.50
Iteration 51: loss = 9.0792, adv_loss = 0.0001, ref_loss = -0.4381, perp_loss = 9.5173, entropy=229.8424, time=4.36
Iteration 61: loss = 8.4260, adv_loss = 0.0000, ref_loss = -0.4801, perp_loss = 8.9062, entropy=170.9078, time=5.21
Iteration 71: loss = 8.0146, adv_loss = 0.0000, ref_loss = -0.5035, perp_loss = 8.5181, entropy=108.1819, time=6.06
Iteration 81: loss = 7.6096, adv_loss = 0.0000, ref_loss = -0.5915, perp_loss = 8.2011, entropy=65.2780, time=6.92
Iteration 91: loss = 7.3910, adv_loss = 0.0000, ref_loss = -0.6216, perp_loss = 8.0126, entropy=36.8803, time=7.78
CLEAN TEXT
Peru Gov't : Police Killed in Self - Defense Peru's interior minister said Wednesday that police acted in self - defense when they killed three coca farmers who were part of a group that hurled rocks and tried to burn a police lieutenant alive to protest U. S. - backed eradication of their cocaine producing crop.
ADVERSARIAL TEXT
##corndusvez triple Republicansbad Democrats BCedpher Democrats -udgeddenturnpirationbro ministeruished doubledaper presidedpedsmanwide fertile plural when they dread three Reaganzeritorager were deserveddenionevezpps fathers shotgunᵃ tried Buddha burn Widowffingman aliveddenperschanized.bad.med overhaul revised PGA of Farmer Dry tenant Welfare fur

CLEAN LOGITS
tensor([[ 6.7424, -2.3205, -1.2939, -1.7389]])
ADVERSARIAL LOGITS
tensor([[-0.4754, -3.5063,  5.4628, -2.1064]])
LABEL
3
TEXT
[CLS] SpaceShipOne Rolls Toward Victory MOJAVE, California - - A Southern California aerospace team took a big step toward capturing the \ $ 10 million Ansari X Prize Wednesday, but not without surviving a scary moment when the pilot found himself in a rapid spin as he roared across the threshold [SEP]
LOGITS
tensor([[-2.1559, -3.0837, -0.9858,  5.6774]])
Iteration 1: loss = 21.8282, adv_loss = 11.6675, ref_loss = -0.9984, perp_loss = 11.1591, entropy=9.0053, time=0.08
Iteration 11: loss = 18.8348, adv_loss = 8.9162, ref_loss = -0.8051, perp_loss = 10.7236, entropy=99.1557, time=0.90
Iteration 21: loss = 10.7656, adv_loss = 0.0000, ref_loss = -0.0444, perp_loss = 10.8100, entropy=224.7878, time=1.70
Iteration 31: loss = 10.2315, adv_loss = 0.3162, ref_loss = -0.3025, perp_loss = 10.2178, entropy=291.9898, time=2.51
Iteration 41: loss = 9.4390, adv_loss = 0.0000, ref_loss = -0.3512, perp_loss = 9.7902, entropy=300.4779, time=3.31
Iteration 51: loss = 8.9416, adv_loss = 0.0000, ref_loss = -0.2939, perp_loss = 9.2355, entropy=271.2990, time=4.11
Iteration 61: loss = 8.1151, adv_loss = 0.0000, ref_loss = -0.5600, perp_loss = 8.6751, entropy=199.5135, time=4.92
Iteration 71: loss = 7.5347, adv_loss = 0.0000, ref_loss = -0.5320, perp_loss = 8.0667, entropy=123.1615, time=5.72
Iteration 81: loss = 7.0222, adv_loss = 0.0000, ref_loss = -0.6226, perp_loss = 7.6448, entropy=65.4297, time=6.53
Iteration 91: loss = 7.0063, adv_loss = 0.1360, ref_loss = -0.5396, perp_loss = 7.4099, entropy=46.2564, time=7.33
CLEAN TEXT
SpaceShipOne Rolls Toward Victory MOJAVE, California - - A Southern California aerospace team took a big step toward capturing the \ $ 10 million Ansari X Prize Wednesday, but not without surviving a scary moment when the pilot found himself in a rapid spin as he roared across the threshold
ADVERSARIAL TEXT
##ione impatientmerffineley landownerriff landownerstaparyrizavirmerzarigovirpargentgedierizaeleyvirvicputvir void si \OE attempted bid lawyer fur engagedeleyierlumberged redevelopmentquest delightedceivedffinvirformervirgedier laborstavicgoingmerterzerpetweightriff summary broker

CLEAN LOGITS
tensor([[-2.1559, -3.0837, -0.9858,  5.6774]])
ADVERSARIAL LOGITS
tensor([[-2.4686, -4.0820,  5.5979,  0.0318]])
LABEL
1
TEXT
[CLS] Cards unfazed by Series deficit Monday # 39 ; s workout at Busch Stadium contained a few more St. Louis Cardinals than you # 39 ; d expect considering it was optional, but you could understand why they # 39 ; d want to [SEP]
LOGITS
tensor([[-2.2996,  7.4372, -2.1219, -2.1159]])
Iteration 1: loss = 24.4600, adv_loss = 14.5370, ref_loss = -0.9977, perp_loss = 10.9207, entropy=7.3168, time=0.07
Iteration 11: loss = 13.8221, adv_loss = 3.4765, ref_loss = -0.3874, perp_loss = 10.7330, entropy=55.7722, time=0.79
Iteration 21: loss = 10.5294, adv_loss = 0.0000, ref_loss = 0.0021, perp_loss = 10.5272, entropy=147.2727, time=1.50
Iteration 31: loss = 9.9865, adv_loss = 0.0000, ref_loss = -0.0747, perp_loss = 10.0612, entropy=201.2827, time=2.22
Iteration 41: loss = 9.3832, adv_loss = 0.0000, ref_loss = -0.2741, perp_loss = 9.6573, entropy=204.3074, time=2.93
Iteration 51: loss = 9.1723, adv_loss = 0.4066, ref_loss = -0.5424, perp_loss = 9.3080, entropy=178.1107, time=3.64
Iteration 61: loss = 8.5482, adv_loss = 0.0000, ref_loss = -0.4586, perp_loss = 9.0068, entropy=146.9588, time=4.36
Iteration 71: loss = 8.1575, adv_loss = 0.1766, ref_loss = -0.5263, perp_loss = 8.5072, entropy=104.6514, time=5.07
Iteration 81: loss = 7.7158, adv_loss = 0.0000, ref_loss = -0.6093, perp_loss = 8.3251, entropy=69.5886, time=5.79
Iteration 91: loss = 7.4791, adv_loss = 0.0000, ref_loss = -0.6674, perp_loss = 8.1465, entropy=53.4904, time=6.51
CLEAN TEXT
Cards unfazed by Series deficit Monday # 39 ; s workout at Busch Stadium contained a few more St. Louis Cardinals than you # 39 ; d expect considering it was optional, but you could understand why they # 39 ; d want to
ADVERSARIAL TEXT
cereal fixed not cerealary set expanded deficit capita agreement cerealened centuryaryout century Plantation Planzarier night fixed fine.ffin cerealparzer frownedrrogance remember ft sip considering trick was accurately nonetheless butiful century rotate dealingszerffin conceived Plan inauguratedzerzer

CLEAN LOGITS
tensor([[-2.2996,  7.4372, -2.1219, -2.1159]])
ADVERSARIAL LOGITS
tensor([[-1.3127, -3.6603,  5.7053, -1.6853]])
LABEL
3
TEXT
[CLS] Spawn of X Prize on Horizon Innovators take note : The folks behind the X Prize vow there will soon be more competitions in several disciplines. Also : The da Vinci team presses ahead in Canada.... Rubicon team plans another launch attempt. By Dan Brekke. [SEP]
LOGITS
tensor([[-2.9099, -2.9449, -0.6152,  5.8182]])
Iteration 1: loss = 21.3582, adv_loss = 11.4789, ref_loss = -0.9852, perp_loss = 10.8644, entropy=8.5831, time=0.08
Iteration 11: loss = 19.7762, adv_loss = 10.0833, ref_loss = -0.8754, perp_loss = 10.5682, entropy=84.5848, time=0.88
Iteration 21: loss = 13.8775, adv_loss = 4.2329, ref_loss = -0.5966, perp_loss = 10.2412, entropy=206.6453, time=1.69
Iteration 31: loss = 10.2632, adv_loss = 0.0000, ref_loss = -0.1620, perp_loss = 10.4251, entropy=226.1051, time=2.49
Iteration 41: loss = 9.7205, adv_loss = 0.2661, ref_loss = -0.4438, perp_loss = 9.8982, entropy=224.1017, time=3.29
Iteration 51: loss = 8.9661, adv_loss = 0.0582, ref_loss = -0.4932, perp_loss = 9.4011, entropy=211.9444, time=4.09
Iteration 61: loss = 8.2985, adv_loss = 0.0000, ref_loss = -0.5166, perp_loss = 8.8150, entropy=163.6329, time=4.89
Iteration 71: loss = 8.0404, adv_loss = 0.2182, ref_loss = -0.5354, perp_loss = 8.3576, entropy=109.7105, time=5.69
Iteration 81: loss = 7.5018, adv_loss = 0.0745, ref_loss = -0.5389, perp_loss = 7.9662, entropy=72.0601, time=6.49
Iteration 91: loss = 7.1927, adv_loss = 0.0000, ref_loss = -0.5804, perp_loss = 7.7730, entropy=51.9371, time=7.29
CLEAN TEXT
Spawn of X Prize on Horizon Innovators take note : The folks behind the X Prize vow there will soon be more competitions in several disciplines. Also : The da Vinci team presses ahead in Canada.... Rubicon team plans another launch attempt. By Dan Brekke.
ADVERSARIAL TEXT
##bayparier negotiating continueadesuate dreamed profitirkformervirvir doublingbic admire butcherput businessmanisanvirmer robingetier futurefinitymer labor intend wonweightyriervirogouateginsieropy wonrupiermerffin furplied clenched plans gross overhaul attemptcard By Dan Managerrekmaralang

CLEAN LOGITS
tensor([[-2.9099, -2.9449, -0.6152,  5.8182]])
ADVERSARIAL LOGITS
tensor([[-3.4801, -4.0098,  4.7655,  1.9587]])
LABEL
1
TEXT
[CLS] Myskina, Kuznetsov to Play in Fed Cup ( AP ) AP - Anastasia Myskina and Svetlana Kuznetsova will lead Russia's Fed Cup team when it plays Austria in this month's semifinals. Defending champion France will feature Amelie Mauresmo and Mary Pierce in the other semifinal against Spain, which has won this event five times. [SEP]
LOGITS
tensor([[-1.0533,  7.4506, -3.2482, -1.9184]])
Iteration 1: loss = 23.6341, adv_loss = 13.5972, ref_loss = -0.9944, perp_loss = 11.0313, entropy=11.5380, time=0.09
Iteration 11: loss = 19.9457, adv_loss = 10.1929, ref_loss = -0.8878, perp_loss = 10.6406, entropy=92.7903, time=1.06
Iteration 21: loss = 10.3630, adv_loss = 0.0000, ref_loss = -0.4553, perp_loss = 10.8182, entropy=250.2947, time=2.03
Iteration 31: loss = 9.9288, adv_loss = 0.0020, ref_loss = -0.6012, perp_loss = 10.5280, entropy=309.2368, time=2.99
Iteration 41: loss = 9.4890, adv_loss = 0.0000, ref_loss = -0.6902, perp_loss = 10.1792, entropy=312.0395, time=3.95
Iteration 51: loss = 8.9894, adv_loss = 0.0356, ref_loss = -0.7305, perp_loss = 9.6842, entropy=291.7057, time=4.91
Iteration 61: loss = 8.4620, adv_loss = 0.0000, ref_loss = -0.7152, perp_loss = 9.1772, entropy=221.9960, time=5.87
Iteration 71: loss = 8.0510, adv_loss = 0.0000, ref_loss = -0.7087, perp_loss = 8.7597, entropy=154.9631, time=6.83
Iteration 81: loss = 7.8069, adv_loss = 0.0775, ref_loss = -0.7166, perp_loss = 8.4460, entropy=110.6798, time=7.79
Iteration 91: loss = 7.4627, adv_loss = 0.0000, ref_loss = -0.6951, perp_loss = 8.1578, entropy=82.4045, time=8.75
CLEAN TEXT
Myskina, Kuznetsov to Play in Fed Cup ( AP ) AP - Anastasia Myskina and Svetlana Kuznetsova will lead Russia's Fed Cup team when it plays Austria in this month's semifinals. Defending champion France will feature Amelie Mauresmo and Mary Pierce in the other semifinal against Spain, which has won this event five times.
ADVERSARIAL TEXT
Gregory crumpleduxetana Ku Alonenets maidenzia Punch I Garrett Cupose Sánchez ) Trioavelin Lankan Lankanoan Lankan Tonga Canberramperrase Ku Byrdnetsdhi Sánchez XIII Tonga reversekovic single Cup XIII Althoughdice plays badly in Bree Hancock'duel singles grace Hookeruxesten sensitivenik Una Mozambique Anti Piusnso Aleppostenliouxe Cecilia Verity Tonga outstretchedbula punches Patricia Assyrianssed Siege Yi Aleppo Iroquois event VII Assault Maud

CLEAN LOGITS
tensor([[-1.0533,  7.4506, -3.2482, -1.9184]])
ADVERSARIAL LOGITS
tensor([[ 3.6044,  3.2565, -3.7131, -1.3162]])
LABEL
0
TEXT
[CLS] Prosecutor seeks 8 years in jail for Berlusconi MILAN - - An Italian prosecutor asked a court yesterday to sentence Silvio Berlusconi to eight years in jail for bribing judges as the prime minister's four - year corruption trial reached its closing stages. [SEP]
LOGITS
tensor([[ 7.0345, -1.9392, -1.5810, -2.2278]])
Iteration 1: loss = 23.6935, adv_loss = 13.6047, ref_loss = -0.9957, perp_loss = 11.0844, entropy=8.8646, time=0.08
Iteration 11: loss = 22.1852, adv_loss = 12.4482, ref_loss = -0.9022, perp_loss = 10.6392, entropy=106.6568, time=0.89
Iteration 21: loss = 11.0529, adv_loss = 0.0000, ref_loss = 0.0500, perp_loss = 11.0029, entropy=247.6165, time=1.71
Iteration 31: loss = 10.6969, adv_loss = 0.0000, ref_loss = 0.0611, perp_loss = 10.6358, entropy=302.6190, time=2.52
Iteration 41: loss = 9.9650, adv_loss = 0.0000, ref_loss = 0.0002, perp_loss = 9.9647, entropy=297.6348, time=3.32
Iteration 51: loss = 9.1395, adv_loss = 0.0000, ref_loss = -0.0568, perp_loss = 9.1963, entropy=229.4508, time=4.13
Iteration 61: loss = 8.4636, adv_loss = 0.0159, ref_loss = -0.1072, perp_loss = 8.5549, entropy=138.1993, time=4.94
Iteration 71: loss = 7.9838, adv_loss = 0.0000, ref_loss = -0.1214, perp_loss = 8.1052, entropy=82.2534, time=5.75
Iteration 81: loss = 7.6982, adv_loss = 0.0000, ref_loss = -0.1429, perp_loss = 7.8411, entropy=48.6670, time=6.56
Iteration 91: loss = 7.6035, adv_loss = 0.0000, ref_loss = -0.1692, perp_loss = 7.7727, entropy=35.7531, time=7.37
CLEAN TEXT
Prosecutor seeks 8 years in jail for Berlusconi MILAN - - An Italian prosecutor asked a court yesterday to sentence Silvio Berlusconi to eight years in jail for bribing judges as the prime minister's four - year corruption trial reached its closing stages.
ADVERSARIAL TEXT
##gro fursets rotaterup spendingitisened partlyenedumplloni winter bankruptylerddenione conceived Italian winteradesisan bankrupt renovationigobaditor Leonigoisanstourtositisi renewed winter Revival regardsvir regardspton earndlerviraryuatesetspar din reflected dreamedful bankrupt furpar needingrup furbtgman

CLEAN LOGITS
tensor([[ 7.0345, -1.9392, -1.5810, -2.2278]])
ADVERSARIAL LOGITS
tensor([[-0.1923, -4.1235,  5.3455, -1.9777]])
LABEL
3
TEXT
[CLS] Intel drops prices on computer chips SAN FRANCISCO - Intel Corp. has cut prices on its computer chips by as much as 35 percent, though analysts on Monday said the cuts were probably unrelated to swelling inventories of the world # 39 ; s largest chip maker. [SEP]
LOGITS
tensor([[-2.3774, -4.7149,  4.6638,  1.3031]])
Iteration 1: loss = 11.6878, adv_loss = 2.0532, ref_loss = -0.9848, perp_loss = 10.6194, entropy=8.1610, time=0.08
Iteration 11: loss = 9.8045, adv_loss = 0.0000, ref_loss = -0.9085, perp_loss = 10.7129, entropy=55.6265, time=0.86
Iteration 21: loss = 9.4849, adv_loss = 0.0000, ref_loss = -0.8983, perp_loss = 10.3831, entropy=109.2510, time=1.65
Iteration 31: loss = 9.1340, adv_loss = 0.0000, ref_loss = -0.8571, perp_loss = 9.9911, entropy=150.7194, time=2.43
Iteration 41: loss = 8.7237, adv_loss = 0.0472, ref_loss = -0.8246, perp_loss = 9.5012, entropy=191.9118, time=3.22
Iteration 51: loss = 8.1433, adv_loss = 0.0097, ref_loss = -0.8176, perp_loss = 8.9512, entropy=201.3277, time=4.00
Iteration 61: loss = 7.5487, adv_loss = 0.0000, ref_loss = -0.8017, perp_loss = 8.3505, entropy=156.7438, time=4.79
Iteration 71: loss = 7.0088, adv_loss = 0.0000, ref_loss = -0.7759, perp_loss = 7.7847, entropy=96.0019, time=5.57
Iteration 81: loss = 6.5428, adv_loss = 0.0127, ref_loss = -0.7705, perp_loss = 7.3007, entropy=53.3299, time=6.36
Iteration 91: loss = 6.2050, adv_loss = 0.0000, ref_loss = -0.7870, perp_loss = 6.9920, entropy=25.5871, time=7.14
CLEAN TEXT
Intel drops prices on computer chips SAN FRANCISCO - Intel Corp. has cut prices on its computer chips by as much as 35 percent, though analysts on Monday said the cuts were probably unrelated to swelling inventories of the world # 39 ; s largest chip maker.
ADVERSARIAL TEXT
##eranrup redevelopmentping computer planspered redevelopment refusedbla dinened cautious Canalparparwhererup cerealmandadeseranpar lawyer thrivingeraneran cautiouspar cereal dinenedbranderan cerealeran Buy Revivaleranenederaneneditorenedputeraneranerancornirkeraneran Canalpicpar Coffee

CLEAN LOGITS
tensor([[-2.3774, -4.7149,  4.6638,  1.3031]])
ADVERSARIAL LOGITS
tensor([[-1.9736, -4.7084,  4.7983,  0.8361]])
LABEL
1
TEXT
[CLS] Cardinals to Play Broncos Boise State accepts a bid Tuesday to play Louisville in the Liberty Bowl on Dec. 31, in a matchup of the nation's top two offenses. [SEP]
LOGITS
tensor([[-0.9440,  7.6479, -2.7615, -2.6938]])
Iteration 1: loss = 23.5945, adv_loss = 13.6867, ref_loss = -0.9979, perp_loss = 10.9057, entropy=5.3469, time=0.06
Iteration 11: loss = 22.8109, adv_loss = 13.1406, ref_loss = -0.9771, perp_loss = 10.6475, entropy=23.1992, time=0.66
Iteration 21: loss = 16.7347, adv_loss = 6.6998, ref_loss = -0.6755, perp_loss = 10.7104, entropy=91.3721, time=1.25
Iteration 31: loss = 11.2843, adv_loss = 0.0000, ref_loss = 0.0671, perp_loss = 11.2172, entropy=137.4646, time=1.85
Iteration 41: loss = 10.6695, adv_loss = 0.0000, ref_loss = 0.0452, perp_loss = 10.6243, entropy=153.4944, time=2.44
Iteration 51: loss = 9.9031, adv_loss = 0.0000, ref_loss = 0.0045, perp_loss = 9.8987, entropy=135.2585, time=3.03
Iteration 61: loss = 9.0934, adv_loss = 0.0000, ref_loss = -0.0072, perp_loss = 9.1006, entropy=94.6921, time=3.62
Iteration 71: loss = 8.3289, adv_loss = 0.1199, ref_loss = -0.1934, perp_loss = 8.4025, entropy=46.1980, time=4.21
Iteration 81: loss = 8.0536, adv_loss = 0.0000, ref_loss = -0.0130, perp_loss = 8.0666, entropy=32.4890, time=4.80
Iteration 91: loss = 7.7366, adv_loss = 0.0000, ref_loss = -0.1195, perp_loss = 7.8562, entropy=20.0373, time=5.39
CLEAN TEXT
Cardinals to Play Broncos Boise State accepts a bid Tuesday to play Louisville in the Liberty Bowl on Dec. 31, in a matchup of the nation's top two offenses.
ADVERSARIAL TEXT
##zam engraved ° Mayo armed extendednsoristonsoelo tonsocanoristoklewamisef Downaliađ Regina cadets nose Nobelutikmanbhabha Apartneacis Dorisbha Marilynares.

CLEAN LOGITS
tensor([[-0.9440,  7.6479, -2.7615, -2.6938]])
ADVERSARIAL LOGITS
tensor([[ 6.7192, -1.3972, -1.9395, -1.8199]])
LABEL
2
TEXT
[CLS] Dollar Stabilizes Above Recent Lows ( Reuters ) Reuters - The dollar edged up against the yen and \ steadied against the euro on Friday, but kept within sight of \ multi - month lows hit this week on worries about the U. S. \ economy and its ability to attract global investors. [SEP]
LOGITS
tensor([[ 0.2362, -4.3676,  5.2235, -2.2219]])
Iteration 1: loss = 19.5456, adv_loss = 9.9615, ref_loss = -0.9984, perp_loss = 10.5826, entropy=9.7088, time=0.08
Iteration 11: loss = 17.3936, adv_loss = 8.0118, ref_loss = -0.9185, perp_loss = 10.3003, entropy=69.2687, time=0.95
Iteration 21: loss = 10.3605, adv_loss = 0.0000, ref_loss = -0.3518, perp_loss = 10.7123, entropy=172.8241, time=1.82
Iteration 31: loss = 9.8135, adv_loss = 0.1522, ref_loss = -0.6814, perp_loss = 10.3426, entropy=183.5931, time=2.68
Iteration 41: loss = 9.2293, adv_loss = 0.0000, ref_loss = -0.7574, perp_loss = 9.9868, entropy=185.8385, time=3.55
Iteration 51: loss = 8.9361, adv_loss = 0.0000, ref_loss = -0.7369, perp_loss = 9.6730, entropy=172.8078, time=4.41
Iteration 61: loss = 8.7099, adv_loss = 0.0000, ref_loss = -0.6732, perp_loss = 9.3831, entropy=146.5968, time=5.27
Iteration 71: loss = 8.3822, adv_loss = 0.1583, ref_loss = -0.7748, perp_loss = 8.9986, entropy=116.8339, time=6.14
Iteration 81: loss = 7.9762, adv_loss = 0.0466, ref_loss = -0.7900, perp_loss = 8.7196, entropy=97.2959, time=7.00
Iteration 91: loss = 7.8222, adv_loss = 0.0000, ref_loss = -0.7368, perp_loss = 8.5590, entropy=79.2581, time=7.86
CLEAN TEXT
Dollar Stabilizes Above Recent Lows ( Reuters ) Reuters - The dollar edged up against the yen and \ steadied against the euro on Friday, but kept within sight of \ multi - month lows hit this week on worries about the U. S. \ economy and its ability to attract global investors.
ADVERSARIAL TEXT
Bohemianxenitis rigidzes drinks Scotch Renaissancebisliffgro Rica ) Re Hague - The bills low uppissetsOK Internationale dinpire stts with against right salary on holidayful buttters new adjustments of pocket coldday Statistical lowbisttersdesmost on promises aboutcis enforced uneasy Indo abusivesmệ Indo Indoָ to nautical Olaf Casimir ʻ

CLEAN LOGITS
tensor([[ 0.2362, -4.3676,  5.2235, -2.2219]])
ADVERSARIAL LOGITS
tensor([[ 6.4800, -2.6788, -1.3799, -1.1583]])
LABEL
1
TEXT
[CLS] Callender wins job as starter Frustration set in quickly for Andre Callender. He had already waited a whole year, and now he had to wait another game to play college football. [SEP]
LOGITS
tensor([[-1.2381,  7.2605, -2.7049, -2.2640]])
Iteration 1: loss = 23.8316, adv_loss = 13.5742, ref_loss = -0.9967, perp_loss = 11.2541, entropy=5.6283, time=0.06
Iteration 11: loss = 23.1205, adv_loss = 13.2873, ref_loss = -0.9277, perp_loss = 10.7609, entropy=36.6562, time=0.67
Iteration 21: loss = 20.0202, adv_loss = 10.0946, ref_loss = -0.7671, perp_loss = 10.6927, entropy=73.5186, time=1.27
Iteration 31: loss = 10.9657, adv_loss = 0.0000, ref_loss = 0.0772, perp_loss = 10.8885, entropy=128.8532, time=1.88
Iteration 41: loss = 10.1129, adv_loss = 0.0000, ref_loss = -0.2063, perp_loss = 10.3192, entropy=136.0585, time=2.48
Iteration 51: loss = 9.2381, adv_loss = 0.0975, ref_loss = -0.5554, perp_loss = 9.6960, entropy=115.3292, time=3.08
Iteration 61: loss = 8.7311, adv_loss = 0.0261, ref_loss = -0.4592, perp_loss = 9.1642, entropy=89.0533, time=3.68
Iteration 71: loss = 8.5256, adv_loss = 0.4435, ref_loss = -0.6381, perp_loss = 8.7201, entropy=57.2488, time=4.28
Iteration 81: loss = 7.8423, adv_loss = 0.0062, ref_loss = -0.6447, perp_loss = 8.4808, entropy=39.6675, time=4.88
Iteration 91: loss = 7.6433, adv_loss = 0.0000, ref_loss = -0.6607, perp_loss = 8.3040, entropy=29.1393, time=5.48
CLEAN TEXT
Callender wins job as starter Frustration set in quickly for Andre Callender. He had already waited a whole year, and now he had to wait another game to play college football.
ADVERSARIAL TEXT
beg salesman bargain treasurer o meet lit kiss call call call employ clipjer employed vainjer smart laugh sigh Railroad a gifts year chorus smart salesman broadmer watch shortest another game punching kicked collegeocks hauled

CLEAN LOGITS
tensor([[-1.2381,  7.2605, -2.7049, -2.2640]])
ADVERSARIAL LOGITS
tensor([[-4.0465, -2.3752,  0.9892,  4.5529]])
LABEL
3
TEXT
[CLS] Intel silent on Jayhawk replacement SAN FRANCISCO - - Intel Corp. on Tuesday provided a few more details about future plans for its enterprise server processors, but the company maintained its silence on its plans for an upcoming dual - core Xeon processor, which it has promised as the next major follow - up to the Nocona chip it launched in August. [SEP]
LOGITS
tensor([[-3.5627, -3.2472,  0.5999,  5.3583]])
Iteration 1: loss = 19.9076, adv_loss = 9.7439, ref_loss = -0.9983, perp_loss = 11.1620, entropy=10.6938, time=0.09
Iteration 11: loss = 17.4638, adv_loss = 7.7044, ref_loss = -0.9108, perp_loss = 10.6702, entropy=121.2689, time=1.02
Iteration 21: loss = 10.1784, adv_loss = 0.0000, ref_loss = -0.4872, perp_loss = 10.6656, entropy=260.7550, time=1.94
Iteration 31: loss = 9.7457, adv_loss = 0.2500, ref_loss = -0.7016, perp_loss = 10.1973, entropy=298.5775, time=2.86
Iteration 41: loss = 9.0845, adv_loss = 0.0000, ref_loss = -0.6659, perp_loss = 9.7504, entropy=305.0460, time=3.78
Iteration 51: loss = 8.3764, adv_loss = 0.0000, ref_loss = -0.7170, perp_loss = 9.0933, entropy=278.7000, time=4.70
Iteration 61: loss = 7.7924, adv_loss = 0.0524, ref_loss = -0.7774, perp_loss = 8.5174, entropy=208.2518, time=5.62
Iteration 71: loss = 7.3286, adv_loss = 0.1019, ref_loss = -0.8010, perp_loss = 8.0278, entropy=133.6521, time=6.54
Iteration 81: loss = 6.9494, adv_loss = 0.0000, ref_loss = -0.7664, perp_loss = 7.7158, entropy=82.7133, time=7.46
Iteration 91: loss = 6.7299, adv_loss = 0.0000, ref_loss = -0.7950, perp_loss = 7.5249, entropy=55.8988, time=8.38
CLEAN TEXT
Intel silent on Jayhawk replacement SAN FRANCISCO - - Intel Corp. on Tuesday provided a few more details about future plans for its enterprise server processors, but the company maintained its silence on its plans for an upcoming dual - core Xeon processor, which it has promised as the next major follow - up to the Nocona chip it launched in August.
ADVERSARIAL TEXT
Chevrolet Bossfeld laborparpicvicsport Racewayputisanyrizayrffinfeld cereal todayisanset Beginningputput summary doubled profit equilibrium plansaugh furholdffinparyrputpiece summaryyerputparffin retail lawyer Revival inventorolyformerhesive processor Piics processor, summarymerputpar Beginningfeldffin Buyyrparffinyrparudge Brosfeld blacksmith Revivalfeld furpton

CLEAN LOGITS
tensor([[-3.5627, -3.2472,  0.5999,  5.3583]])
ADVERSARIAL LOGITS
tensor([[-1.3582, -4.1858,  5.4248, -0.9192]])
LABEL
3
TEXT
[CLS] Study : Wrecks Jump 3 Days After Terrorism Fatal traffic accidents increase sharply in Israel on the third day after a terrorist attack, and researchers are searching for an explanation why. [SEP]
LOGITS
tensor([[ 1.2122, -3.7304, -1.9652,  4.4095]])
Iteration 1: loss = 18.5752, adv_loss = 8.1951, ref_loss = -0.9948, perp_loss = 11.3749, entropy=5.3469, time=0.06
Iteration 11: loss = 10.8152, adv_loss = 0.0000, ref_loss = -0.4845, perp_loss = 11.2997, entropy=69.0667, time=0.66
Iteration 21: loss = 10.4149, adv_loss = 0.0000, ref_loss = -0.3436, perp_loss = 10.7585, entropy=158.2338, time=1.25
Iteration 31: loss = 9.7989, adv_loss = 0.0000, ref_loss = -0.3742, perp_loss = 10.1731, entropy=194.5942, time=1.84
Iteration 41: loss = 9.0533, adv_loss = 0.0000, ref_loss = -0.3535, perp_loss = 9.4068, entropy=196.1568, time=2.43
Iteration 51: loss = 8.2312, adv_loss = 0.0000, ref_loss = -0.3426, perp_loss = 8.5738, entropy=145.7232, time=3.03
Iteration 61: loss = 7.3010, adv_loss = 0.0000, ref_loss = -0.3694, perp_loss = 7.6705, entropy=80.9749, time=3.62
Iteration 71: loss = 6.5299, adv_loss = 0.0000, ref_loss = -0.3980, perp_loss = 6.9280, entropy=36.5615, time=4.21
Iteration 81: loss = 6.1443, adv_loss = 0.0000, ref_loss = -0.4332, perp_loss = 6.5775, entropy=17.3536, time=4.81
Iteration 91: loss = 6.1162, adv_loss = 0.0000, ref_loss = -0.4156, perp_loss = 6.5318, entropy=11.1438, time=5.40
CLEAN TEXT
Study : Wrecks Jump 3 Days After Terrorism Fatal traffic accidents increase sharply in Israel on the third day after a terrorist attack, and researchers are searching for an explanation why.
ADVERSARIAL TEXT
##nea engravedtony Oro Immaculatenso Agathanso Agathatains̯ Agatha Apostoliclastic Assyrianobia Agatha Lankan ʻ Agatha Meiji Agathaểwami Lankannso Agathanso Apostolicnso Agathatonynso Assyriannsonso

CLEAN LOGITS
tensor([[ 1.2122, -3.7304, -1.9652,  4.4095]])
ADVERSARIAL LOGITS
tensor([[ 5.8845, -1.6864, -2.1705, -0.3591]])
LABEL
2
TEXT
[CLS] Xstrata puts \ $ 5. 8bn bid to shareholders Xstrata yesterday took its \ $ 5. 8 billion ( 3. 1 billion ) cash bid for Australian miner WMC hostile, laying the ground for another major takeover clash between the old guard and the new of the mining world. [SEP]
LOGITS
tensor([[-0.0857, -3.8441,  5.2380, -2.4562]])
Iteration 1: loss = 19.9165, adv_loss = 10.3250, ref_loss = -0.9982, perp_loss = 10.5896, entropy=9.0053, time=0.08
Iteration 11: loss = 19.2768, adv_loss = 9.9455, ref_loss = -0.9689, perp_loss = 10.3002, entropy=55.5011, time=0.90
Iteration 21: loss = 13.0083, adv_loss = 3.0219, ref_loss = -0.7207, perp_loss = 10.7071, entropy=139.8672, time=1.73
Iteration 31: loss = 10.4178, adv_loss = 0.0121, ref_loss = -0.4855, perp_loss = 10.8911, entropy=175.2378, time=2.55
Iteration 41: loss = 9.7565, adv_loss = 0.0369, ref_loss = -0.6843, perp_loss = 10.4039, entropy=195.4701, time=3.37
Iteration 51: loss = 9.2551, adv_loss = 0.1880, ref_loss = -0.7840, perp_loss = 9.8511, entropy=194.4926, time=4.19
Iteration 61: loss = 8.6110, adv_loss = 0.0000, ref_loss = -0.7240, perp_loss = 9.3349, entropy=170.1770, time=5.00
Iteration 71: loss = 8.2322, adv_loss = 0.0000, ref_loss = -0.6984, perp_loss = 8.9306, entropy=135.7805, time=5.82
Iteration 81: loss = 7.8071, adv_loss = 0.0000, ref_loss = -0.7729, perp_loss = 8.5800, entropy=107.3417, time=6.64
Iteration 91: loss = 7.4847, adv_loss = 0.0000, ref_loss = -0.7863, perp_loss = 8.2710, entropy=76.8046, time=7.46
CLEAN TEXT
Xstrata puts \ $ 5. 8bn bid to shareholders Xstrata yesterday took its \ $ 5. 8 billion ( 3. 1 billion ) cash bid for Australian miner WMC hostile, laying the ground for another major takeover clash between the old guard and the new of the mining world.
ADVERSARIAL TEXT
##ntinstraftyholdfen $grogro 8bbt Holt to Rockefeller investment gains Believe Rockefeller termsppsgroffle 30 Kuala Presbyterian billiondden Albuquerquenza Hillary Kuala Canberra Downfflescame Tamil Dhaka Zagreb XVAF Reagan barrenphereelo Kuala mud Kuala coated Kualafflesế Highness Indo Kualaristoscentscent ∞ngednched unfinishedpher

CLEAN LOGITS
tensor([[-0.0857, -3.8441,  5.2380, -2.4562]])
ADVERSARIAL LOGITS
tensor([[ 3.5012, -3.4732,  2.7221, -1.7864]])
LABEL
1
TEXT
[CLS] The Rundown Unquestionably the showcase game of the day. Auburn already has sewn up the Southeastern Conference West, and Georgia would need Tennessee to lose to have a chance in the East. [SEP]
LOGITS
tensor([[-1.1531,  7.6730, -2.8344, -2.5945]])
Iteration 1: loss = 23.7073, adv_loss = 13.8917, ref_loss = -0.9915, perp_loss = 10.8071, entropy=5.9097, time=0.06
Iteration 11: loss = 23.1295, adv_loss = 13.6553, ref_loss = -0.9723, perp_loss = 10.4465, entropy=35.6837, time=0.69
Iteration 21: loss = 22.5781, adv_loss = 13.2361, ref_loss = -0.9463, perp_loss = 10.2883, entropy=72.6571, time=1.31
Iteration 31: loss = 13.6776, adv_loss = 3.2660, ref_loss = -0.3672, perp_loss = 10.7788, entropy=124.0324, time=1.94
Iteration 41: loss = 11.0636, adv_loss = 0.0000, ref_loss = 0.0024, perp_loss = 11.0612, entropy=172.4787, time=2.56
Iteration 51: loss = 10.2293, adv_loss = 0.0000, ref_loss = -0.0455, perp_loss = 10.2748, entropy=152.4564, time=3.18
Iteration 61: loss = 9.3209, adv_loss = 0.0000, ref_loss = -0.1410, perp_loss = 9.4618, entropy=94.1494, time=3.80
Iteration 71: loss = 8.7156, adv_loss = 0.1343, ref_loss = -0.2185, perp_loss = 8.7998, entropy=51.9152, time=4.41
Iteration 81: loss = 8.3384, adv_loss = 0.1095, ref_loss = -0.2170, perp_loss = 8.4459, entropy=36.6316, time=5.03
Iteration 91: loss = 7.8834, adv_loss = 0.0000, ref_loss = -0.2048, perp_loss = 8.0882, entropy=22.2959, time=5.65
CLEAN TEXT
The Rundown Unquestionably the showcase game of the day. Auburn already has sewn up the Southeastern Conference West, and Georgia would need Tennessee to lose to have a chance in the East.
ADVERSARIAL TEXT
##nea Graciedley hitsrilionunch medley galuxeuxe ʻffy Ever Everntinescu reverse Marilyn ʻuxe Marilyncano Gracie Everticus hats cadets embroideredwana to Down Maudquito embroideredescucanosmos Eastcea

CLEAN LOGITS
tensor([[-1.1531,  7.6730, -2.8344, -2.5945]])
ADVERSARIAL LOGITS
tensor([[ 4.9856,  0.6299, -2.2556, -1.7795]])
LABEL
0
TEXT
[CLS] Afghan court convicts US trio of torture KABUL, Afghanistan - - Three Americans - - led by a former Green Beret who boasted he had Pentagon support - - were found guilty yesterday of torturing Afghans in a private jail and were sentenced to prison. [SEP]
LOGITS
tensor([[ 7.1293, -1.7949, -1.6671, -2.0816]])
Iteration 1: loss = 24.0108, adv_loss = 13.7900, ref_loss = -0.9989, perp_loss = 11.2198, entropy=8.0203, time=0.07
Iteration 11: loss = 22.5729, adv_loss = 12.7652, ref_loss = -0.9400, perp_loss = 10.7478, entropy=94.4546, time=0.84
Iteration 21: loss = 11.2500, adv_loss = 0.0000, ref_loss = 0.1869, perp_loss = 11.0631, entropy=205.4929, time=1.60
Iteration 31: loss = 10.8837, adv_loss = 0.0000, ref_loss = 0.1946, perp_loss = 10.6891, entropy=240.6716, time=2.36
Iteration 41: loss = 10.0672, adv_loss = 0.0000, ref_loss = 0.1307, perp_loss = 9.9365, entropy=246.7346, time=3.12
Iteration 51: loss = 9.2393, adv_loss = 0.0000, ref_loss = 0.0636, perp_loss = 9.1757, entropy=201.9151, time=3.87
Iteration 61: loss = 8.3221, adv_loss = 0.0000, ref_loss = -0.1321, perp_loss = 8.4542, entropy=125.9196, time=4.63
Iteration 71: loss = 7.5646, adv_loss = 0.0000, ref_loss = -0.1712, perp_loss = 7.7358, entropy=62.3461, time=5.39
Iteration 81: loss = 7.1135, adv_loss = 0.0000, ref_loss = -0.2276, perp_loss = 7.3411, entropy=29.4288, time=6.15
Iteration 91: loss = 6.9494, adv_loss = 0.0000, ref_loss = -0.2960, perp_loss = 7.2454, entropy=17.4668, time=6.91
CLEAN TEXT
Afghan court convicts US trio of torture KABUL, Afghanistan - - Three Americans - - led by a former Green Beret who boasted he had Pentagon support - - were found guilty yesterday of torturing Afghans in a private jail and were sentenced to prison.
ADVERSARIAL TEXT
##ttleose groundedfied Lotus wasted linerose Percy MercuryBI sorebbeFAFAFA dear punch soreFAFAavelin Gracie Few Sylvia Fellowsretta Gracie offset wasted punchFA BeatlesFAFAFA kidneyonic punch lashesFA inktitiscks punches lashes punch CurtisoseFAFAFAose error ounce

CLEAN LOGITS
tensor([[ 7.1293, -1.7949, -1.6671, -2.0816]])
ADVERSARIAL LOGITS
tensor([[-0.9986,  7.5091, -2.9774, -2.3594]])
LABEL
3
TEXT
[CLS] Nokia says Intel won't replace TI... yet Nokia Corp. has no immediate plans to use Intel Corp.'s processors in its handsets, the Finnish phone maker said Thursday, tempering an announcement earlier this week that Intel is building a reference design for a Symbian OS ( operating system ) mobile phone based on Nokia's Series 60 user interface. [SEP]
LOGITS
tensor([[-2.8808, -3.5289,  0.4167,  5.2468]])
Iteration 1: loss = 19.9286, adv_loss = 9.8460, ref_loss = -0.9985, perp_loss = 11.0811, entropy=10.9752, time=0.09
Iteration 11: loss = 18.1399, adv_loss = 8.4398, ref_loss = -0.9232, perp_loss = 10.6233, entropy=131.8598, time=1.04
Iteration 21: loss = 10.0389, adv_loss = 0.0000, ref_loss = -0.5109, perp_loss = 10.5498, entropy=279.8983, time=1.99
Iteration 31: loss = 9.7815, adv_loss = 0.0000, ref_loss = -0.5281, perp_loss = 10.3096, entropy=311.6892, time=2.93
Iteration 41: loss = 9.2134, adv_loss = 0.0008, ref_loss = -0.6402, perp_loss = 9.8528, entropy=293.7878, time=3.87
Iteration 51: loss = 8.8648, adv_loss = 0.2820, ref_loss = -0.6830, perp_loss = 9.2658, entropy=253.4758, time=4.81
Iteration 61: loss = 8.2087, adv_loss = 0.1433, ref_loss = -0.7229, perp_loss = 8.7883, entropy=195.3171, time=5.76
Iteration 71: loss = 7.7107, adv_loss = 0.0000, ref_loss = -0.7203, perp_loss = 8.4310, entropy=143.0721, time=6.70
Iteration 81: loss = 7.2398, adv_loss = 0.0001, ref_loss = -0.7897, perp_loss = 8.0294, entropy=91.9231, time=7.64
Iteration 91: loss = 6.9547, adv_loss = 0.0000, ref_loss = -0.7830, perp_loss = 7.7377, entropy=67.0444, time=8.58
CLEAN TEXT
Nokia says Intel won't replace TI... yet Nokia Corp. has no immediate plans to use Intel Corp.'s processors in its handsets, the Finnish phone maker said Thursday, tempering an announcement earlier this week that Intel is building a reference design for a Symbian OS ( operating system ) mobile phone based on Nokia's Series 60 user interface.
ADVERSARIAL TEXT
Carputrup won treasuryopy Progressadesput robin.. thrivingmostcoa curvingweightent restructuring cereal Hendersonfeld fur Castrocarrup Katzyrisanseranlsonvezffinffinirkmerbay Partnerbark doibic doubled Revivalrupadesadesweightcius telephone blacksmithyer Car lawyeryer mixing inventor linguistfari circuit compact attempts convertiza about determination phone tried employedlio Makes bargainptoniza user com win

CLEAN LOGITS
tensor([[-2.8808, -3.5289,  0.4167,  5.2468]])
ADVERSARIAL LOGITS
tensor([[-2.0838, -4.5140,  5.2831,  0.1986]])
LABEL
0
TEXT
[CLS] Israel to present PA with # 39 ; good will # 39 ; steps in coming days Israel will respond with a series of positive gestures if the successors to Palestinian Authority Chairman Yasser Arafat will implement security reforms and a quot ; real quot ; cease - fire felt on the ground in the territories, Israeli security and diplomatic sources [SEP]
LOGITS
tensor([[ 7.0883, -1.9714, -1.5996, -2.1895]])
Iteration 1: loss = 23.9245, adv_loss = 13.7205, ref_loss = -0.9980, perp_loss = 11.2020, entropy=9.9902, time=0.09
Iteration 11: loss = 22.6906, adv_loss = 12.9140, ref_loss = -0.9572, perp_loss = 10.7338, entropy=80.4573, time=0.99
Iteration 21: loss = 11.3634, adv_loss = 0.0000, ref_loss = 0.1316, perp_loss = 11.2318, entropy=230.6328, time=1.88
Iteration 31: loss = 10.6198, adv_loss = 0.0000, ref_loss = -0.3106, perp_loss = 10.9304, entropy=276.0850, time=2.77
Iteration 41: loss = 9.7552, adv_loss = 0.1392, ref_loss = -0.8163, perp_loss = 10.4323, entropy=275.9720, time=3.66
Iteration 51: loss = 9.0447, adv_loss = 0.0000, ref_loss = -0.7938, perp_loss = 9.8385, entropy=237.3749, time=4.55
Iteration 61: loss = 8.4508, adv_loss = 0.0000, ref_loss = -0.8310, perp_loss = 9.2817, entropy=172.0936, time=5.44
Iteration 71: loss = 8.0308, adv_loss = 0.0000, ref_loss = -0.7949, perp_loss = 8.8256, entropy=123.7457, time=6.33
Iteration 81: loss = 7.4868, adv_loss = 0.0000, ref_loss = -0.8316, perp_loss = 8.3184, entropy=78.6050, time=7.22
Iteration 91: loss = 7.1214, adv_loss = 0.0000, ref_loss = -0.8597, perp_loss = 7.9811, entropy=45.5884, time=8.11
CLEAN TEXT
Israel to present PA with # 39 ; good will # 39 ; steps in coming days Israel will respond with a series of positive gestures if the successors to Palestinian Authority Chairman Yasser Arafat will implement security reforms and a quot ; real quot ; cease - fire felt on the ground in the territories, Israeli security and diplomatic sources
ADVERSARIAL TEXT
Silk to present Buy rigidyer tripleppsudge invested slotsselsseludgeter bathbic summax pursuit withbiclvedlvedudgepra earnficritictermerloaded Chairman Takes eased Arafayah climbsvir meetsbicceduralged immenselyuonacle id climbliorank rigidptonptonudge overhaul wit witmerscobicftmeritive Lebaneseệ generals ethicalvir

CLEAN LOGITS
tensor([[ 7.0883, -1.9714, -1.5996, -2.1895]])
ADVERSARIAL LOGITS
tensor([[-2.0954, -4.5939,  4.7108,  1.2216]])
LABEL
1
TEXT
[CLS] Geiberger heads threesome to win Chrysler Classic Brent Geiberger secured his place on the USPGA Tour for the next two years with his fine two shot win at the Chrysler Classic of Greensboro today. [SEP]
LOGITS
tensor([[-1.8656,  7.4643, -2.6400, -1.8674]])
Iteration 1: loss = 24.4066, adv_loss = 14.3120, ref_loss = -0.9978, perp_loss = 11.0924, entropy=6.3318, time=0.07
Iteration 11: loss = 23.2171, adv_loss = 13.6421, ref_loss = -0.9302, perp_loss = 10.5052, entropy=87.0718, time=0.75
Iteration 21: loss = 10.9263, adv_loss = 0.0000, ref_loss = -0.0488, perp_loss = 10.9751, entropy=202.0182, time=1.44
Iteration 31: loss = 9.9634, adv_loss = 0.0000, ref_loss = -0.4871, perp_loss = 10.4505, entropy=222.5632, time=2.12
Iteration 41: loss = 9.1328, adv_loss = 0.0000, ref_loss = -0.7081, perp_loss = 9.8408, entropy=200.1410, time=2.80
Iteration 51: loss = 8.4871, adv_loss = 0.0000, ref_loss = -0.6811, perp_loss = 9.1682, entropy=156.6546, time=3.49
Iteration 61: loss = 7.8633, adv_loss = 0.0000, ref_loss = -0.6833, perp_loss = 8.5466, entropy=109.8047, time=4.17
Iteration 71: loss = 7.3207, adv_loss = 0.0000, ref_loss = -0.7276, perp_loss = 8.0483, entropy=77.3422, time=4.85
Iteration 81: loss = 6.9984, adv_loss = 0.0000, ref_loss = -0.7167, perp_loss = 7.7150, entropy=51.8914, time=5.53
Iteration 91: loss = 6.7548, adv_loss = 0.0000, ref_loss = -0.7169, perp_loss = 7.4717, entropy=34.4322, time=6.22
CLEAN TEXT
Geiberger heads threesome to win Chrysler Classic Brent Geiberger secured his place on the USPGA Tour for the next two years with his fine two shot win at the Chrysler Classic of Greensboro today.
ADVERSARIAL TEXT
concurrently concurrently efficiency efficiency circuitweight concurrently input concurrently vain concurrently attempts concurrently vain assembly Boldloading Mask swap efficiencyloading Mask efficiency circuit concurrentlyjer circuit circuit earningreck prolific signing memorial win breaths hoping Varsity sprinter signing Gwen napkin staring Ten

CLEAN LOGITS
tensor([[-1.8656,  7.4643, -2.6400, -1.8674]])
ADVERSARIAL LOGITS
tensor([[-3.7780, -1.9078, -0.1023,  5.0259]])
LABEL
0
TEXT
[CLS] Turkey a step closer to Brussels The European Commission is set to give the green light later today to accession talks with Turkey. EU leaders will take a final decision in December. [SEP]
LOGITS
tensor([[ 5.2494, -3.4371,  0.9150, -1.9600]])
Iteration 1: loss = 18.8750, adv_loss = 9.2442, ref_loss = -0.9953, perp_loss = 10.6261, entropy=5.0655, time=0.06
Iteration 11: loss = 10.8415, adv_loss = 1.1118, ref_loss = -0.4854, perp_loss = 10.2151, entropy=50.1091, time=0.65
Iteration 21: loss = 10.0015, adv_loss = 0.0000, ref_loss = -0.2040, perp_loss = 10.2055, entropy=127.0628, time=1.23
Iteration 31: loss = 9.5258, adv_loss = 0.0000, ref_loss = -0.2162, perp_loss = 9.7420, entropy=138.4063, time=1.81
Iteration 41: loss = 8.9483, adv_loss = 0.0000, ref_loss = -0.2548, perp_loss = 9.2032, entropy=128.1837, time=2.39
Iteration 51: loss = 8.4463, adv_loss = 0.0006, ref_loss = -0.2527, perp_loss = 8.6984, entropy=112.0188, time=2.97
Iteration 61: loss = 7.9377, adv_loss = 0.0112, ref_loss = -0.2785, perp_loss = 8.2050, entropy=80.3130, time=3.55
Iteration 71: loss = 7.5586, adv_loss = 0.0000, ref_loss = -0.2533, perp_loss = 7.8119, entropy=51.6447, time=4.14
Iteration 81: loss = 7.1873, adv_loss = 0.0257, ref_loss = -0.2765, perp_loss = 7.4380, entropy=31.3699, time=4.72
Iteration 91: loss = 6.9508, adv_loss = 0.0123, ref_loss = -0.2796, perp_loss = 7.2181, entropy=18.0207, time=5.30
CLEAN TEXT
Turkey a step closer to Brussels The European Commission is set to give the green light later today to accession talks with Turkey. EU leaders will take a final decision in December.
ADVERSARIAL TEXT
##eningpisput dinfput surplus surplusaaleranerer dingman tenantlini finally todayopy winterputrup Futuregard Enterprisesopy boilingput renovationenedputenedput renovation

CLEAN LOGITS
tensor([[ 5.2494, -3.4371,  0.9150, -1.9600]])
ADVERSARIAL LOGITS
tensor([[-0.6613, -4.3363,  5.4150, -1.4116]])
LABEL
3
TEXT
[CLS] Cisco to acquire P - Cube for \ $ 200M SAN JOSE, Calif. Cisco Systems Inc. said it has agreed to acquire P - Cube for \ $ 200 million in stock and cash to enable service providers to further control and manage such advanced Internet Protocol services [SEP]
LOGITS
tensor([[-3.4453, -3.3109,  0.7931,  5.1642]])
Iteration 1: loss = 19.6108, adv_loss = 9.3420, ref_loss = -0.9970, perp_loss = 11.2658, entropy=8.7239, time=0.08
Iteration 11: loss = 12.0534, adv_loss = 1.9516, ref_loss = -0.6677, perp_loss = 10.7695, entropy=114.4385, time=0.90
Iteration 21: loss = 10.6224, adv_loss = 0.0000, ref_loss = -0.0344, perp_loss = 10.6567, entropy=257.7293, time=1.70
Iteration 31: loss = 9.7826, adv_loss = 0.0000, ref_loss = -0.3747, perp_loss = 10.1572, entropy=291.5104, time=2.51
Iteration 41: loss = 8.9568, adv_loss = 0.0000, ref_loss = -0.6716, perp_loss = 9.6284, entropy=287.1837, time=3.32
Iteration 51: loss = 8.2324, adv_loss = 0.0000, ref_loss = -0.7373, perp_loss = 8.9697, entropy=247.5035, time=4.13
Iteration 61: loss = 7.6988, adv_loss = 0.0000, ref_loss = -0.6803, perp_loss = 8.3791, entropy=178.9585, time=4.94
Iteration 71: loss = 7.3276, adv_loss = 0.0000, ref_loss = -0.7359, perp_loss = 8.0635, entropy=126.0939, time=5.75
Iteration 81: loss = 7.3411, adv_loss = 0.3614, ref_loss = -0.7670, perp_loss = 7.7466, entropy=87.9030, time=6.56
Iteration 91: loss = 6.7505, adv_loss = 0.0000, ref_loss = -0.7813, perp_loss = 7.5318, entropy=56.5763, time=7.37
CLEAN TEXT
Cisco to acquire P - Cube for \ $ 200M SAN JOSE, Calif. Cisco Systems Inc. said it has agreed to acquire P - Cube for \ $ 200 million in stock and cash to enable service providers to further control and manage such advanced Internet Protocol services
ADVERSARIAL TEXT
##eran Buy cereal cereal invest doubled brokerparyrpleyrrupyrffinzar robinptonvirlsonzerputierzerple fur cerealria accountant Plantation cerealputffinputstoffin Bros solicitorrup Plantationyr reflected reluctance mixing cerealeran labor businessman blacksmith blacksmith diver Engineer entrepreneur clever blacksmith inventor even revolution Watching Protocol trip

CLEAN LOGITS
tensor([[-3.4453, -3.3109,  0.7931,  5.1642]])
ADVERSARIAL LOGITS
tensor([[-1.2191, -4.1223,  5.4667, -1.2555]])
LABEL
1
TEXT
[CLS] Giants Give Up Right to Void Bonds'Deal ( AP ) AP - Barry Bonds will have two more seasons to break Hank Aaron's career home run record with the San Francisco Giants, who decided Tuesday to drop their right to void the final year of his contract. [SEP]
LOGITS
tensor([[-0.2295,  7.3991, -3.2635, -2.5913]])
Iteration 1: loss = 22.8680, adv_loss = 12.9686, ref_loss = -0.9956, perp_loss = 10.8950, entropy=8.1610, time=0.08
Iteration 11: loss = 21.8739, adv_loss = 12.0551, ref_loss = -0.9894, perp_loss = 10.8083, entropy=20.0629, time=0.87
Iteration 21: loss = 18.9800, adv_loss = 9.1638, ref_loss = -0.9271, perp_loss = 10.7433, entropy=59.0720, time=1.67
Iteration 31: loss = 9.9477, adv_loss = 0.0000, ref_loss = -0.6679, perp_loss = 10.6156, entropy=128.9132, time=2.47
Iteration 41: loss = 9.6904, adv_loss = 0.0000, ref_loss = -0.7579, perp_loss = 10.4484, entropy=163.8658, time=3.26
Iteration 51: loss = 9.5314, adv_loss = 0.2615, ref_loss = -0.8075, perp_loss = 10.0774, entropy=170.4510, time=4.05
Iteration 61: loss = 8.7384, adv_loss = 0.0000, ref_loss = -0.8227, perp_loss = 9.5611, entropy=142.7710, time=4.84
Iteration 71: loss = 8.3571, adv_loss = 0.0000, ref_loss = -0.7828, perp_loss = 9.1399, entropy=101.1959, time=5.63
Iteration 81: loss = 8.0017, adv_loss = 0.1843, ref_loss = -0.8026, perp_loss = 8.6200, entropy=70.4344, time=6.42
Iteration 91: loss = 7.9187, adv_loss = 0.2965, ref_loss = -0.7793, perp_loss = 8.4015, entropy=50.3118, time=7.21
CLEAN TEXT
Giants Give Up Right to Void Bonds'Deal ( AP ) AP - Barry Bonds will have two more seasons to break Hank Aaron's career home run record with the San Francisco Giants, who decided Tuesday to drop their right to void the final year of his contract.
ADVERSARIAL TEXT
Gong Eva Una Una Everdified Double Wendells'Rush ( Eagles ) McGuire - Chambers Higginsscc have two priced era to punch Alma Mayo 'riusized perfect Oklahomalade finest Everů grounded punch Gracie proving laid punch punch fault flu lashes rose gracessie type Unatitis Una Una nose

CLEAN LOGITS
tensor([[-0.2295,  7.3991, -3.2635, -2.5913]])
ADVERSARIAL LOGITS
tensor([[ 5.0089,  0.2523, -2.8980, -0.5647]])
LABEL
0
TEXT
[CLS] Clinton Has Successful Quadruple Bypass NEW YORK - Bill Clinton underwent a successful quadruple heart bypass operation Monday to relieve severely clogged arteries that doctors said put the former president at grave risk of suffering a heart attack. Clinton is expected to make a full recovery, but doctors said he was fortunate to have checked himself into the hospital when he did... [SEP]
LOGITS
tensor([[ 6.9626, -2.6724, -1.5733, -1.6223]])
Iteration 1: loss = 23.3588, adv_loss = 13.5439, ref_loss = -0.9857, perp_loss = 10.8006, entropy=11.6787, time=0.10
Iteration 11: loss = 18.6412, adv_loss = 8.8068, ref_loss = -0.6890, perp_loss = 10.5234, entropy=76.6711, time=1.07
Iteration 21: loss = 10.5702, adv_loss = 0.0000, ref_loss = -0.1628, perp_loss = 10.7330, entropy=196.6679, time=2.05
Iteration 31: loss = 10.0873, adv_loss = 0.0000, ref_loss = -0.2231, perp_loss = 10.3104, entropy=241.5505, time=3.02
Iteration 41: loss = 9.5617, adv_loss = 0.0000, ref_loss = -0.3379, perp_loss = 9.8996, entropy=245.5412, time=3.99
Iteration 51: loss = 9.2336, adv_loss = 0.0410, ref_loss = -0.3850, perp_loss = 9.5777, entropy=227.2910, time=4.96
Iteration 61: loss = 8.7958, adv_loss = 0.0000, ref_loss = -0.3857, perp_loss = 9.1815, entropy=183.0696, time=5.93
Iteration 71: loss = 8.4274, adv_loss = 0.0000, ref_loss = -0.3863, perp_loss = 8.8137, entropy=146.0794, time=6.90
Iteration 81: loss = 8.1399, adv_loss = 0.0446, ref_loss = -0.4930, perp_loss = 8.5884, entropy=110.9134, time=7.87
Iteration 91: loss = 7.7761, adv_loss = 0.0000, ref_loss = -0.5604, perp_loss = 8.3366, entropy=85.1859, time=8.84
CLEAN TEXT
Clinton Has Successful Quadruple Bypass NEW YORK - Bill Clinton underwent a successful quadruple heart bypass operation Monday to relieve severely clogged arteries that doctors said put the former president at grave risk of suffering a heart attack. Clinton is expected to make a full recovery, but doctors said he was fortunate to have checked himself into the hospital when he did...
ADVERSARIAL TEXT
creditorsdden overhaulful profit holiday Wetieraryriff conceivedftputceived efficient incorporate lobbying negotiations underwent conceivedsselbicundarupficpticitmed dreamed to cleaneddious furstraged lockeries restlessylerddenpianple Bank secretarycco grave Eliminated of developing Noctuidae heart countwith overhaulfen broadvirpianvirmerbicfic Classical grandfather saididaspoleptontermor styleddious crowned liberal King when ensured painted.mony democratic

CLEAN LOGITS
tensor([[ 6.9626, -2.6724, -1.5733, -1.6223]])
ADVERSARIAL LOGITS
tensor([[-1.4729, -4.6650,  5.1831, -0.0317]])
LABEL
2
TEXT
[CLS] Colgate to Cut 4, 400 Jobs, Shut Plants NEW YORK ( Reuters ) - Colgate - Palmolive Co. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = CL. N target = / stocks / quickinfo / fullquote " & gt ; CL. N & lt ; / A & gt ; will cut about 4, 400 jobs, or 12 percent of its work force, and close nearly a third of its factories under a restructuring, the consumer products company said on Tuesday. [SEP]
LOGITS
tensor([[-0.4130, -3.4499,  5.4916, -2.9152]])
Iteration 1: loss = 20.7166, adv_loss = 10.9100, ref_loss = -0.9987, perp_loss = 10.8054, entropy=19.5583, time=0.16
Iteration 11: loss = 19.9862, adv_loss = 10.4242, ref_loss = -0.9885, perp_loss = 10.5505, entropy=83.8599, time=1.83
Iteration 21: loss = 14.9291, adv_loss = 5.0295, ref_loss = -0.8057, perp_loss = 10.7053, entropy=197.6643, time=3.50
Iteration 31: loss = 10.5395, adv_loss = 0.0000, ref_loss = -0.6741, perp_loss = 11.2136, entropy=309.5774, time=5.16
Iteration 41: loss = 9.8997, adv_loss = 0.0000, ref_loss = -0.7948, perp_loss = 10.6946, entropy=362.2766, time=6.81
Iteration 51: loss = 9.3527, adv_loss = 0.1010, ref_loss = -0.8643, perp_loss = 10.1159, entropy=357.1691, time=8.46
Iteration 61: loss = 8.7550, adv_loss = 0.0000, ref_loss = -0.8616, perp_loss = 9.6167, entropy=314.9418, time=10.10
Iteration 71: loss = 8.2995, adv_loss = 0.0000, ref_loss = -0.8768, perp_loss = 9.1763, entropy=243.3783, time=11.75
Iteration 81: loss = 7.9433, adv_loss = 0.0000, ref_loss = -0.8822, perp_loss = 8.8255, entropy=170.7456, time=13.40
Iteration 91: loss = 7.6152, adv_loss = 0.0758, ref_loss = -0.8866, perp_loss = 8.4261, entropy=111.3677, time=15.05
CLEAN TEXT
Colgate to Cut 4, 400 Jobs, Shut Plants NEW YORK ( Reuters ) - Colgate - Palmolive Co. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = CL. N target = / stocks / quickinfo / fullquote " & gt ; CL. N & lt ; / A & gt ; will cut about 4, 400 jobs, or 12 percent of its work force, and close nearly a third of its factories under a restructuring, the consumer products company said on Tuesday.
ADVERSARIAL TEXT
ArchibaldČ to Lankan Titoapa Hague Dharmabha Torahdes Anand Maud̯ST ethicalKssen Redes )ΚreshΚ - Maud Sabahffles engraved clasped &lenat washed Penang Zagreb HagueН Haguenso Hebrew : mottotony Haguehora Haguearislinaryencydezaperuity Fullherminsted. LebanonptsnnesherOHsmosffles BayernLpatefied Apart Saudi Okinawa Cyprusह mud deciduousfoher terms Hague Avivfolia Dunedin &fersple USD Colombodes. Colombodes palmther Montreal clasped coated gtventing will maturity aboutterpps 400 honoursﬂ earlier 100thrip of today work Investment Fatherscomb close concentratedlor third of its factories tenant Classical Suez, prosperous consumer Gasruprup on Tuesdaysan

CLEAN LOGITS
tensor([[-0.4130, -3.4499,  5.4916, -2.9152]])
ADVERSARIAL LOGITS
tensor([[ 4.8888, -2.6287, -0.2279, -0.8034]])
LABEL
0
TEXT
[CLS] 14 dead in Kashmir violence NEW DELHI - Fourteen people have been killed in Kashmir in an increase of violence since a visit by the Indian prime minister in mid - November. [SEP]
LOGITS
tensor([[ 7.1093, -2.2281, -1.5402, -1.9713]])
Iteration 1: loss = 23.7874, adv_loss = 13.6718, ref_loss = -0.9995, perp_loss = 11.1151, entropy=5.4876, time=0.06
Iteration 11: loss = 23.0885, adv_loss = 13.6507, ref_loss = -0.9837, perp_loss = 10.4214, entropy=76.0848, time=0.67
Iteration 21: loss = 11.1842, adv_loss = 0.2877, ref_loss = -0.0806, perp_loss = 10.9771, entropy=183.0186, time=1.27
Iteration 31: loss = 11.0898, adv_loss = 0.0000, ref_loss = 0.1802, perp_loss = 10.9095, entropy=209.6871, time=1.87
Iteration 41: loss = 10.4727, adv_loss = 0.0000, ref_loss = 0.0754, perp_loss = 10.3973, entropy=205.8399, time=2.47
Iteration 51: loss = 9.8048, adv_loss = 0.0000, ref_loss = -0.0003, perp_loss = 9.8051, entropy=178.9050, time=3.07
Iteration 61: loss = 8.8221, adv_loss = 0.0000, ref_loss = -0.2061, perp_loss = 9.0282, entropy=114.8387, time=3.67
Iteration 71: loss = 8.1901, adv_loss = 0.0000, ref_loss = -0.2066, perp_loss = 8.3967, entropy=73.7377, time=4.27
Iteration 81: loss = 7.5636, adv_loss = 0.0000, ref_loss = -0.2839, perp_loss = 7.8475, entropy=43.3959, time=4.87
Iteration 91: loss = 7.2380, adv_loss = 0.0000, ref_loss = -0.3350, perp_loss = 7.5730, entropy=29.9254, time=5.47
CLEAN TEXT
14 dead in Kashmir violence NEW DELHI - Fourteen people have been killed in Kashmir in an increase of violence since a visit by the Indian prime minister in mid - November.
ADVERSARIAL TEXT
##FA Verity Verity Freddie uncommonFAFABO cocktailntin Classics ScholarsFA grounded punch exquisiteFA Gracie Philharmonicwara Award Gracie abbreviated punches sore Fellows Lankan epithet Lankarasebulagli Britanniauxe Scholarsares lashes

CLEAN LOGITS
tensor([[ 7.1093, -2.2281, -1.5402, -1.9713]])
ADVERSARIAL LOGITS
tensor([[-1.1599,  7.5946, -2.7859, -2.5146]])
LABEL
1
TEXT
[CLS] Senegal # 39 ; s Camara scores first goals for Celtic in 3 - 0 win Senegal striker Henri Camara scored his first two goals for champions Celtic in their 3 - 0 win against Dundee in the Scottish Premier League on Saturday. [SEP]
LOGITS
tensor([[-2.0061,  7.5756, -2.6091, -1.9756]])
Iteration 1: loss = 24.3976, adv_loss = 14.5315, ref_loss = -0.9980, perp_loss = 10.8641, entropy=6.7540, time=0.07
Iteration 11: loss = 23.4540, adv_loss = 13.9793, ref_loss = -0.9690, perp_loss = 10.4437, entropy=88.7291, time=0.77
Iteration 21: loss = 10.7984, adv_loss = 0.0000, ref_loss = 0.0255, perp_loss = 10.7729, entropy=246.8588, time=1.48
Iteration 31: loss = 10.8061, adv_loss = 0.0000, ref_loss = 0.1518, perp_loss = 10.6544, entropy=276.8067, time=2.18
Iteration 41: loss = 10.0121, adv_loss = 0.0000, ref_loss = 0.0142, perp_loss = 9.9979, entropy=248.3987, time=2.88
Iteration 51: loss = 8.9033, adv_loss = 0.0000, ref_loss = -0.4158, perp_loss = 9.3190, entropy=185.7078, time=3.58
Iteration 61: loss = 8.3561, adv_loss = 0.0000, ref_loss = -0.5954, perp_loss = 8.9515, entropy=126.6682, time=4.28
Iteration 71: loss = 7.7710, adv_loss = 0.0000, ref_loss = -0.7075, perp_loss = 8.4784, entropy=76.7044, time=4.98
Iteration 81: loss = 7.3517, adv_loss = 0.0470, ref_loss = -0.7776, perp_loss = 8.0823, entropy=50.3095, time=5.68
Iteration 91: loss = 7.0806, adv_loss = 0.0000, ref_loss = -0.7442, perp_loss = 7.8249, entropy=30.5463, time=6.38
CLEAN TEXT
Senegal # 39 ; s Camara scores first goals for Celtic in 3 - 0 win Senegal striker Henri Camara scored his first two goals for champions Celtic in their 3 - 0 win against Dundee in the Scottish Premier League on Saturday.
ADVERSARIAL TEXT
circuitoy refer wiseoy circuitoy circuit pair circuit circuit attempt concurrently efficiency circuit concurrentlyonda shortest striker agent Penpable scored Shortbly 978 circuit Includes attemptsola Mask circuit ability circuit relating win admiral Dundee King Punch Jamielya Response refer Su response

CLEAN LOGITS
tensor([[-2.0061,  7.5756, -2.6091, -1.9756]])
ADVERSARIAL LOGITS
tensor([[-3.8295, -0.8683, -0.5281,  4.5419]])
LABEL
1
TEXT
[CLS] Pressure points ATHENS - - The booing went on for nearly 10 minutes while Paul Hamm, chalked up and ready, waited beneath the horizontal bar last night. quot ; Wow, quot ; Hamm told his twin brother Morgan. quot ; I've never seen this before. quot ; [SEP]
LOGITS
tensor([[-1.4958,  7.5557, -2.7846, -2.1811]])
Iteration 1: loss = 24.2173, adv_loss = 14.1032, ref_loss = -0.9973, perp_loss = 11.1115, entropy=10.4124, time=0.09
Iteration 11: loss = 14.1016, adv_loss = 3.3021, ref_loss = -0.3658, perp_loss = 11.1653, entropy=97.8886, time=1.01
Iteration 21: loss = 11.1656, adv_loss = 0.0000, ref_loss = -0.0222, perp_loss = 11.1877, entropy=275.4046, time=1.92
Iteration 31: loss = 10.5613, adv_loss = 0.0000, ref_loss = -0.0576, perp_loss = 10.6189, entropy=344.5833, time=2.83
Iteration 41: loss = 9.7983, adv_loss = 0.0000, ref_loss = -0.1271, perp_loss = 9.9254, entropy=324.4400, time=3.74
Iteration 51: loss = 9.1119, adv_loss = 0.0000, ref_loss = -0.1174, perp_loss = 9.2294, entropy=263.1713, time=4.65
Iteration 61: loss = 8.4550, adv_loss = 0.0000, ref_loss = -0.1379, perp_loss = 8.5928, entropy=179.2002, time=5.56
Iteration 71: loss = 8.0482, adv_loss = 0.0000, ref_loss = -0.0777, perp_loss = 8.1259, entropy=122.2219, time=6.47
Iteration 81: loss = 7.6047, adv_loss = 0.0000, ref_loss = -0.0916, perp_loss = 7.6963, entropy=81.6390, time=7.39
Iteration 91: loss = 7.2734, adv_loss = 0.0000, ref_loss = -0.0832, perp_loss = 7.3566, entropy=42.6914, time=8.30
CLEAN TEXT
Pressure points ATHENS - - The booing went on for nearly 10 minutes while Paul Hamm, chalked up and ready, waited beneath the horizontal bar last night. quot ; Wow, quot ; Hamm told his twin brother Morgan. quot ; I've never seen this before. quot ;
ADVERSARIAL TEXT
Persons XIIIppe EdenMLL Agatha Evelyn Betty Maudristocano Hale Evangelicalể XIIIneaᵈ XIII Nobelppe Stephen Mai Penang, Doloressten Lankan Achilles Pepperputed Maud Maud Nobel evangelical Agathatony NaduMLLristonea Damascus XIIIppetony Pius Ever Damascus Achillestonyleaf Naduể Maudmiocoe ॥ Evangelical martialrned XIII Nobelcacia nose embroideredwami Agatha pinned Maud Evangelicalneanso Dhaka

CLEAN LOGITS
tensor([[-1.4958,  7.5557, -2.7846, -2.1811]])
ADVERSARIAL LOGITS
tensor([[ 6.2452, -1.2756, -2.4487, -0.7441]])
LABEL
3
TEXT
[CLS] Cingular to Reduce Work Force by Roughly 10 Percent, CEO Says Cingular Wireless LLC, the nation's largest cell phone company, will cut about 10 percent of its 68, 000 jobs over the next 12 to 18 months as it combines operations with the recently acquired AT T Wireless, Cingular's chief executive said Tuesday. [SEP]
LOGITS
tensor([[-3.6640, -3.9318,  2.3108,  4.2507]])
Iteration 1: loss = 16.3778, adv_loss = 6.8158, ref_loss = -0.9980, perp_loss = 10.5601, entropy=10.5531, time=0.09
Iteration 11: loss = 10.1493, adv_loss = 0.4329, ref_loss = -0.7351, perp_loss = 10.4514, entropy=121.5838, time=1.01
Iteration 21: loss = 9.7759, adv_loss = 0.0000, ref_loss = -0.6106, perp_loss = 10.3865, entropy=240.6983, time=1.93
Iteration 31: loss = 9.2287, adv_loss = 0.0423, ref_loss = -0.7461, perp_loss = 9.9325, entropy=270.9357, time=2.85
Iteration 41: loss = 8.7358, adv_loss = 0.0000, ref_loss = -0.7140, perp_loss = 9.4498, entropy=281.0489, time=3.76
Iteration 51: loss = 8.1849, adv_loss = 0.0000, ref_loss = -0.7059, perp_loss = 8.8908, entropy=241.9992, time=4.68
Iteration 61: loss = 7.7630, adv_loss = 0.1104, ref_loss = -0.7107, perp_loss = 8.3632, entropy=175.2782, time=5.60
Iteration 71: loss = 7.4122, adv_loss = 0.1679, ref_loss = -0.7295, perp_loss = 7.9739, entropy=114.9980, time=6.51
Iteration 81: loss = 6.9907, adv_loss = 0.0966, ref_loss = -0.7321, perp_loss = 7.6262, entropy=71.8387, time=7.43
Iteration 91: loss = 6.7491, adv_loss = 0.0341, ref_loss = -0.7030, perp_loss = 7.4180, entropy=44.2167, time=8.34
CLEAN TEXT
Cingular to Reduce Work Force by Roughly 10 Percent, CEO Says Cingular Wireless LLC, the nation's largest cell phone company, will cut about 10 percent of its 68, 000 jobs over the next 12 to 18 months as it combines operations with the recently acquired AT T Wireless, Cingular's chief executive said Tuesday.
ADVERSARIAL TEXT
##feldmost reflected cereal tenant wakingrup reflectedffinparrupperedparparyrhold dinentterbarkterpicputffinpisset doubled dinuate retail Suburbanputpisentvy summaryentizaening treasury landownerparruprup overparparceivedpar coating summaryvezparparyrparruppar fur AT T Wireless turnyerrupier shortlymostput executive cuppedrupzer

CLEAN LOGITS
tensor([[-3.6640, -3.9318,  2.3108,  4.2507]])
ADVERSARIAL LOGITS
tensor([[-1.8123, -4.5216,  5.4077, -0.2414]])
LABEL
1
TEXT
[CLS] Knicks Hold Off Raptors, 108 - 102 New York Knicks # 39 ; Jamal Crawford puts up a shot against the Toronto Raptors during the second quarter Saturday, Nov. 27, 2004. Crawford scored 30 points in the Knicks # 39 ; 108 - 102 win. [SEP]
LOGITS
tensor([[-1.8499,  7.5464, -2.5896, -2.1333]])
Iteration 1: loss = 24.2996, adv_loss = 14.3928, ref_loss = -0.9989, perp_loss = 10.9058, entropy=8.5832, time=0.08
Iteration 11: loss = 23.6093, adv_loss = 14.1970, ref_loss = -0.9783, perp_loss = 10.3906, entropy=94.8305, time=0.89
Iteration 21: loss = 22.5772, adv_loss = 13.5338, ref_loss = -0.9519, perp_loss = 9.9952, entropy=200.9447, time=1.70
Iteration 31: loss = 17.4463, adv_loss = 8.2438, ref_loss = -0.8080, perp_loss = 10.0104, entropy=255.9468, time=2.51
Iteration 41: loss = 10.4419, adv_loss = 0.0000, ref_loss = -0.4032, perp_loss = 10.8452, entropy=269.1634, time=3.32
Iteration 51: loss = 9.3801, adv_loss = 0.0000, ref_loss = -0.7323, perp_loss = 10.1123, entropy=251.6810, time=4.13
Iteration 61: loss = 8.8584, adv_loss = 0.0000, ref_loss = -0.7981, perp_loss = 9.6564, entropy=209.4659, time=4.93
Iteration 71: loss = 8.5697, adv_loss = 0.2535, ref_loss = -0.8336, perp_loss = 9.1497, entropy=163.8867, time=5.74
Iteration 81: loss = 7.8747, adv_loss = 0.0000, ref_loss = -0.8402, perp_loss = 8.7149, entropy=123.4880, time=6.54
Iteration 91: loss = 7.6479, adv_loss = 0.0522, ref_loss = -0.8334, perp_loss = 8.4291, entropy=88.4314, time=7.35
CLEAN TEXT
Knicks Hold Off Raptors, 108 - 102 New York Knicks # 39 ; Jamal Crawford puts up a shot against the Toronto Raptors during the second quarter Saturday, Nov. 27, 2004. Crawford scored 30 points in the Knicks # 39 ; 108 - 102 win.
ADVERSARIAL TEXT
Whoever Tanaka Hepburn definitive Unaphy Curtis best Unabel 1 Sophie Freddie Marilynsma Trio Triongled Fender Angelina Curtis Cream punch pinch punch punch single resulting Gracie Keith curve sore second liner sore One Stafford Stafford sprawling mark single lashes flu lashes Pepper Booker Philadelphia Alma Una Stone punch Curtis break Single Wilde Rooney Gracie NJ.

CLEAN LOGITS
tensor([[-1.8499,  7.5464, -2.5896, -2.1333]])
ADVERSARIAL LOGITS
tensor([[ 4.8802,  1.0516, -2.8390, -1.3067]])
LABEL
0
TEXT
[CLS] Myanmar frees nearly 4, 000 prisoners UN Secretary General Kofi Annan has praised the release of several political prisoners in Myanmar, the BBC reported Saturday. Annan also said he hoped others still behind [SEP]
LOGITS
tensor([[ 7.1286, -2.2571, -1.6284, -1.8624]])
Iteration 1: loss = 23.8480, adv_loss = 13.7068, ref_loss = -0.9948, perp_loss = 11.1361, entropy=5.9097, time=0.06
Iteration 11: loss = 23.0072, adv_loss = 13.4620, ref_loss = -0.9820, perp_loss = 10.5272, entropy=67.7080, time=0.69
Iteration 21: loss = 11.2979, adv_loss = 0.0000, ref_loss = 0.1493, perp_loss = 11.1487, entropy=172.8253, time=1.31
Iteration 31: loss = 11.1416, adv_loss = 0.0000, ref_loss = 0.1994, perp_loss = 10.9422, entropy=205.9268, time=1.93
Iteration 41: loss = 10.0147, adv_loss = 0.0000, ref_loss = -0.1099, perp_loss = 10.1246, entropy=198.4537, time=2.56
Iteration 51: loss = 10.0834, adv_loss = 0.9320, ref_loss = -0.5282, perp_loss = 9.6797, entropy=161.8121, time=3.18
Iteration 61: loss = 8.6708, adv_loss = 0.0521, ref_loss = -0.3887, perp_loss = 9.0074, entropy=122.3702, time=3.80
Iteration 71: loss = 7.9424, adv_loss = 0.0000, ref_loss = -0.4163, perp_loss = 8.3586, entropy=70.9698, time=4.42
Iteration 81: loss = 7.4696, adv_loss = 0.0000, ref_loss = -0.4703, perp_loss = 7.9399, entropy=41.6202, time=5.04
Iteration 91: loss = 7.2154, adv_loss = 0.0001, ref_loss = -0.5208, perp_loss = 7.7361, entropy=28.1177, time=5.66
CLEAN TEXT
Myanmar frees nearly 4, 000 prisoners UN Secretary General Kofi Annan has praised the release of several political prisoners in Myanmar, the BBC reported Saturday. Annan also said he hoped others still behind
ADVERSARIAL TEXT
punch free PiusVAFA 800 000 differ affordable InstitutesraseFAFAtitis Gracie signature Gracie Gracie StoneFA slipsenia grounded punch grace Nadu Sophie grace punchrase ScholarschiaFA Colombo earliest Angelina overlooked punch Gracieệ

CLEAN LOGITS
tensor([[ 7.1286, -2.2571, -1.6284, -1.8624]])
ADVERSARIAL LOGITS
tensor([[ 0.1095,  7.4073, -3.2512, -2.8498]])
LABEL
1
TEXT
[CLS] F1 BOSS LOSES COURT CASE Formula One boss Bernie Ecclestones control over the sport may be on the decline after a court ruled against him in a dispute with three banks. [SEP]
LOGITS
tensor([[-0.6773,  6.4810, -1.9815, -2.3507]])
Iteration 1: loss = 22.3241, adv_loss = 12.2827, ref_loss = -0.9940, perp_loss = 11.0354, entropy=6.1911, time=0.06
Iteration 11: loss = 20.1768, adv_loss = 10.1634, ref_loss = -0.8523, perp_loss = 10.8656, entropy=28.3730, time=0.70
Iteration 21: loss = 10.8888, adv_loss = 0.0000, ref_loss = -0.0832, perp_loss = 10.9720, entropy=93.7367, time=1.33
Iteration 31: loss = 10.5050, adv_loss = 0.0000, ref_loss = -0.1032, perp_loss = 10.6083, entropy=138.0913, time=1.97
Iteration 41: loss = 9.7958, adv_loss = 0.0000, ref_loss = -0.1597, perp_loss = 9.9554, entropy=161.8714, time=2.60
Iteration 51: loss = 9.1332, adv_loss = 0.0000, ref_loss = -0.1736, perp_loss = 9.3068, entropy=140.4931, time=3.23
Iteration 61: loss = 8.6993, adv_loss = 0.0000, ref_loss = -0.1445, perp_loss = 8.8437, entropy=98.4251, time=3.86
Iteration 71: loss = 8.1490, adv_loss = 0.0000, ref_loss = -0.1563, perp_loss = 8.3053, entropy=50.8552, time=4.49
Iteration 81: loss = 7.8329, adv_loss = 0.0000, ref_loss = -0.1104, perp_loss = 7.9433, entropy=30.8267, time=5.12
Iteration 91: loss = 7.5530, adv_loss = 0.0000, ref_loss = -0.1952, perp_loss = 7.7481, entropy=17.9675, time=5.76
CLEAN TEXT
F1 BOSS LOSES COURT CASE Formula One boss Bernie Ecclestones control over the sport may be on the decline after a court ruled against him in a dispute with three banks.
ADVERSARIAL TEXT
##former Maskwitch concurrentlyyncweight bid Maskloaded concurrently wrestlermelloaded inventor High comic www comic penurerformerff Does Tennis extradierjermer compensate presents act court ruled againstzer in lose demandff engaged profitdier

CLEAN LOGITS
tensor([[-0.6773,  6.4810, -1.9815, -2.3507]])
ADVERSARIAL LOGITS
tensor([[-3.3282, -3.3275,  1.0434,  4.9364]])
LABEL
3
TEXT
[CLS] Worldwide PC Market Seen Doubling by 2010 NEW YORK ( Reuters ) - The number of personal computers worldwide is expected to double to about 1. 3 billion by 2010, driven by explosive growth in emerging markets such as China, Russia and India, according to a report released on Tuesday by Forrester Research Inc. [SEP]
LOGITS
tensor([[-3.7926, -4.2096,  2.7815,  4.0393]])
Iteration 1: loss = 15.7855, adv_loss = 6.0246, ref_loss = -0.9899, perp_loss = 10.7509, entropy=9.7088, time=0.09
Iteration 11: loss = 9.9688, adv_loss = 0.1343, ref_loss = -0.7331, perp_loss = 10.5677, entropy=99.7131, time=0.96
Iteration 21: loss = 9.7635, adv_loss = 0.0000, ref_loss = -0.6940, perp_loss = 10.4575, entropy=218.2774, time=1.83
Iteration 31: loss = 9.3160, adv_loss = 0.0298, ref_loss = -0.7406, perp_loss = 10.0269, entropy=250.6461, time=2.69
Iteration 41: loss = 8.8187, adv_loss = 0.0444, ref_loss = -0.7547, perp_loss = 9.5289, entropy=265.8207, time=3.56
Iteration 51: loss = 8.3204, adv_loss = 0.0000, ref_loss = -0.7072, perp_loss = 9.0276, entropy=241.5680, time=4.43
Iteration 61: loss = 7.7532, adv_loss = 0.0002, ref_loss = -0.7525, perp_loss = 8.5055, entropy=198.4334, time=5.30
Iteration 71: loss = 7.4112, adv_loss = 0.0000, ref_loss = -0.7004, perp_loss = 8.1116, entropy=139.6746, time=6.16
Iteration 81: loss = 7.0606, adv_loss = 0.0435, ref_loss = -0.7146, perp_loss = 7.7317, entropy=89.4896, time=7.03
Iteration 91: loss = 6.6428, adv_loss = 0.0000, ref_loss = -0.7470, perp_loss = 7.3898, entropy=51.5384, time=7.90
CLEAN TEXT
Worldwide PC Market Seen Doubling by 2010 NEW YORK ( Reuters ) - The number of personal computers worldwide is expected to double to about 1. 3 billion by 2010, driven by explosive growth in emerging markets such as China, Russia and India, according to a report released on Tuesday by Forrester Research Inc.
ADVERSARIAL TEXT
##finityeoncarsirkenedpareran cerealceivedbark cerealeran Mediaeraneranparirkzer din plannedier manufacturer of automated computer rearputbrandpar earnparenedparputisan spending worryingbrandrup doubled investing summarymand Wetparopypareraneranenedputput Partner dinirkffinparparceivedceivedsetset Reform furbayyrpar

CLEAN LOGITS
tensor([[-3.7926, -4.2096,  2.7815,  4.0393]])
ADVERSARIAL LOGITS
tensor([[-2.1261, -4.5881,  5.0740,  0.5694]])
LABEL
3
TEXT
[CLS] DOJ won't appeal Oracle ruling WASHINGTON - The U. S. Department of Justice ( DOJ ) will not appeal a ruling by a California judge that would allow Oracle Corp.'s proposed hostile takeover of competing software vendor PeopleSoft Inc. [SEP]
LOGITS
tensor([[-3.0124, -4.2590,  1.6292,  4.7323]])
Iteration 1: loss = 17.8998, adv_loss = 7.8595, ref_loss = -0.9954, perp_loss = 11.0357, entropy=8.4424, time=0.08
Iteration 11: loss = 10.3676, adv_loss = 0.0000, ref_loss = -0.5387, perp_loss = 10.9063, entropy=142.6923, time=0.88
Iteration 21: loss = 10.1853, adv_loss = 0.0000, ref_loss = -0.4696, perp_loss = 10.6549, entropy=248.0927, time=1.68
Iteration 31: loss = 9.6071, adv_loss = 0.0543, ref_loss = -0.5928, perp_loss = 10.1456, entropy=273.1607, time=2.48
Iteration 41: loss = 9.1742, adv_loss = 0.2336, ref_loss = -0.6210, perp_loss = 9.5617, entropy=272.4727, time=3.28
Iteration 51: loss = 8.3735, adv_loss = 0.0000, ref_loss = -0.5824, perp_loss = 8.9559, entropy=232.2546, time=4.08
Iteration 61: loss = 7.8254, adv_loss = 0.0635, ref_loss = -0.5849, perp_loss = 8.3468, entropy=155.8171, time=4.88
Iteration 71: loss = 7.3580, adv_loss = 0.1228, ref_loss = -0.5940, perp_loss = 7.8292, entropy=91.8484, time=5.68
Iteration 81: loss = 6.8735, adv_loss = 0.1178, ref_loss = -0.6306, perp_loss = 7.3863, entropy=57.3289, time=6.48
Iteration 91: loss = 6.5811, adv_loss = 0.0000, ref_loss = -0.6078, perp_loss = 7.1889, entropy=39.7226, time=7.28
CLEAN TEXT
DOJ won't appeal Oracle ruling WASHINGTON - The U. S. Department of Justice ( DOJ ) will not appeal a ruling by a California judge that would allow Oracle Corp.'s proposed hostile takeover of competing software vendor PeopleSoft Inc.
ADVERSARIAL TEXT
##par cereal renovationparenederaner grew Widowisanpledvirbla doublederanbark doubledparparpar wonparparzer laborparpareranceivedparceivedputceived doubled Revivalparsetenedffinffinfulfining tenant Revivalffin senedput Revival incorporate engaged software salesman Featuredfraiaheranzer

CLEAN LOGITS
tensor([[-3.0124, -4.2590,  1.6292,  4.7323]])
ADVERSARIAL LOGITS
tensor([[-1.8520, -3.9128,  5.4762, -0.7671]])
LABEL
2
TEXT
[CLS] Ovitz Defends His Tenure Michael Ovitz said on Tuesday that Walt Disney Co. would have made a string of dazzling deals and shrewd strategic moves during his brief tenure as the company # 39 ; s president [SEP]
LOGITS
tensor([[-0.7654, -3.8258,  5.3460, -1.8691]])
Iteration 1: loss = 20.6122, adv_loss = 11.1540, ref_loss = -0.9980, perp_loss = 10.4562, entropy=7.1761, time=0.07
Iteration 11: loss = 20.1369, adv_loss = 10.9030, ref_loss = -0.9745, perp_loss = 10.2084, entropy=24.1678, time=0.80
Iteration 21: loss = 19.1442, adv_loss = 9.9352, ref_loss = -0.8778, perp_loss = 10.0868, entropy=81.2208, time=1.52
Iteration 31: loss = 11.2045, adv_loss = 0.0000, ref_loss = 0.1146, perp_loss = 11.0899, entropy=141.3409, time=2.25
Iteration 41: loss = 10.8447, adv_loss = 0.0000, ref_loss = 0.1255, perp_loss = 10.7193, entropy=156.2686, time=2.97
Iteration 51: loss = 10.1026, adv_loss = 0.0000, ref_loss = 0.1228, perp_loss = 9.9798, entropy=143.9067, time=3.69
Iteration 61: loss = 9.1108, adv_loss = 0.0000, ref_loss = 0.0665, perp_loss = 9.0443, entropy=108.5067, time=4.41
Iteration 71: loss = 8.2580, adv_loss = 0.0000, ref_loss = -0.0376, perp_loss = 8.2956, entropy=67.3234, time=5.13
Iteration 81: loss = 7.8853, adv_loss = 0.0000, ref_loss = -0.0048, perp_loss = 7.8901, entropy=36.2901, time=5.85
Iteration 91: loss = 7.5493, adv_loss = 0.0042, ref_loss = -0.0643, perp_loss = 7.6094, entropy=22.1508, time=6.57
CLEAN TEXT
Ovitz Defends His Tenure Michael Ovitz said on Tuesday that Walt Disney Co. would have made a string of dazzling deals and shrewd strategic moves during his brief tenure as the company # 39 ; s president
ADVERSARIAL TEXT
Dubai AlbuquerqueMM Frankfurtfen saturated Tito Penangristo Highness Evangelicalcens Kualagro on Hagueela Bangladeshiffles ʻ. Penanggrogroscent Penangscent Saudi evangelicalivespherpherpolisddenscent Hague slipperyddenscent Hagueddendden specialisedffles Khmerdes anniversary slipperygro

CLEAN LOGITS
tensor([[-0.7654, -3.8258,  5.3460, -1.8691]])
ADVERSARIAL LOGITS
tensor([[ 6.4755, -2.3127, -0.9042, -1.7946]])
LABEL
2
TEXT
[CLS] Oracle in Merger Talks with Other Firms SAN FRANCISCO ( Reuters ) - Oracle Corp. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = ORCL. O target = / stocks / quickinfo / fullquote " & gt ; ORCL. O & lt ; / A & gt ; is in merger talks with other technology companies as it awaits the outcome of its \ $ 9. 2 billion hostile takeover bid for rival software maker PeopleSoft Inc. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = PSFT. O target = / stocks / quickinfo / fullquote " & gt ; PSFT. O & lt ; / A & gt ;. [SEP]
LOGITS
tensor([[-0.5356, -3.4808,  5.4890, -2.7541]])
Iteration 1: loss = 20.9729, adv_loss = 11.0458, ref_loss = -0.9988, perp_loss = 10.9259, entropy=28.8450, time=0.23
Iteration 11: loss = 20.5554, adv_loss = 10.8673, ref_loss = -0.9925, perp_loss = 10.6806, entropy=94.8555, time=2.56
Iteration 21: loss = 19.8999, adv_loss = 10.3698, ref_loss = -0.9841, perp_loss = 10.5142, entropy=210.0874, time=4.88
Iteration 31: loss = 11.3486, adv_loss = 0.9961, ref_loss = -0.6124, perp_loss = 10.9650, entropy=377.6487, time=7.20
Iteration 41: loss = 10.2889, adv_loss = 0.0000, ref_loss = -0.6138, perp_loss = 10.9027, entropy=510.4396, time=9.50
Iteration 51: loss = 9.7674, adv_loss = 0.0000, ref_loss = -0.7529, perp_loss = 10.5203, entropy=520.1119, time=11.80
Iteration 61: loss = 9.2160, adv_loss = 0.0000, ref_loss = -0.8415, perp_loss = 10.0574, entropy=464.4337, time=14.10
Iteration 71: loss = 8.7571, adv_loss = 0.0000, ref_loss = -0.8377, perp_loss = 9.5948, entropy=386.2670, time=16.40
Iteration 81: loss = 8.4104, adv_loss = 0.0473, ref_loss = -0.8721, perp_loss = 9.2352, entropy=303.0745, time=18.70
Iteration 91: loss = 8.0003, adv_loss = 0.0000, ref_loss = -0.8764, perp_loss = 8.8767, entropy=241.0801, time=21.00
CLEAN TEXT
Oracle in Merger Talks with Other Firms SAN FRANCISCO ( Reuters ) - Oracle Corp. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = ORCL. O target = / stocks / quickinfo / fullquote " & gt ; ORCL. O & lt ; / A & gt ; is in merger talks with other technology companies as it awaits the outcome of its \ $ 9. 2 billion hostile takeover bid for rival software maker PeopleSoft Inc. & lt ; A HREF = " http : / / www. investor. reuters. com / FullQuote. aspx? ticker = PSFT. O target = / stocks / quickinfo / fullquote " & gt ; PSFT. O & lt ; / A & gt ;.
ADVERSARIAL TEXT
leader fur Carnival Decca renovation until with Makesdekamel Decca months F DCNC 1905COlistedputvir mixing meet shipyardirk. 1793btt ; 1913 ¹⁄₂ Maxwell Burtiber broker 1793 varficficppszar drinksroots salarypectilization comzled Fullaperuosi Highestfallbtficzerzar Philips sectors Strauss Macau misconduct OnicsТdon classics Chevrolet advanceszarplevirplefra Perkinszarterchardzertermer manufacturer Warwick. Conservativesceivedstilleryierstillery bid mixing Gaszerttor mixingizabroizalson solicitor renovationrup curlsetivobadalytic broad 尚 oftraorf m² 9. P billion dealer takeover quotazar Rome liberalwick Breweryŭhall honours. & turntbt Ø PT MarxFT = Фios Weber quarterssmoénsmo Burt. refall Anders comsik Full sumuotor Native 1793zer row Onmer badminton ¹⁄₂ ¹⁄₂çsket summary doi trousers coated struck Noahsulstrafoier fullvirsul mixingman doi ¹⁄₂tages ⅓put ¾ willingness & quartert Sullivan reign Bosskins ¹⁄₂t ft.

CLEAN LOGITS
tensor([[-0.5356, -3.4808,  5.4890, -2.7541]])
ADVERSARIAL LOGITS
tensor([[-1.8146, -4.1993,  2.0820,  3.2577]])
LABEL
1
TEXT
[CLS] Carpentier regains focus for win MONTEREY, Calif. - - As Patrick Carpentier cruised toward his second straight dominating victory at Mazda Raceway Laguna Seca, he let his mind wander. [SEP]
LOGITS
tensor([[-2.1583,  7.3086, -2.3465, -1.7092]])
Iteration 1: loss = 24.0212, adv_loss = 13.9589, ref_loss = -0.9961, perp_loss = 11.0584, entropy=6.7539, time=0.07
Iteration 11: loss = 22.5792, adv_loss = 12.8969, ref_loss = -0.8930, perp_loss = 10.5753, entropy=70.5099, time=0.77
Iteration 21: loss = 10.7668, adv_loss = 0.0000, ref_loss = 0.0024, perp_loss = 10.7644, entropy=163.5164, time=1.48
Iteration 31: loss = 10.6284, adv_loss = 0.0000, ref_loss = 0.0434, perp_loss = 10.5850, entropy=183.0229, time=2.18
Iteration 41: loss = 9.9552, adv_loss = 0.0000, ref_loss = -0.0071, perp_loss = 9.9623, entropy=170.6637, time=2.88
Iteration 51: loss = 9.0758, adv_loss = 0.0416, ref_loss = -0.2168, perp_loss = 9.2510, entropy=147.4026, time=3.58
Iteration 61: loss = 8.4775, adv_loss = 0.0000, ref_loss = -0.2074, perp_loss = 8.6849, entropy=120.0275, time=4.28
Iteration 71: loss = 8.0765, adv_loss = 0.2220, ref_loss = -0.4122, perp_loss = 8.2667, entropy=84.3909, time=4.98
Iteration 81: loss = 7.4365, adv_loss = 0.0000, ref_loss = -0.4597, perp_loss = 7.8962, entropy=50.0157, time=5.68
Iteration 91: loss = 7.1691, adv_loss = 0.0000, ref_loss = -0.4326, perp_loss = 7.6017, entropy=30.8012, time=6.38
CLEAN TEXT
Carpentier regains focus for win MONTEREY, Calif. - - As Patrick Carpentier cruised toward his second straight dominating victory at Mazda Raceway Laguna Seca, he let his mind wander.
ADVERSARIAL TEXT
concurrentlyync chorus sight tag salesman compensate win telephone salesman response efficiency concurrently turnout concurrentlymeleyformer attempting concurrently concurrently tow vain employed concurrentlymerformer Metacriticojazer Won circuitjer Ivan Dan Pursuit Trial Sprintoki hoping concurrently Cade chorus blacksmith ability beg

CLEAN LOGITS
tensor([[-2.1583,  7.3086, -2.3465, -1.7092]])
ADVERSARIAL LOGITS
tensor([[-3.5100, -3.0215,  0.5862,  5.2461]])
LABEL
1
TEXT
[CLS] Brewers Hand Cards Fourth Straight Loss ( AP ) AP - Matt Morris struggled in his final tuneup for the playoffs, and the Milwaukee Brewers beat the St. Louis Cardinals 7 - 6 Thursday night to send the NL Central champions to their first four - game losing streak of the season. [SEP]
LOGITS
tensor([[-1.1746,  7.6215, -2.9184, -2.3586]])
Iteration 1: loss = 23.8181, adv_loss = 13.8590, ref_loss = -0.9988, perp_loss = 10.9579, entropy=8.3017, time=0.08
Iteration 11: loss = 23.2385, adv_loss = 13.6341, ref_loss = -0.9863, perp_loss = 10.5907, entropy=53.5065, time=0.88
Iteration 21: loss = 21.1565, adv_loss = 11.8148, ref_loss = -0.9378, perp_loss = 10.2795, entropy=139.0389, time=1.68
Iteration 31: loss = 12.1002, adv_loss = 2.3274, ref_loss = -0.6886, perp_loss = 10.4613, entropy=214.5103, time=2.48
Iteration 41: loss = 10.0544, adv_loss = 0.0000, ref_loss = -0.5195, perp_loss = 10.5740, entropy=225.1794, time=3.27
Iteration 51: loss = 9.8367, adv_loss = 0.6700, ref_loss = -0.8002, perp_loss = 9.9670, entropy=204.5985, time=4.07
Iteration 61: loss = 8.8392, adv_loss = 0.0089, ref_loss = -0.7990, perp_loss = 9.6294, entropy=174.9117, time=4.87
Iteration 71: loss = 8.7906, adv_loss = 0.4474, ref_loss = -0.8365, perp_loss = 9.1797, entropy=124.7890, time=5.67
Iteration 81: loss = 7.9913, adv_loss = 0.1566, ref_loss = -0.7891, perp_loss = 8.6238, entropy=84.8943, time=6.46
Iteration 91: loss = 7.7218, adv_loss = 0.3184, ref_loss = -0.7352, perp_loss = 8.1386, entropy=53.6798, time=7.26
CLEAN TEXT
Brewers Hand Cards Fourth Straight Loss ( AP ) AP - Matt Morris struggled in his final tuneup for the playoffs, and the Milwaukee Brewers beat the St. Louis Cardinals 7 - 6 Thursday night to send the NL Central champions to their first four - game losing streak of the season.
ADVERSARIAL TEXT
Shield Una Unasten Triple rigorous Una reference Una )VA - Musa punch Rollins reverse Una punch Triple Rooney Una definitive Trio Chun Una oath Una Mayo bowl Darlingboybula Marilyn Una Unamieose liner 5 finest Una among slips 9 slips lashes rosewana Angelina accumulated 8 Scholarsgli Angelina versions PA cheek

CLEAN LOGITS
tensor([[-1.1746,  7.6215, -2.9184, -2.3586]])
ADVERSARIAL LOGITS
tensor([[ 5.4411, -0.1929, -2.8380, -0.4291]])
LABEL
0
TEXT
[CLS] Israel Unions Start Nationwide Strike JERUSALEM ( Reuters ) - Israeli unions began a nationwide strike on Tuesday expected to affect about 400, 000 public sector workers and severely hamper international travel. [SEP]
LOGITS
tensor([[ 5.8028, -2.4644,  0.1496, -2.1162]])
Iteration 1: loss = 21.1030, adv_loss = 10.7060, ref_loss = -0.9948, perp_loss = 11.3918, entropy=6.1911, time=0.06
Iteration 11: loss = 11.1767, adv_loss = 0.7341, ref_loss = -0.3602, perp_loss = 10.8029, entropy=95.9650, time=0.70
Iteration 21: loss = 10.4999, adv_loss = 0.0000, ref_loss = -0.0788, perp_loss = 10.5787, entropy=228.1047, time=1.33
Iteration 31: loss = 9.8127, adv_loss = 0.0000, ref_loss = -0.1123, perp_loss = 9.9250, entropy=242.3823, time=1.97
Iteration 41: loss = 9.0371, adv_loss = 0.0000, ref_loss = -0.1311, perp_loss = 9.1682, entropy=223.2348, time=2.60
Iteration 51: loss = 8.4368, adv_loss = 0.0107, ref_loss = -0.1619, perp_loss = 8.5879, entropy=167.9211, time=3.23
Iteration 61: loss = 7.8532, adv_loss = 0.0000, ref_loss = -0.1310, perp_loss = 7.9842, entropy=92.6021, time=3.86
Iteration 71: loss = 7.3737, adv_loss = 0.0000, ref_loss = -0.1347, perp_loss = 7.5084, entropy=40.4096, time=4.49
Iteration 81: loss = 6.9919, adv_loss = 0.0000, ref_loss = -0.1526, perp_loss = 7.1444, entropy=18.8128, time=5.12
Iteration 91: loss = 6.8378, adv_loss = 0.0074, ref_loss = -0.1531, perp_loss = 6.9835, entropy=10.7113, time=5.76
CLEAN TEXT
Israel Unions Start Nationwide Strike JERUSALEM ( Reuters ) - Israeli unions began a nationwide strike on Tuesday expected to affect about 400, 000 public sector workers and severely hamper international travel.
ADVERSARIAL TEXT
##entederan child Beer Dadpered Wetpareranrupenederanented boilingruparyerthallrupaalvezented dinented fixedrup oferanperedentedwhereceivedperedpered Wetpar tenant tenantlsonlsoneran Revival

CLEAN LOGITS
tensor([[ 5.8028, -2.4644,  0.1496, -2.1162]])
ADVERSARIAL LOGITS
tensor([[-0.2353, -3.6779,  5.1947, -2.5060]])
LABEL
0
TEXT
[CLS] UK to assess Iraq troop move A reconnaissance team is to visit the area around Baghdad where UK forces could be sent to provide US back - up. [SEP]
LOGITS
tensor([[ 6.9168, -2.5566, -1.4293, -1.5671]])
Iteration 1: loss = 23.6535, adv_loss = 13.3897, ref_loss = -0.9960, perp_loss = 11.2598, entropy=4.3619, time=0.08
Iteration 11: loss = 18.9896, adv_loss = 8.8715, ref_loss = -0.8221, perp_loss = 10.9402, entropy=45.4784, time=0.62
Iteration 21: loss = 11.2537, adv_loss = 0.0000, ref_loss = 0.0886, perp_loss = 11.1652, entropy=111.0460, time=1.17
Iteration 31: loss = 10.4062, adv_loss = 0.0000, ref_loss = -0.3193, perp_loss = 10.7256, entropy=132.3236, time=1.71
Iteration 41: loss = 9.8596, adv_loss = 0.3075, ref_loss = -0.6582, perp_loss = 10.2103, entropy=123.1914, time=2.25
Iteration 51: loss = 9.1065, adv_loss = 0.1370, ref_loss = -0.6398, perp_loss = 9.6093, entropy=103.6157, time=2.80
Iteration 61: loss = 8.4171, adv_loss = 0.0000, ref_loss = -0.6946, perp_loss = 9.1117, entropy=73.8030, time=3.34
Iteration 71: loss = 8.0577, adv_loss = 0.0000, ref_loss = -0.6216, perp_loss = 8.6792, entropy=56.6852, time=3.88
Iteration 81: loss = 7.6794, adv_loss = 0.0000, ref_loss = -0.6981, perp_loss = 8.3774, entropy=42.7969, time=4.42
Iteration 91: loss = 7.4264, adv_loss = 0.1299, ref_loss = -0.7366, perp_loss = 8.0331, entropy=27.1720, time=4.97
CLEAN TEXT
UK to assess Iraq troop move A reconnaissance team is to visit the area around Baghdad where UK forces could be sent to provide US back - up.
ADVERSARIAL TEXT
##lstonrice concurrently Iraq crisis ego concurrently intersection concurrently Metacritic contact interest the tallest ul Baghdad Duffyrang Hutchinsonsionalloading comic < Using concurrentlysional contactsional insertion

CLEAN LOGITS
tensor([[ 6.9168, -2.5566, -1.4293, -1.5671]])
ADVERSARIAL LOGITS
tensor([[-1.9631, -3.4981, -0.4582,  5.4149]])
LABEL
2
TEXT
[CLS] Northrop Grumman Gets \ $ 408 Million Pact Defense contractor Northrop Grumman Corp. on Monday said it received a 10 - year, \ $ 408 million Army contract to provide simulated battle command training support to Army corps commanders - the latest award in [SEP]
LOGITS
tensor([[-2.6749, -4.1286,  4.9467,  1.0676]])
Iteration 1: loss = 18.9976, adv_loss = 9.3506, ref_loss = -0.9923, perp_loss = 10.6394, entropy=8.0203, time=0.07
Iteration 11: loss = 12.2891, adv_loss = 2.1314, ref_loss = -0.6904, perp_loss = 10.8481, entropy=65.9980, time=0.84
Iteration 21: loss = 10.6550, adv_loss = 0.0000, ref_loss = -0.3199, perp_loss = 10.9749, entropy=194.5824, time=1.60
Iteration 31: loss = 9.9903, adv_loss = 0.0000, ref_loss = -0.3103, perp_loss = 10.3006, entropy=250.6676, time=2.36
Iteration 41: loss = 9.1496, adv_loss = 0.0053, ref_loss = -0.2996, perp_loss = 9.4439, entropy=257.9447, time=3.12
Iteration 51: loss = 8.3150, adv_loss = 0.0080, ref_loss = -0.2946, perp_loss = 8.6016, entropy=212.9514, time=3.88
Iteration 61: loss = 7.5374, adv_loss = 0.0036, ref_loss = -0.2884, perp_loss = 7.8222, entropy=124.2059, time=4.64
Iteration 71: loss = 6.9314, adv_loss = 0.0054, ref_loss = -0.2986, perp_loss = 7.2247, entropy=53.8048, time=5.40
Iteration 81: loss = 6.6334, adv_loss = 0.0000, ref_loss = -0.3022, perp_loss = 6.9357, entropy=23.8960, time=6.16
Iteration 91: loss = 6.5202, adv_loss = 0.0000, ref_loss = -0.3008, perp_loss = 6.8210, entropy=12.7438, time=6.92
CLEAN TEXT
Northrop Grumman Gets \ $ 408 Million Pact Defense contractor Northrop Grumman Corp. on Monday said it received a 10 - year, \ $ 408 million Army contract to provide simulated battle command training support to Army corps commanders - the latest award in
ADVERSARIAL TEXT
turnout Mask Bold concurrentlysionalloading attemptsaper swaploadingloadingloaded swaploadingloading attempts concurrently attempting concurrently attempting willingness Cast Mask www harnesssionalloading attemptingwright attemptsloadingweight concurrently harnessloaded cart concurrentlyync wwwyer Flint www Bold Mask input swap vain concurrently attempting intersection concurrentlyloadedloading vainël

CLEAN LOGITS
tensor([[-2.6749, -4.1286,  4.9467,  1.0676]])
ADVERSARIAL LOGITS
tensor([[-3.2114, -3.1455,  0.2731,  5.3536]])
LABEL
1
TEXT
[CLS] THE 35TH RYDER CUP Tiger # 39 ; s Cup doesn # 39 ; t run over with success Bloomfield Township, Mich. - - The Ryder Cup is upon us, and you know what that means : Time to dress up as Mrs. Doubtfire and taunt Colin Montgomerie from behind the ropes? [SEP]
LOGITS
tensor([[-2.1134,  7.4798, -2.3537, -2.1170]])
Iteration 1: loss = 24.5773, adv_loss = 14.5388, ref_loss = -0.9926, perp_loss = 11.0311, entropy=10.2716, time=0.09
Iteration 11: loss = 22.0590, adv_loss = 12.1591, ref_loss = -0.7795, perp_loss = 10.6794, entropy=142.8308, time=1.00
Iteration 21: loss = 10.8647, adv_loss = 0.0000, ref_loss = 0.0087, perp_loss = 10.8560, entropy=347.7642, time=1.90
Iteration 31: loss = 10.3236, adv_loss = 0.0000, ref_loss = -0.0603, perp_loss = 10.3839, entropy=394.1920, time=2.81
Iteration 41: loss = 9.5246, adv_loss = 0.0000, ref_loss = -0.1131, perp_loss = 9.6377, entropy=345.4604, time=3.71
Iteration 51: loss = 8.8123, adv_loss = 0.1598, ref_loss = -0.1661, perp_loss = 8.8186, entropy=263.4042, time=4.62
Iteration 61: loss = 8.0367, adv_loss = 0.0000, ref_loss = -0.1523, perp_loss = 8.1889, entropy=172.7781, time=5.52
Iteration 71: loss = 7.5750, adv_loss = 0.0000, ref_loss = -0.0973, perp_loss = 7.6724, entropy=99.6752, time=6.42
Iteration 81: loss = 7.1025, adv_loss = 0.0000, ref_loss = -0.1579, perp_loss = 7.2605, entropy=50.9627, time=7.33
Iteration 91: loss = 6.8897, adv_loss = 0.0000, ref_loss = -0.1322, perp_loss = 7.0219, entropy=31.6426, time=8.23
CLEAN TEXT
THE 35TH RYDER CUP Tiger # 39 ; s Cup doesn # 39 ; t run over with success Bloomfield Township, Mich. - - The Ryder Cup is upon us, and you know what that means : Time to dress up as Mrs. Doubtfire and taunt Colin Montgomerie from behind the ropes?
ADVERSARIAL TEXT
attempts wrestlerreckweightoy harness concurrentlypet Pursuit harness Maskweight swapformer attempting tag attempting wrestlerweight turnout concurrentlymeljer vain Yangfield Swamp turnout vain rodformer turnout concurrently Bold blacksmithpable compensate blacksmith concurrentlyjer compensate Mask Mask concurrently turnout turnout Mask turnoutync blacksmith blacksmith swap Mask turnout Troy tag Mask blacksmith tag vain vainformerjer Ciceromer attempting turnout blacksmith circuit attempts attempts

CLEAN LOGITS
tensor([[-2.1134,  7.4798, -2.3537, -2.1170]])
ADVERSARIAL LOGITS
tensor([[-3.3937, -1.6537, -0.1993,  4.7288]])
LABEL
1
TEXT
[CLS] Troubled Real and Roma meet as Champions League resumes Madrid, Spain ( Sports Network ) - Two clubs with storied tradition but in the midst of current turmoil will meet Tuesday when Real Madrid and Roma highlight Matchday 2 of the UEFA Champions League group play. [SEP]
LOGITS
tensor([[-1.7658,  7.6256, -2.6912, -2.1127]])
Iteration 1: loss = 24.3573, adv_loss = 14.3871, ref_loss = -0.9987, perp_loss = 10.9689, entropy=7.7389, time=0.07
Iteration 11: loss = 23.7481, adv_loss = 14.1297, ref_loss = -0.9662, perp_loss = 10.5847, entropy=68.3988, time=0.82
Iteration 21: loss = 22.7102, adv_loss = 13.4607, ref_loss = -0.9400, perp_loss = 10.1894, entropy=162.8443, time=1.57
Iteration 31: loss = 10.9767, adv_loss = 0.5151, ref_loss = -0.5191, perp_loss = 10.9807, entropy=214.8439, time=2.32
Iteration 41: loss = 10.3119, adv_loss = 0.0000, ref_loss = -0.5705, perp_loss = 10.8823, entropy=218.7430, time=3.07
Iteration 51: loss = 9.7071, adv_loss = 0.2592, ref_loss = -0.7336, perp_loss = 10.1815, entropy=200.3260, time=3.81
Iteration 61: loss = 8.6996, adv_loss = 0.0000, ref_loss = -0.8278, perp_loss = 9.5273, entropy=154.7787, time=4.56
Iteration 71: loss = 8.3560, adv_loss = 0.0576, ref_loss = -0.7764, perp_loss = 9.0748, entropy=116.1660, time=5.30
Iteration 81: loss = 7.9156, adv_loss = 0.0968, ref_loss = -0.8008, perp_loss = 8.6196, entropy=92.7318, time=6.05
Iteration 91: loss = 7.5990, adv_loss = 0.0000, ref_loss = -0.7688, perp_loss = 8.3678, entropy=72.4142, time=6.79
CLEAN TEXT
Troubled Real and Roma meet as Champions League resumes Madrid, Spain ( Sports Network ) - Two clubs with storied tradition but in the midst of current turmoil will meet Tuesday when Real Madrid and Roma highlight Matchday 2 of the UEFA Champions League group play.
ADVERSARIAL TEXT
Zeusrise Gracie punches Lynn Percy V Royce Tripleuxeuxe Clair I Pauline Una Curtis Alma Novel Ivan nude Harlem Bertie Neville Gracie Lotusuxe fancy punchuxe punch finest punch punch punch Yale ODS chip mattered duelrsch sore Floridaday Curtisose Loser UEFA finishimationdice x copied

CLEAN LOGITS
tensor([[-1.7658,  7.6256, -2.6912, -2.1127]])
ADVERSARIAL LOGITS
tensor([[ 3.3363,  0.7802, -3.4465,  1.0754]])
LABEL
3
TEXT
[CLS] Report : Consumers tuning in to plasma TVs First - quarter shipments of plasma televisions in the United States more than doubled from the previous year, according to research firm iSuppli. Prices fell by nearly \ $ 1, 000 over the same period. [SEP]
LOGITS
tensor([[-3.0458, -4.0487,  1.6717,  4.5408]])
Iteration 1: loss = 17.8796, adv_loss = 7.8508, ref_loss = -0.9966, perp_loss = 11.0254, entropy=8.1610, time=0.08
Iteration 11: loss = 11.1444, adv_loss = 1.2017, ref_loss = -0.6966, perp_loss = 10.6393, entropy=98.8445, time=0.88
Iteration 21: loss = 9.9676, adv_loss = 0.0000, ref_loss = -0.5772, perp_loss = 10.5448, entropy=214.0418, time=1.67
Iteration 31: loss = 9.7289, adv_loss = 0.3536, ref_loss = -0.6725, perp_loss = 10.0478, entropy=230.8610, time=2.46
Iteration 41: loss = 9.0654, adv_loss = 0.1429, ref_loss = -0.6473, perp_loss = 9.5697, entropy=228.4855, time=3.25
Iteration 51: loss = 8.5750, adv_loss = 0.2375, ref_loss = -0.6665, perp_loss = 9.0039, entropy=202.7632, time=4.04
Iteration 61: loss = 7.8491, adv_loss = 0.0801, ref_loss = -0.6880, perp_loss = 8.4570, entropy=148.2510, time=4.83
Iteration 71: loss = 7.5270, adv_loss = 0.0936, ref_loss = -0.6736, perp_loss = 8.1070, entropy=101.1119, time=5.62
Iteration 81: loss = 7.1118, adv_loss = 0.0000, ref_loss = -0.6913, perp_loss = 7.8031, entropy=68.8060, time=6.41
Iteration 91: loss = 6.8393, adv_loss = 0.0000, ref_loss = -0.7228, perp_loss = 7.5621, entropy=42.4292, time=7.20
CLEAN TEXT
Report : Consumers tuning in to plasma TVs First - quarter shipments of plasma televisions in the United States more than doubled from the previous year, according to research firm iSuppli. Prices fell by nearly \ $ 1, 000 over the same period.
ADVERSARIAL TEXT
##par doubledopy laborpar notirkcier viewedput shaping dinvirvir labor of plasma television watch finally dreamed delightedfeldpar reflected profit cerealretaparputvirrup to worrying Brosyrceived doubled Brosvolvedirkrup Māori wary Revivalvirenedviryrffinput furrup fur earn cereal

CLEAN LOGITS
tensor([[-3.0458, -4.0487,  1.6717,  4.5408]])
ADVERSARIAL LOGITS
tensor([[-1.8710, -4.4201,  5.3561, -0.0644]])
LABEL
2
TEXT
[CLS] Snap - on warns for 3Q, 2004 Vehicle tool maker sees profit below forecasts amid high steel prices, soft demand in Europe. NEW YORK ( Reuters ) - Snap - on Inc., which makes vehicle - repair tools, said Tuesday its third - quarter and full - year [SEP]
LOGITS
tensor([[-1.2482, -4.0344,  5.5554, -1.3719]])
Iteration 1: loss = 21.2667, adv_loss = 11.8063, ref_loss = -0.9979, perp_loss = 10.4583, entropy=9.0053, time=0.08
Iteration 11: loss = 19.9110, adv_loss = 10.4717, ref_loss = -0.9488, perp_loss = 10.3881, entropy=62.2538, time=0.91
Iteration 21: loss = 15.4244, adv_loss = 5.2008, ref_loss = -0.6238, perp_loss = 10.8474, entropy=163.5759, time=1.73
Iteration 31: loss = 11.1735, adv_loss = 0.0000, ref_loss = -0.1134, perp_loss = 11.2870, entropy=200.0778, time=2.56
Iteration 41: loss = 10.2924, adv_loss = 0.0000, ref_loss = -0.5244, perp_loss = 10.8167, entropy=188.3076, time=3.38
Iteration 51: loss = 9.8468, adv_loss = 0.1605, ref_loss = -0.6149, perp_loss = 10.3012, entropy=173.2291, time=4.20
Iteration 61: loss = 9.0626, adv_loss = 0.0000, ref_loss = -0.6945, perp_loss = 9.7571, entropy=147.7569, time=5.02
Iteration 71: loss = 8.5789, adv_loss = 0.0000, ref_loss = -0.6683, perp_loss = 9.2472, entropy=118.1558, time=5.84
Iteration 81: loss = 8.2193, adv_loss = 0.0000, ref_loss = -0.5953, perp_loss = 8.8147, entropy=81.6934, time=6.66
Iteration 91: loss = 7.8281, adv_loss = 0.0000, ref_loss = -0.6774, perp_loss = 8.5055, entropy=61.8992, time=7.48
CLEAN TEXT
Snap - on warns for 3Q, 2004 Vehicle tool maker sees profit below forecasts amid high steel prices, soft demand in Europe. NEW YORK ( Reuters ) - Snap - on Inc., which makes vehicle - repair tools, said Tuesday its third - quarter and full - year
ADVERSARIAL TEXT
##keldes vocationalpher bilateral for orthodox UAEoop 2004 Investment feet maker sees profit below Remembers Down lone Qatarhere ONEnged Yugoslavia behavioral KualaΚ Okinawa Penangnged subdivided Kualacamecame PTristo -nged tentativenaclehes strongpher, considers evergreenả -fflesddenfers Reginamberwich Hague keenher considers sobervanceaper

CLEAN LOGITS
tensor([[-1.2482, -4.0344,  5.5554, -1.3719]])
ADVERSARIAL LOGITS
tensor([[ 4.3849, -3.1068,  1.7298, -1.8936]])
LABEL
3
TEXT
[CLS] Linux puts another financial feather in its cap Industry observers say Linux's similarity to Unix, its lower cost and ability to run on Intel hardware make the Unix market ripe for open - source conquest. [SEP]
LOGITS
tensor([[-1.4250, -3.8666, -0.2320,  4.7476]])
Iteration 1: loss = 20.4186, adv_loss = 10.0110, ref_loss = -0.9969, perp_loss = 11.4045, entropy=5.7690, time=0.06
Iteration 11: loss = 19.5056, adv_loss = 9.5414, ref_loss = -0.9644, perp_loss = 10.9287, entropy=45.2923, time=0.68
Iteration 21: loss = 17.3584, adv_loss = 7.7490, ref_loss = -0.9053, perp_loss = 10.5147, entropy=113.7074, time=1.30
Iteration 31: loss = 10.2622, adv_loss = 0.2849, ref_loss = -0.5911, perp_loss = 10.5684, entropy=166.5964, time=1.92
Iteration 41: loss = 9.7603, adv_loss = 0.0000, ref_loss = -0.5634, perp_loss = 10.3237, entropy=167.8787, time=2.53
Iteration 51: loss = 9.2639, adv_loss = 0.3901, ref_loss = -0.7512, perp_loss = 9.6250, entropy=147.6436, time=3.15
Iteration 61: loss = 8.3586, adv_loss = 0.0000, ref_loss = -0.7336, perp_loss = 9.0922, entropy=110.3689, time=3.76
Iteration 71: loss = 7.8650, adv_loss = 0.0000, ref_loss = -0.7195, perp_loss = 8.5845, entropy=74.8933, time=4.38
Iteration 81: loss = 7.5714, adv_loss = 0.0000, ref_loss = -0.7237, perp_loss = 8.2951, entropy=46.7671, time=4.99
Iteration 91: loss = 7.3573, adv_loss = 0.0000, ref_loss = -0.7418, perp_loss = 8.0991, entropy=35.8641, time=5.60
CLEAN TEXT
Linux puts another financial feather in its cap Industry observers say Linux's similarity to Unix, its lower cost and ability to run on Intel hardware make the Unix market ripe for open - source conquest.
ADVERSARIAL TEXT
##feld Poor another Kemplumput holdings borrowedholdingckoned Nikecorncar Katz butcherfeld Plan Car raise Labour reflectedfeld engagedpiece cereal din Electronic deciduoustour butcher Graphic inventor butcher inventor openjer sourceré engaged

CLEAN LOGITS
tensor([[-1.4250, -3.8666, -0.2320,  4.7476]])
ADVERSARIAL LOGITS
tensor([[-2.8077, -4.8077,  4.4625,  2.1649]])
LABEL
1
TEXT
[CLS] Australia better prepared, says Gilchrist Mumbai - Australia # 39 ; s stand - in captain Adam Gilchrist said on Saturday his team was seeking a momentous Test series triumph in India. [SEP]
LOGITS
tensor([[-1.8670,  7.6309, -2.7386, -2.0476]])
Iteration 1: loss = 24.4061, adv_loss = 14.5156, ref_loss = -0.9982, perp_loss = 10.8888, entropy=5.7690, time=0.06
Iteration 11: loss = 23.5100, adv_loss = 14.1707, ref_loss = -0.9603, perp_loss = 10.2995, entropy=63.9754, time=0.68
Iteration 21: loss = 15.7757, adv_loss = 6.0243, ref_loss = -0.7118, perp_loss = 10.4632, entropy=169.8413, time=1.30
Iteration 31: loss = 10.5732, adv_loss = 0.0000, ref_loss = -0.3993, perp_loss = 10.9725, entropy=189.8179, time=1.92
Iteration 41: loss = 10.1505, adv_loss = 0.2742, ref_loss = -0.5958, perp_loss = 10.4722, entropy=181.0530, time=2.53
Iteration 51: loss = 9.5062, adv_loss = 0.0396, ref_loss = -0.5735, perp_loss = 10.0401, entropy=147.6985, time=3.14
Iteration 61: loss = 10.3930, adv_loss = 1.3748, ref_loss = -0.5230, perp_loss = 9.5412, entropy=104.2893, time=3.76
Iteration 71: loss = 8.5936, adv_loss = 0.0000, ref_loss = -0.5089, perp_loss = 9.1025, entropy=75.9236, time=4.37
Iteration 81: loss = 8.5125, adv_loss = 0.0734, ref_loss = -0.4358, perp_loss = 8.8749, entropy=50.2436, time=4.99
Iteration 91: loss = 8.2460, adv_loss = 0.4448, ref_loss = -0.6832, perp_loss = 8.4844, entropy=38.7418, time=5.60
CLEAN TEXT
Australia better prepared, says Gilchrist Mumbai - Australia # 39 ; s stand - in captain Adam Gilchrist said on Saturday his team was seeking a momentous Test series triumph in India.
ADVERSARIAL TEXT
baldunch Una Unarung Unautiminated Alfredo XIII Tonga Pius Marilyn Electoral s offences BenedictIA immunity Adam sanctions tipped Hague Una Gracie Gracie Lankan immunityppe Damascus abulaose Test series repeat in nominated.

CLEAN LOGITS
tensor([[-1.8670,  7.6309, -2.7386, -2.0476]])
ADVERSARIAL LOGITS
tensor([[ 6.0202, -0.0901, -2.4572, -1.9499]])
LABEL
3
TEXT
[CLS] Skulls Trojan keelhauls Symbian phones Users with Symbian - based mobile phones have been hit by malicious code that disables smartphone features. Skulls, a Trojan horse program that poses as gaming software, is one of the first examples of malicious code to successfully infect mobiles. [SEP]
LOGITS
tensor([[-2.2010, -3.6259, -0.2404,  5.2949]])
Iteration 1: loss = 20.4651, adv_loss = 10.5379, ref_loss = -0.9977, perp_loss = 10.9249, entropy=9.7088, time=0.08
Iteration 11: loss = 19.4914, adv_loss = 9.9883, ref_loss = -0.9686, perp_loss = 10.4717, entropy=113.4855, time=0.96
Iteration 21: loss = 17.0629, adv_loss = 7.7613, ref_loss = -0.8252, perp_loss = 10.1269, entropy=273.1143, time=1.83
Iteration 31: loss = 10.4467, adv_loss = 0.0000, ref_loss = -0.1457, perp_loss = 10.5923, entropy=305.9991, time=2.71
Iteration 41: loss = 9.7981, adv_loss = 0.0089, ref_loss = -0.3124, perp_loss = 10.1015, entropy=298.5023, time=3.57
Iteration 51: loss = 9.4258, adv_loss = 0.3619, ref_loss = -0.4203, perp_loss = 9.4842, entropy=268.7680, time=4.44
Iteration 61: loss = 8.4268, adv_loss = 0.0418, ref_loss = -0.4605, perp_loss = 8.8455, entropy=201.1134, time=5.31
Iteration 71: loss = 8.0500, adv_loss = 0.1532, ref_loss = -0.4819, perp_loss = 8.3788, entropy=128.7388, time=6.18
Iteration 81: loss = 7.5628, adv_loss = 0.0391, ref_loss = -0.4942, perp_loss = 8.0179, entropy=83.6890, time=7.05
Iteration 91: loss = 7.2578, adv_loss = 0.0000, ref_loss = -0.4623, perp_loss = 7.7201, entropy=58.5814, time=7.91
CLEAN TEXT
Skulls Trojan keelhauls Symbian phones Users with Symbian - based mobile phones have been hit by malicious code that disables smartphone features. Skulls, a Trojan horse program that poses as gaming software, is one of the first examples of malicious code to successfully infect mobiles.
ADVERSARIAL TEXT
##harfyraughisanvicudge quartersfinity investingolisisanzerydroptonumatic Boss bargainisan Citizen goodsput proprietorweightput landownerparrupfeldierharfparputmeraperputenvez absorbing,izalungrup Registerirk boarded redevelopmentopy Dad meeting stirringaugh robinadyiza willingnessaugh furierisan Goodmanent willingnessyrisan mobile merchantgins

CLEAN LOGITS
tensor([[-2.2010, -3.6259, -0.2404,  5.2949]])
ADVERSARIAL LOGITS
tensor([[-3.0594, -4.5517,  4.9464,  1.5485]])
LABEL
2
TEXT
[CLS] S amp ; P 500 Rises for 4th Day ; Material, Energy Shares Lead Advance The Standard amp ; Poor # 39 ; s 500 Index rose for a fourth day as investors looked past a disappointing third - quarter economic growth report to better - than - expected readings on Chicago - area business and consumer confidence. [SEP]
LOGITS
tensor([[-0.5052, -3.6936,  5.5109, -2.5167]])
Iteration 1: loss = 20.6289, adv_loss = 11.0509, ref_loss = -0.9997, perp_loss = 10.5776, entropy=9.4274, time=0.08
Iteration 11: loss = 20.1696, adv_loss = 10.8265, ref_loss = -0.9920, perp_loss = 10.3351, entropy=53.7545, time=0.94
Iteration 21: loss = 17.6424, adv_loss = 8.1002, ref_loss = -0.8378, perp_loss = 10.3800, entropy=151.3653, time=1.80
Iteration 31: loss = 10.8855, adv_loss = 0.0000, ref_loss = -0.3641, perp_loss = 11.2497, entropy=250.5922, time=2.66
Iteration 41: loss = 10.1314, adv_loss = 0.0000, ref_loss = -0.6367, perp_loss = 10.7682, entropy=271.5184, time=3.51
Iteration 51: loss = 9.4476, adv_loss = 0.0000, ref_loss = -0.7151, perp_loss = 10.1627, entropy=228.0977, time=4.37
Iteration 61: loss = 8.7440, adv_loss = 0.0762, ref_loss = -0.7524, perp_loss = 9.4202, entropy=165.5276, time=5.22
Iteration 71: loss = 8.3434, adv_loss = 0.0055, ref_loss = -0.6037, perp_loss = 8.9417, entropy=115.1660, time=6.07
Iteration 81: loss = 7.6086, adv_loss = 0.0712, ref_loss = -0.7864, perp_loss = 8.3239, entropy=79.4311, time=6.92
Iteration 91: loss = 7.2134, adv_loss = 0.0459, ref_loss = -0.7504, perp_loss = 7.9179, entropy=45.7039, time=7.78
CLEAN TEXT
S amp ; P 500 Rises for 4th Day ; Material, Energy Shares Lead Advance The Standard amp ; Poor # 39 ; s 500 Index rose for a fourth day as investors looked past a disappointing third - quarter economic growth report to better - than - expected readings on Chicago - area business and consumer confidence.
ADVERSARIAL TEXT
Islamic TNAssenʳ Nationale gramscamekel fixed Everestnched Kosovo Islamicnacle Kenyan engravedČnched Yugoslav mud Bayern Lankanmpusddenristonged Kosovo consecrated mudngedscent Kuala Lankanelopher bitter day towards banksddenckerpherescu HagueХpherХ Hague Albuquerquedden deciduousrrosion deciduous clad Heavy orthodox on Rockefellercomb Industries investment furnishings bench Keynesnan

CLEAN LOGITS
tensor([[-0.5052, -3.6936,  5.5109, -2.5167]])
ADVERSARIAL LOGITS
tensor([[ 6.1276, -2.3293, -0.3711, -2.0077]])
LABEL
2
TEXT
[CLS] Fannie Mae Didn't Comply With Accounting Rules, S. E. C. Says Fannie Mae, the biggest source of money for U. S. home mortgages, broke accounting rules for financial contracts designed to protect against swings in interests rates. [SEP]
LOGITS
tensor([[ 0.0666, -3.8924,  5.3007, -2.5406]])
Iteration 1: loss = 19.9903, adv_loss = 10.2611, ref_loss = -0.9965, perp_loss = 10.7257, entropy=7.8796, time=0.07
Iteration 11: loss = 19.2490, adv_loss = 9.7908, ref_loss = -0.9531, perp_loss = 10.4113, entropy=44.7871, time=0.83
Iteration 21: loss = 10.6739, adv_loss = 0.0860, ref_loss = -0.3114, perp_loss = 10.8994, entropy=114.6953, time=1.59
Iteration 31: loss = 10.4884, adv_loss = 0.0000, ref_loss = -0.2954, perp_loss = 10.7838, entropy=149.7230, time=2.34
Iteration 41: loss = 9.5336, adv_loss = 0.0000, ref_loss = -0.6083, perp_loss = 10.1419, entropy=150.1858, time=3.09
Iteration 51: loss = 9.2112, adv_loss = 0.0000, ref_loss = -0.6160, perp_loss = 9.8272, entropy=141.9980, time=3.84
Iteration 61: loss = 8.9145, adv_loss = 0.1857, ref_loss = -0.7217, perp_loss = 9.4506, entropy=123.3897, time=4.60
Iteration 71: loss = 8.6187, adv_loss = 0.0000, ref_loss = -0.6843, perp_loss = 9.3031, entropy=105.7674, time=5.35
Iteration 81: loss = 8.2487, adv_loss = 0.0000, ref_loss = -0.7032, perp_loss = 8.9519, entropy=81.5284, time=6.10
Iteration 91: loss = 8.0801, adv_loss = 0.0000, ref_loss = -0.6891, perp_loss = 8.7692, entropy=61.8308, time=6.85
CLEAN TEXT
Fannie Mae Didn't Comply With Accounting Rules, S. E. C. Says Fannie Mae, the biggest source of money for U. S. home mortgages, broke accounting rules for financial contracts designed to protect against swings in interests rates.
ADVERSARIAL TEXT
Waller extended Down Sino 'risto ribppagg With Eden Freefen unnamed. ° KCsmos Albuquerquervins Philphere Mae rigid thecks pocket of Floridadrazad toward Danailed pocket Nixons,turn wheat pocket for financial values 1860 sober sanctions against swings in 1950 n.

CLEAN LOGITS
tensor([[ 0.0666, -3.8924,  5.3007, -2.5406]])
ADVERSARIAL LOGITS
tensor([[ 5.3774, -2.7600,  0.5237, -2.0759]])
LABEL
0
TEXT
[CLS] Sharon faces Netanyahu challenge Israeli Prime Minister Ariel Sharon has received a surprise challenge to his plan to expedite a pullout from Gaza after Benjamin Netanyahu, his main rival in the Likud party, called for a referendum on the issue. [SEP]
LOGITS
tensor([[ 7.1738, -2.3596, -1.4432, -2.1396]])
Iteration 1: loss = 24.1065, adv_loss = 13.6198, ref_loss = -0.9992, perp_loss = 11.4859, entropy=7.5982, time=0.07
Iteration 11: loss = 18.1011, adv_loss = 8.0519, ref_loss = -0.7287, perp_loss = 10.7778, entropy=94.1741, time=0.82
Iteration 21: loss = 11.1267, adv_loss = 0.0000, ref_loss = 0.0917, perp_loss = 11.0350, entropy=224.7138, time=1.56
Iteration 31: loss = 10.4769, adv_loss = 0.0000, ref_loss = -0.0677, perp_loss = 10.5447, entropy=272.9370, time=2.29
Iteration 41: loss = 9.4630, adv_loss = 0.0000, ref_loss = -0.3115, perp_loss = 9.7746, entropy=263.7404, time=3.03
Iteration 51: loss = 8.5077, adv_loss = 0.0000, ref_loss = -0.6632, perp_loss = 9.1708, entropy=219.7966, time=3.77
Iteration 61: loss = 7.8730, adv_loss = 0.0000, ref_loss = -0.7205, perp_loss = 8.5935, entropy=160.2454, time=4.51
Iteration 71: loss = 7.2789, adv_loss = 0.0000, ref_loss = -0.8033, perp_loss = 8.0822, entropy=102.8148, time=5.24
Iteration 81: loss = 6.9362, adv_loss = 0.0000, ref_loss = -0.7790, perp_loss = 7.7151, entropy=68.1201, time=5.98
Iteration 91: loss = 6.6098, adv_loss = 0.1229, ref_loss = -0.8425, perp_loss = 7.3294, entropy=36.1342, time=6.72
CLEAN TEXT
Sharon faces Netanyahu challenge Israeli Prime Minister Ariel Sharon has received a surprise challenge to his plan to expedite a pullout from Gaza after Benjamin Netanyahu, his main rival in the Likud party, called for a referendum on the issue.
ADVERSARIAL TEXT
ScholarsFAFAFAescu memorableildeFA Double SophiegliFA copied punchFAFAFA sore punch overlookedFA qualityKOtitis Classics singleFA Britannia Hitlerdira Heldbba Lama prayers Angelinazong liner lashesonicildenesia chancebula Double Angelina punch overlooked grounded Double punch Angelina epithet

CLEAN LOGITS
tensor([[ 7.1738, -2.3596, -1.4432, -2.1396]])
ADVERSARIAL LOGITS
tensor([[ 0.7846,  6.9394, -3.5839, -2.7251]])
LABEL
3
TEXT
[CLS] Toshiba to Unveil HD DVD Laptops in 2005 - - Paper TOKYO ( Reuters ) - Japan's Toshiba Corp. & lt ; A HREF = " http : / / www. reuters. co. uk / financeQuoteLookup. jhtml? ticker = 6502. T qtype = sym infotype = info qcat = news " & gt ; 6502. T & lt ; / A & gt ; will introduce laptop computers with HD DVD technology in December 2005, aiming to pressure rivals in the battle over formats for next - generation DVDs, the Nihon Keizai daily said on Wednesday. [SEP]
LOGITS
tensor([[-2.3927, -3.4695, -0.1949,  5.3965]])
Iteration 1: loss = 20.4648, adv_loss = 10.5161, ref_loss = -0.9979, perp_loss = 10.9466, entropy=20.9654, time=0.17
Iteration 11: loss = 19.1905, adv_loss = 9.5215, ref_loss = -0.9412, perp_loss = 10.6102, entropy=189.8203, time=1.94
Iteration 21: loss = 10.2487, adv_loss = 0.4805, ref_loss = -0.7987, perp_loss = 10.5669, entropy=360.0346, time=3.71
Iteration 31: loss = 9.4924, adv_loss = 0.0000, ref_loss = -0.8092, perp_loss = 10.3016, entropy=479.3299, time=5.46
Iteration 41: loss = 9.1561, adv_loss = 0.1230, ref_loss = -0.8291, perp_loss = 9.8623, entropy=516.3613, time=7.22
Iteration 51: loss = 8.3450, adv_loss = 0.0165, ref_loss = -0.8454, perp_loss = 9.1738, entropy=479.6011, time=8.97
Iteration 61: loss = 7.5717, adv_loss = 0.0000, ref_loss = -0.8446, perp_loss = 8.4163, entropy=354.9814, time=10.72
Iteration 71: loss = 7.0833, adv_loss = 0.1224, ref_loss = -0.8556, perp_loss = 7.8165, entropy=215.2560, time=12.48
Iteration 81: loss = 6.6447, adv_loss = 0.0406, ref_loss = -0.8545, perp_loss = 7.4586, entropy=156.3900, time=14.23
Iteration 91: loss = 6.4583, adv_loss = 0.0184, ref_loss = -0.8382, perp_loss = 7.2780, entropy=103.4135, time=15.98
CLEAN TEXT
Toshiba to Unveil HD DVD Laptops in 2005 - - Paper TOKYO ( Reuters ) - Japan's Toshiba Corp. & lt ; A HREF = " http : / / www. reuters. co. uk / financeQuoteLookup. jhtml? ticker = 6502. T qtype = sym infotype = info qcat = news " & gt ; 6502. T & lt ; / A & gt ; will introduce laptop computers with HD DVD technology in December 2005, aiming to pressure rivals in the battle over formats for next - generation DVDs, the Nihon Keizai daily said on Wednesday.
ADVERSARIAL TEXT
##feldshi wonizasselpar Boss bargainficdierjervicudge overhaulkinbic engagedmereleybicviceley bargainvir doubledvic rear summary→eological sum participated solicitor dealings sum summary summaryformer A preview doubledvirparaperyrgedputmple wwwsee re capitalism grew investedreta 2017 decent financial corner capita Colemanielmer profitlumwick doubledlungeleybicweight forecast Buy Buy overtime Carloformerdiermerptonweightweight blacksmithweightweight blacksmith blacksmith Makes blacksmithaper Makesweight blacksmithjer blacksmith Merry inventor blacksmith inventor inventorjer blacksmith turnout turnout turnout voljereley blacksmithweightjer blacksmith blacksmith Bold AutomaticEG Bold Mask Makesweight turnoutweight blacksmith Boldweight turnout inventor Bold Bold turnoutweight turnoutweight employed blacksmithweight Merry Makes Yongeleyiza bargain employed bidyerjer hire

CLEAN LOGITS
tensor([[-2.3927, -3.4695, -0.1949,  5.3965]])
ADVERSARIAL LOGITS
tensor([[-3.2993, -4.8229,  4.4380,  2.5732]])
LABEL
2
TEXT
[CLS] GM, Daimler Go Green Team - up will help the companies compete and fill gaps in both firms'portfolios. [SEP]
LOGITS
tensor([[-0.3420, -4.9207,  2.5340,  1.9438]])
Iteration 1: loss = 15.9217, adv_loss = 6.2571, ref_loss = -0.9880, perp_loss = 10.6526, entropy=3.6584, time=0.05
Iteration 11: loss = 10.8549, adv_loss = 0.4536, ref_loss = -0.5260, perp_loss = 10.9273, entropy=28.4817, time=0.58
Iteration 21: loss = 10.2607, adv_loss = 0.0044, ref_loss = -0.4822, perp_loss = 10.7385, entropy=67.8402, time=1.09
Iteration 31: loss = 9.6711, adv_loss = 0.0140, ref_loss = -0.5863, perp_loss = 10.2434, entropy=82.1027, time=1.61
Iteration 41: loss = 9.0059, adv_loss = 0.0000, ref_loss = -0.6483, perp_loss = 9.6542, entropy=88.6427, time=2.13
Iteration 51: loss = 8.3873, adv_loss = 0.0000, ref_loss = -0.6264, perp_loss = 9.0137, entropy=85.2186, time=2.65
Iteration 61: loss = 7.7533, adv_loss = 0.0000, ref_loss = -0.6131, perp_loss = 8.3664, entropy=61.4708, time=3.17
Iteration 71: loss = 7.2492, adv_loss = 0.0000, ref_loss = -0.6667, perp_loss = 7.9159, entropy=34.6460, time=3.69
Iteration 81: loss = 6.7826, adv_loss = 0.0220, ref_loss = -0.6867, perp_loss = 7.4473, entropy=18.6397, time=4.21
Iteration 91: loss = 6.5474, adv_loss = 0.0000, ref_loss = -0.6412, perp_loss = 7.1886, entropy=9.9910, time=4.73
CLEAN TEXT
GM, Daimler Go Green Team - up will help the companies compete and fill gaps in both firms'portfolios.
ADVERSARIAL TEXT
ok Using tow Maskliography Trailloading Mask Mask Maskweight intersection Treasurer bargain engagedjer pull bargain engaged trendier executive workersfic

CLEAN LOGITS
tensor([[-0.3420, -4.9207,  2.5340,  1.9438]])
ADVERSARIAL LOGITS
tensor([[-2.9172, -3.7349,  0.6597,  5.3197]])
LABEL
0
TEXT
[CLS] Bollywood actress Nirupa Roy dies Bollywood actress Nirupa Roy dies after a heart attack at her home in Mumbai ( Bombay ) aged 73. [SEP]
LOGITS
tensor([[ 6.7226, -2.5292, -1.5923, -1.3000]])
Iteration 1: loss = 22.9707, adv_loss = 12.9054, ref_loss = -0.9800, perp_loss = 11.0454, entropy=4.3619, time=0.06
Iteration 11: loss = 22.2246, adv_loss = 12.5346, ref_loss = -0.9490, perp_loss = 10.6389, entropy=37.8757, time=0.60
Iteration 21: loss = 10.9638, adv_loss = 0.0979, ref_loss = -0.1810, perp_loss = 11.0469, entropy=113.7363, time=1.15
Iteration 31: loss = 10.7661, adv_loss = 0.0000, ref_loss = -0.0976, perp_loss = 10.8637, entropy=134.5596, time=1.69
Iteration 41: loss = 10.0329, adv_loss = 0.0000, ref_loss = -0.2316, perp_loss = 10.2645, entropy=121.4246, time=2.24
Iteration 51: loss = 9.3139, adv_loss = 0.0000, ref_loss = -0.3536, perp_loss = 9.6676, entropy=92.0508, time=2.78
Iteration 61: loss = 9.0721, adv_loss = 0.3014, ref_loss = -0.4094, perp_loss = 9.1801, entropy=65.0073, time=3.33
Iteration 71: loss = 8.4614, adv_loss = 0.0000, ref_loss = -0.3426, perp_loss = 8.8039, entropy=46.1287, time=3.87
Iteration 81: loss = 8.1829, adv_loss = 0.0000, ref_loss = -0.2945, perp_loss = 8.4774, entropy=29.8108, time=4.42
Iteration 91: loss = 7.7666, adv_loss = 0.0230, ref_loss = -0.5541, perp_loss = 8.2977, entropy=24.0957, time=4.96
CLEAN TEXT
Bollywood actress Nirupa Roy dies Bollywood actress Nirupa Roy dies after a heart attack at her home in Mumbai ( Bombay ) aged 73.
ADVERSARIAL TEXT
##gablesionalloadedsionalloadedmented < Bollywood html < subscriptionmented fansional lens Includeslston Mysore Irvingmiooom Whereas Irving Mysore Queens Phillip aged 59ffs

CLEAN LOGITS
tensor([[ 6.7226, -2.5292, -1.5923, -1.3000]])
ADVERSARIAL LOGITS
tensor([[-1.1961, -3.6008, -0.8990,  5.2203]])
LABEL
3
TEXT
[CLS] Firefox Browser Alternative to Microsoft ( AP ) AP - Web surfing has belonged almost exclusively to Microsoft Corp.'s Internet Explorer ever since it buried Netscape's pioneering browser. That doesn't seem to have bothered the developers of the Mozilla Firefox, a feisty new kid on the block that's worth a serious look. [SEP]
LOGITS
tensor([[-1.9697, -3.3459, -0.9256,  5.7074]])
Iteration 1: loss = 21.6910, adv_loss = 11.6263, ref_loss = -0.9976, perp_loss = 11.0623, entropy=10.8345, time=0.09
Iteration 11: loss = 19.7514, adv_loss = 10.0503, ref_loss = -0.9379, perp_loss = 10.6390, entropy=143.5743, time=1.04
Iteration 21: loss = 12.9335, adv_loss = 2.8681, ref_loss = -0.5133, perp_loss = 10.5786, entropy=304.2275, time=1.98
Iteration 31: loss = 10.5034, adv_loss = 0.0000, ref_loss = -0.1083, perp_loss = 10.6117, entropy=374.9516, time=2.92
Iteration 41: loss = 9.6872, adv_loss = 0.0000, ref_loss = -0.3070, perp_loss = 9.9942, entropy=379.3236, time=3.86
Iteration 51: loss = 9.0391, adv_loss = 0.0000, ref_loss = -0.3520, perp_loss = 9.3911, entropy=340.2624, time=4.80
Iteration 61: loss = 8.4525, adv_loss = 0.2052, ref_loss = -0.4818, perp_loss = 8.7291, entropy=241.4196, time=5.73
Iteration 71: loss = 7.8770, adv_loss = 0.2147, ref_loss = -0.5297, perp_loss = 8.1920, entropy=158.0086, time=6.67
Iteration 81: loss = 7.2159, adv_loss = 0.0290, ref_loss = -0.5431, perp_loss = 7.7300, entropy=97.9067, time=7.61
Iteration 91: loss = 6.8905, adv_loss = 0.0000, ref_loss = -0.5661, perp_loss = 7.4566, entropy=58.1961, time=8.55
CLEAN TEXT
Firefox Browser Alternative to Microsoft ( AP ) AP - Web surfing has belonged almost exclusively to Microsoft Corp.'s Internet Explorer ever since it buried Netscape's pioneering browser. That doesn't seem to have bothered the developers of the Mozilla Firefox, a feisty new kid on the block that's worth a serious look.
ADVERSARIAL TEXT
##aughvirffin Suburban laboropyierharf Microsoftiq wagon Coffee efficientffinffinffinbarkisan Racewayyer Widow Microsoft dealing. robin promoter Planzarigoizavikpton robinvirvirweight doubled investing investingsight willingness witparparparirkbarkrupirkierptonaughrupyrirkirkgel Katzirkirkptonptoneleyfpislumberptonvirffinuateformeriza adjustments Buy goal

CLEAN LOGITS
tensor([[-1.9697, -3.3459, -0.9256,  5.7074]])
ADVERSARIAL LOGITS
tensor([[-2.3727, -4.5081,  5.3974,  0.3239]])
LABEL
2
TEXT
[CLS] Fannie Mae criminal probe begun Federal prosecutors in Washington have opened an investigation into possible wrongdoing at mortgage giant Fannie Mae, just days after regulators accused [SEP]
LOGITS
tensor([[ 0.2282, -3.7889,  5.1524, -2.8268]])
Iteration 1: loss = 19.5342, adv_loss = 9.9365, ref_loss = -0.9985, perp_loss = 10.5961, entropy=4.7840, time=0.06
Iteration 11: loss = 19.0235, adv_loss = 9.7822, ref_loss = -0.9579, perp_loss = 10.1992, entropy=34.0398, time=0.64
Iteration 21: loss = 12.1730, adv_loss = 1.4804, ref_loss = -0.4133, perp_loss = 11.1059, entropy=81.1644, time=1.22
Iteration 31: loss = 11.2579, adv_loss = 0.0000, ref_loss = 0.0428, perp_loss = 11.2150, entropy=121.6633, time=1.80
Iteration 41: loss = 10.4378, adv_loss = 0.0000, ref_loss = 0.0097, perp_loss = 10.4281, entropy=131.7534, time=2.38
Iteration 51: loss = 9.4123, adv_loss = 0.0000, ref_loss = -0.0470, perp_loss = 9.4592, entropy=108.4823, time=2.95
Iteration 61: loss = 8.5219, adv_loss = 0.0000, ref_loss = -0.0774, perp_loss = 8.5993, entropy=73.6625, time=3.53
Iteration 71: loss = 7.8139, adv_loss = 0.0000, ref_loss = -0.0874, perp_loss = 7.9014, entropy=41.7131, time=4.11
Iteration 81: loss = 7.3906, adv_loss = 0.0000, ref_loss = -0.1075, perp_loss = 7.4981, entropy=24.7375, time=4.68
Iteration 91: loss = 7.2556, adv_loss = 0.0000, ref_loss = -0.0717, perp_loss = 7.3274, entropy=15.5595, time=5.26
CLEAN TEXT
Fannie Mae criminal probe begun Federal prosecutors in Washington have opened an investigation into possible wrongdoing at mortgage giant Fannie Mae, just days after regulators accused
ADVERSARIAL TEXT
mudwami Kualawamiilsristo Sino monksristo Zagrebgroelocame abusiveweetescu Paulacumgro sick Malaysian Colomboristodes Kualaristo Hague grasp evergreen Hagueddenils

CLEAN LOGITS
tensor([[ 0.2282, -3.7889,  5.1524, -2.8268]])
ADVERSARIAL LOGITS
tensor([[ 6.6215, -2.0900, -1.2950, -1.7869]])
LABEL
2
TEXT
[CLS] Oracle Fails to Inspire Tech Rally Oracle Corp. handed the software industry some positive earnings news after the bell on Tuesday, but investors pulled cash from the sector on concerns that information technology spending has become anemic. [SEP]
LOGITS
tensor([[-3.7908, -4.0217,  2.4328,  4.2928]])
Iteration 1: loss = 12.7749, adv_loss = 3.3019, ref_loss = -0.9904, perp_loss = 10.4634, entropy=6.6132, time=0.07
Iteration 11: loss = 10.5233, adv_loss = 0.9537, ref_loss = -0.9259, perp_loss = 10.4955, entropy=48.4289, time=0.77
Iteration 21: loss = 9.6427, adv_loss = 0.0000, ref_loss = -0.8012, perp_loss = 10.4439, entropy=136.1874, time=1.47
Iteration 31: loss = 9.0582, adv_loss = 0.0932, ref_loss = -0.8555, perp_loss = 9.8205, entropy=158.9484, time=2.17
Iteration 41: loss = 8.3817, adv_loss = 0.0110, ref_loss = -0.8079, perp_loss = 9.1786, entropy=176.7568, time=2.87
Iteration 51: loss = 7.6298, adv_loss = 0.0069, ref_loss = -0.8066, perp_loss = 8.4295, entropy=163.1452, time=3.57
Iteration 61: loss = 6.8144, adv_loss = 0.0024, ref_loss = -0.8114, perp_loss = 7.6235, entropy=106.0004, time=4.27
Iteration 71: loss = 6.2220, adv_loss = 0.0000, ref_loss = -0.8256, perp_loss = 7.0476, entropy=49.8906, time=4.96
Iteration 81: loss = 5.9025, adv_loss = 0.0000, ref_loss = -0.8293, perp_loss = 6.7318, entropy=22.6385, time=5.66
Iteration 91: loss = 5.8014, adv_loss = 0.0000, ref_loss = -0.8098, perp_loss = 6.6112, entropy=12.1547, time=6.36
CLEAN TEXT
Oracle Fails to Inspire Tech Rally Oracle Corp. handed the software industry some positive earnings news after the bell on Tuesday, but investors pulled cash from the sector on concerns that information technology spending has become anemic.
ADVERSARIAL TEXT
Maskync harness Maskync concurrentlyloadedël Mask concurrentlyloading Mask Mask Maskloadedloadingël swap Makeswright Mask concurrently concurrently vain vain attempts ok shareholder attempts earnings beg deputy bargaindier vainweightdierweightloaded Maskweight vain Mask Mask vain

CLEAN LOGITS
tensor([[-3.7908, -4.0217,  2.4328,  4.2928]])
ADVERSARIAL LOGITS
tensor([[-3.1934, -3.3606,  0.4527,  5.3817]])
LABEL
3
TEXT
[CLS] Users Buoyed by Monthly Patch Releases OCTOBER 18, 2004 ( COMPUTERWORLD ) - Microsoft Corp. # 39 ; s move to a monthly patch - release cycle one year ago this month has made it easier to install security updates for Windows and other products, IT managers said last weekeven as they were greeted with a [SEP]
LOGITS
tensor([[-3.4733, -3.0776,  0.3737,  5.4165]])
Iteration 1: loss = 19.9721, adv_loss = 9.9851, ref_loss = -0.9949, perp_loss = 10.9818, entropy=10.6937, time=0.09
Iteration 11: loss = 18.7814, adv_loss = 9.1565, ref_loss = -0.9630, perp_loss = 10.5879, entropy=125.3419, time=1.02
Iteration 21: loss = 10.6718, adv_loss = 0.0000, ref_loss = -0.0939, perp_loss = 10.7657, entropy=277.0403, time=1.95
Iteration 31: loss = 9.9628, adv_loss = 0.0000, ref_loss = -0.2868, perp_loss = 10.2496, entropy=334.3702, time=2.87
Iteration 41: loss = 9.4215, adv_loss = 0.1140, ref_loss = -0.4025, perp_loss = 9.7099, entropy=343.0340, time=3.79
Iteration 51: loss = 8.8004, adv_loss = 0.0000, ref_loss = -0.4246, perp_loss = 9.2249, entropy=304.2576, time=4.71
Iteration 61: loss = 8.3147, adv_loss = 0.0049, ref_loss = -0.3731, perp_loss = 8.6829, entropy=225.3903, time=5.64
Iteration 71: loss = 7.7237, adv_loss = 0.0500, ref_loss = -0.4831, perp_loss = 8.1568, entropy=146.2609, time=6.56
Iteration 81: loss = 7.3850, adv_loss = 0.0000, ref_loss = -0.4085, perp_loss = 7.7935, entropy=94.6919, time=7.48
Iteration 91: loss = 7.0627, adv_loss = 0.0000, ref_loss = -0.4054, perp_loss = 7.4682, entropy=60.7576, time=8.40
CLEAN TEXT
Users Buoyed by Monthly Patch Releases OCTOBER 18, 2004 ( COMPUTERWORLD ) - Microsoft Corp. # 39 ; s move to a monthly patch - release cycle one year ago this month has made it easier to install security updates for Windows and other products, IT managers said last weekeven as they were greeted with a
ADVERSARIAL TEXT
##ffin negotiating bargain carpenterentput toward anticipated attemptsronicbarkparbarklumberparzer Meetingierptonviraughcierparffinvirformer doubled attorney Liuptonudgeput finallygins shopvez furierzar -rup advantageier furputyrfityrlumber robinvirvicager spendingaughputfallier robinvirffinmerrup dreamedparzerptonffinparbic Plan dealingisan profit

CLEAN LOGITS
tensor([[-3.4733, -3.0776,  0.3737,  5.4165]])
ADVERSARIAL LOGITS
tensor([[-3.5124, -3.7342,  5.1049,  1.1409]])
LABEL
2
TEXT
[CLS] Thai Airways orders six Airbus superjumbos Thai Airways International plans to buy six Airbus A380 double - decker aircraft that will be delivered in 2008 and 2009. The airline is also ordering two additional A340 aircraft. [SEP]
LOGITS
tensor([[ 0.8649, -3.4605,  3.8381, -0.9755]])
Iteration 1: loss = 18.0958, adv_loss = 8.0709, ref_loss = -0.9957, perp_loss = 11.0206, entropy=6.7540, time=0.07
Iteration 11: loss = 12.6813, adv_loss = 2.7561, ref_loss = -0.8047, perp_loss = 10.7299, entropy=52.2490, time=0.78
Iteration 21: loss = 10.5176, adv_loss = 0.0000, ref_loss = -0.3782, perp_loss = 10.8959, entropy=141.8642, time=1.48
Iteration 31: loss = 9.9200, adv_loss = 0.0170, ref_loss = -0.5091, perp_loss = 10.4120, entropy=157.0742, time=2.18
Iteration 41: loss = 9.5957, adv_loss = 0.1495, ref_loss = -0.5729, perp_loss = 10.0191, entropy=150.6530, time=2.88
Iteration 51: loss = 9.2870, adv_loss = 0.1181, ref_loss = -0.4885, perp_loss = 9.6574, entropy=134.6293, time=3.58
Iteration 61: loss = 8.7376, adv_loss = 0.0489, ref_loss = -0.4878, perp_loss = 9.1765, entropy=112.2266, time=4.28
Iteration 71: loss = 8.3024, adv_loss = 0.0000, ref_loss = -0.4891, perp_loss = 8.7915, entropy=76.1794, time=4.98
Iteration 81: loss = 8.0460, adv_loss = 0.0009, ref_loss = -0.4303, perp_loss = 8.4754, entropy=57.4161, time=5.68
Iteration 91: loss = 7.8199, adv_loss = 0.0627, ref_loss = -0.4544, perp_loss = 8.2116, entropy=44.7964, time=6.38
CLEAN TEXT
Thai Airways orders six Airbus superjumbos Thai Airways International plans to buy six Airbus A380 double - decker aircraft that will be delivered in 2008 and 2009. The airline is also ordering two additional A340 aircraft.
ADVERSARIAL TEXT
Thaiʳ Colombo Classics Sino Para Montereyristo Complete Peña ʻ Nathaniel Alexandriaapa accumulated inherited Princeton inheritedcano shaped spans Albuquerque Gerhard Benz Lahoreuren will Complete ordered in everyday everyday realized challenging The airline Stick literally ordering worthy chartered bilateral Düsseldorf trained derivedpher

CLEAN LOGITS
tensor([[ 0.8649, -3.4605,  3.8381, -0.9755]])
ADVERSARIAL LOGITS
tensor([[ 3.4009, -1.0739, -0.4413, -0.6298]])
LABEL
0
TEXT
[CLS] Hague Court Imposes Defense Counsel on Milosevic THE HAGUE ( Reuters ) - Judges at The Hague tribunal on Thursday imposed a defense counsel on former Yugoslav President Slobodan Milosevic to avoid further delays in his war crimes trial. [SEP]
LOGITS
tensor([[ 7.0850, -1.9969, -1.5686, -2.1536]])
Iteration 1: loss = 23.8966, adv_loss = 13.6563, ref_loss = -0.9970, perp_loss = 11.2374, entropy=7.5982, time=0.07
Iteration 11: loss = 18.3744, adv_loss = 8.4576, ref_loss = -0.7649, perp_loss = 10.6817, entropy=94.9720, time=0.82
Iteration 21: loss = 11.0922, adv_loss = 0.0000, ref_loss = 0.1378, perp_loss = 10.9544, entropy=223.3746, time=1.56
Iteration 31: loss = 10.5471, adv_loss = 0.0000, ref_loss = 0.1440, perp_loss = 10.4031, entropy=264.6339, time=2.29
Iteration 41: loss = 9.7164, adv_loss = 0.0000, ref_loss = 0.0342, perp_loss = 9.6822, entropy=249.0049, time=3.03
Iteration 51: loss = 8.8139, adv_loss = 0.0000, ref_loss = -0.2507, perp_loss = 9.0646, entropy=194.1296, time=3.77
Iteration 61: loss = 8.1399, adv_loss = 0.0000, ref_loss = -0.3262, perp_loss = 8.4661, entropy=129.9504, time=4.51
Iteration 71: loss = 7.5744, adv_loss = 0.0000, ref_loss = -0.4037, perp_loss = 7.9781, entropy=78.8403, time=5.24
Iteration 81: loss = 7.0965, adv_loss = 0.0000, ref_loss = -0.5431, perp_loss = 7.6396, entropy=45.0794, time=5.98
Iteration 91: loss = 6.9605, adv_loss = 0.0000, ref_loss = -0.5518, perp_loss = 7.5123, entropy=31.6100, time=6.72
CLEAN TEXT
Hague Court Imposes Defense Counsel on Milosevic THE HAGUE ( Reuters ) - Judges at The Hague tribunal on Thursday imposed a defense counsel on former Yugoslav President Slobodan Milosevic to avoid further delays in his war crimes trial.
ADVERSARIAL TEXT
##ilde Circle ImpoFA flu Percy Percy Mercury MintFAFAtitisMAUEinateduted flu AngelinaFA Gracie flu Relief Curtis ClassicsFA Mercury trademark punchildeFAhmuintetker shadowynies RoyalFAFA Marilyn Branch Percy remaining signaturesuted PercyFAuted flu grounded fluilde

CLEAN LOGITS
tensor([[ 7.0850, -1.9969, -1.5686, -2.1536]])
ADVERSARIAL LOGITS
tensor([[-0.2106,  6.6652, -2.3678, -2.6919]])
LABEL
3
TEXT
[CLS] Tesco To Sell Downloadable Tunes Tesco aint daft, theyve done the insurance blag and now they getting stuck into the music downloading service. They will be the first supermarket to enter a market that is worth over 25million and is currently dominated by the Apple run iTunes. [SEP]
LOGITS
tensor([[-3.3359, -3.3624,  1.0475,  4.7629]])
Iteration 1: loss = 18.6311, adv_loss = 8.7847, ref_loss = -0.9934, perp_loss = 10.8399, entropy=9.1460, time=0.08
Iteration 11: loss = 16.4073, adv_loss = 6.8034, ref_loss = -0.8959, perp_loss = 10.4997, entropy=54.1129, time=0.93
Iteration 21: loss = 10.1513, adv_loss = 0.0000, ref_loss = -0.4437, perp_loss = 10.5950, entropy=168.9560, time=1.78
Iteration 31: loss = 9.7907, adv_loss = 0.0903, ref_loss = -0.4857, perp_loss = 10.1861, entropy=223.9299, time=2.62
Iteration 41: loss = 9.1113, adv_loss = 0.0000, ref_loss = -0.6055, perp_loss = 9.7168, entropy=233.5987, time=3.46
Iteration 51: loss = 8.5211, adv_loss = 0.0289, ref_loss = -0.6717, perp_loss = 9.1639, entropy=206.0539, time=4.31
Iteration 61: loss = 8.0202, adv_loss = 0.0000, ref_loss = -0.6595, perp_loss = 8.6798, entropy=167.8119, time=5.15
Iteration 71: loss = 7.8302, adv_loss = 0.2092, ref_loss = -0.6439, perp_loss = 8.2650, entropy=118.1863, time=5.99
Iteration 81: loss = 7.5818, adv_loss = 0.2271, ref_loss = -0.6444, perp_loss = 7.9991, entropy=84.8138, time=6.83
Iteration 91: loss = 7.1074, adv_loss = 0.0000, ref_loss = -0.6277, perp_loss = 7.7351, entropy=59.7919, time=7.68
CLEAN TEXT
Tesco To Sell Downloadable Tunes Tesco aint daft, theyve done the insurance blag and now they getting stuck into the music downloading service. They will be the first supermarket to enter a market that is worth over 25million and is currently dominated by the Apple run iTunes.
ADVERSARIAL TEXT
##eranbaybic doubled winter km² cerealparffin intendpar Revivalisanweight soughtbarkiza Partnerceivedvirput investments overtime uniform engaged cerealhand engineer Flute into theiring Mixing chart wheel night summaryyerparudge continuesrupigo Goodmancorn Plan renovation cerealirkput cereal renovation overtimerupptonvir furput Car cereal Caropyier

CLEAN LOGITS
tensor([[-3.3359, -3.3624,  1.0475,  4.7629]])
ADVERSARIAL LOGITS
tensor([[-1.6466, -4.2991,  5.3711, -0.5044]])
LABEL
3
TEXT
[CLS] Maid sues Sony Pictures exec p2pnet. net News - James Jackson, vp of legal affairs for Sony Pictures Entertainment, filed for bankruptcy protection just days before a lawsuit accusing him and his wife of involuntary servitude, false imprisonment, invasion of privacy, negligence and [SEP]
LOGITS
tensor([[-2.6965, -3.4274,  0.0946,  5.3649]])
Iteration 1: loss = 20.0966, adv_loss = 10.1545, ref_loss = -0.9932, perp_loss = 10.9354, entropy=9.1460, time=0.08
Iteration 11: loss = 16.9785, adv_loss = 7.3272, ref_loss = -0.8481, perp_loss = 10.4994, entropy=99.8481, time=0.93
Iteration 21: loss = 10.4101, adv_loss = 0.0000, ref_loss = -0.1902, perp_loss = 10.6003, entropy=263.3963, time=1.78
Iteration 31: loss = 9.7936, adv_loss = 0.0000, ref_loss = -0.3393, perp_loss = 10.1329, entropy=319.1111, time=2.62
Iteration 41: loss = 9.1692, adv_loss = 0.0902, ref_loss = -0.4630, perp_loss = 9.5420, entropy=305.1299, time=3.46
Iteration 51: loss = 8.4353, adv_loss = 0.0089, ref_loss = -0.5245, perp_loss = 8.9509, entropy=240.8097, time=4.31
Iteration 61: loss = 7.9255, adv_loss = 0.1003, ref_loss = -0.5525, perp_loss = 8.3776, entropy=163.8403, time=5.15
Iteration 71: loss = 7.4003, adv_loss = 0.0502, ref_loss = -0.5547, perp_loss = 7.9047, entropy=96.7028, time=5.99
Iteration 81: loss = 7.4150, adv_loss = 0.4295, ref_loss = -0.5651, perp_loss = 7.5505, entropy=64.6945, time=6.84
Iteration 91: loss = 6.7403, adv_loss = 0.0000, ref_loss = -0.5295, perp_loss = 7.2699, entropy=45.6192, time=7.68
CLEAN TEXT
Maid sues Sony Pictures exec p2pnet. net News - James Jackson, vp of legal affairs for Sony Pictures Entertainment, filed for bankruptcy protection just days before a lawsuit accusing him and his wife of involuntary servitude, false imprisonment, invasion of privacy, negligence and
ADVERSARIAL TEXT
##ened negotiatedierier Growing labor plansput businessman profit Partnerffinzerpps anticipatedisan wonirk profitffin robin legalvir Corazarirkrup cerealorax anticipated bankruptcy amenities summary Plan summarypar willingnessformerffinizaeleyparpar furizasseluate planparvicputfic furpar negotiatevicffinpieceiervirffingenceier

CLEAN LOGITS
tensor([[-2.6965, -3.4274,  0.0946,  5.3649]])
ADVERSARIAL LOGITS
tensor([[-1.3549, -4.2219,  5.3207, -0.7622]])
LABEL
1
TEXT
[CLS] Atlanta police arrest Braves player on DUI charge ATLANTA - Atlanta Braves shortsop Rafael Furcal has been arrested on charges of driving under the influence. Jail officials say Furcal was booked into the Atlanta city jail at 6 : 25 am on charges of DUI, speeding and reckless driving. [SEP]
LOGITS
tensor([[-1.0755,  7.3344, -2.4593, -2.6018]])
Iteration 1: loss = 23.4142, adv_loss = 13.4629, ref_loss = -0.9965, perp_loss = 10.9479, entropy=9.1460, time=0.08
Iteration 11: loss = 22.3346, adv_loss = 12.6834, ref_loss = -0.9322, perp_loss = 10.5833, entropy=68.7779, time=0.93
Iteration 21: loss = 15.7123, adv_loss = 5.7383, ref_loss = -0.6209, perp_loss = 10.5949, entropy=189.8031, time=1.78
Iteration 31: loss = 10.8754, adv_loss = 0.0000, ref_loss = -0.0212, perp_loss = 10.8966, entropy=273.1326, time=2.63
Iteration 41: loss = 10.2229, adv_loss = 0.0000, ref_loss = -0.0384, perp_loss = 10.2613, entropy=283.1927, time=3.47
Iteration 51: loss = 9.2124, adv_loss = 0.0000, ref_loss = -0.0591, perp_loss = 9.2715, entropy=245.4628, time=4.31
Iteration 61: loss = 8.2887, adv_loss = 0.0000, ref_loss = -0.0828, perp_loss = 8.3715, entropy=151.6460, time=5.15
Iteration 71: loss = 7.7915, adv_loss = 0.0000, ref_loss = -0.1503, perp_loss = 7.9418, entropy=84.9366, time=6.00
Iteration 81: loss = 7.5852, adv_loss = 0.0000, ref_loss = -0.1117, perp_loss = 7.6969, entropy=60.4007, time=6.84
Iteration 91: loss = 7.3595, adv_loss = 0.0406, ref_loss = -0.2255, perp_loss = 7.5444, entropy=42.2602, time=7.68
CLEAN TEXT
Atlanta police arrest Braves player on DUI charge ATLANTA - Atlanta Braves shortsop Rafael Furcal has been arrested on charges of driving under the influence. Jail officials say Furcal was booked into the Atlanta city jail at 6 : 25 am on charges of DUI, speeding and reckless driving.
ADVERSARIAL TEXT
XIIIzam Pius TNA Everpher Lankan Nobel Gracie Gracie Nobelcens Piusnza engraved surname Stick Electoral Nobelcelmilel has Nobel Personstainsxed nose Nobelristokles mud Evangelical Meiji ॥ Nobelphertony Janeiro severe Dhaka Julianansoanche Colombo peeled Down Nobel Gracie Evangelicalể Nobel Apartneanso Nationale Nationale slippery Eton pinned Nobel Gracieapa

CLEAN LOGITS
tensor([[-1.0755,  7.3344, -2.4593, -2.6018]])
ADVERSARIAL LOGITS
tensor([[ 6.0008, -0.3166, -2.5414, -1.3946]])
LABEL
2
TEXT
[CLS] Oracle v. Peoplesoft : the joke is on... Opinion I thought it was a joke when Oracle first announced that it was going to try to buy PeopleSoft ; or, at best, a spoiling tactic over PeopleSoft # 39 ; s acquisition of JD Edwards. [SEP]
LOGITS
tensor([[-3.5046, -4.0915,  5.1242,  1.0340]])
Iteration 1: loss = 18.5842, adv_loss = 8.9495, ref_loss = -0.9929, perp_loss = 10.6276, entropy=9.0053, time=0.08
Iteration 11: loss = 11.0233, adv_loss = 0.4698, ref_loss = -0.4714, perp_loss = 11.0249, entropy=90.2679, time=0.91
Iteration 21: loss = 10.4101, adv_loss = 0.0000, ref_loss = -0.3710, perp_loss = 10.7811, entropy=239.7556, time=1.73
Iteration 31: loss = 9.6010, adv_loss = 0.0000, ref_loss = -0.3734, perp_loss = 9.9744, entropy=325.3446, time=2.55
Iteration 41: loss = 8.6878, adv_loss = 0.0000, ref_loss = -0.3790, perp_loss = 9.0669, entropy=329.9354, time=3.37
Iteration 51: loss = 7.8652, adv_loss = 0.0000, ref_loss = -0.3606, perp_loss = 8.2258, entropy=263.2296, time=4.19
Iteration 61: loss = 7.1172, adv_loss = 0.0000, ref_loss = -0.3805, perp_loss = 7.4977, entropy=148.5841, time=5.01
Iteration 71: loss = 6.5937, adv_loss = 0.0046, ref_loss = -0.4448, perp_loss = 7.0340, entropy=65.8369, time=5.83
Iteration 81: loss = 6.2474, adv_loss = 0.0062, ref_loss = -0.4832, perp_loss = 6.7244, entropy=27.7800, time=6.65
Iteration 91: loss = 6.0960, adv_loss = 0.0000, ref_loss = -0.5096, perp_loss = 6.6055, entropy=13.6585, time=7.47
CLEAN TEXT
Oracle v. Peoplesoft : the joke is on... Opinion I thought it was a joke when Oracle first announced that it was going to try to buy PeopleSoft ; or, at best, a spoiling tactic over PeopleSoft # 39 ; s acquisition of JD Edwards.
ADVERSARIAL TEXT
Mask insertionloading Maskloading Maskloadingsional concurrentlyync Mask Maskweight tag Mask owe concurrentlymelweightloaded Maskloading Maskwright attempts blacksmith concurrently vainyncdier concurrentlyaper attempts attempting tag attempts compensate hireyer, salesmanformerël vain wrestler beg inventor Mask vain tow Maskaper Maskloadedweight vainsional Mask Mask Mask concurrently vain

CLEAN LOGITS
tensor([[-3.5046, -4.0915,  5.1242,  1.0340]])
ADVERSARIAL LOGITS
tensor([[-3.0678, -3.2332,  0.1959,  5.4618]])
LABEL
2
TEXT
[CLS] Probe Sought on Charges FDA Discredited Whistleblower The head of the Senate Finance Committee called on the US Department of Health and Human Services to launch a probe of allegations that the US Food and Drug Administration went out of its way to discredit a whistleblower. [SEP]
LOGITS
tensor([[-2.1848, -4.7745,  3.3532,  2.7685]])
Iteration 1: loss = 15.4911, adv_loss = 5.6696, ref_loss = -0.9957, perp_loss = 10.8173, entropy=9.0053, time=0.08
Iteration 11: loss = 10.5779, adv_loss = 0.1205, ref_loss = -0.6680, perp_loss = 11.1254, entropy=84.4816, time=0.91
Iteration 21: loss = 10.3564, adv_loss = 0.0275, ref_loss = -0.5154, perp_loss = 10.8443, entropy=198.8620, time=1.73
Iteration 31: loss = 9.8506, adv_loss = 0.0686, ref_loss = -0.4832, perp_loss = 10.2651, entropy=250.0512, time=2.55
Iteration 41: loss = 9.0030, adv_loss = 0.0104, ref_loss = -0.4650, perp_loss = 9.4577, entropy=266.6682, time=3.37
Iteration 51: loss = 8.1895, adv_loss = 0.0117, ref_loss = -0.4353, perp_loss = 8.6131, entropy=239.7438, time=4.19
Iteration 61: loss = 7.2555, adv_loss = 0.0099, ref_loss = -0.4289, perp_loss = 7.6745, entropy=144.4699, time=5.01
Iteration 71: loss = 6.6480, adv_loss = 0.0000, ref_loss = -0.4233, perp_loss = 7.0714, entropy=60.7707, time=5.83
Iteration 81: loss = 6.2579, adv_loss = 0.0006, ref_loss = -0.4389, perp_loss = 6.6962, entropy=26.7372, time=6.65
Iteration 91: loss = 6.2633, adv_loss = 0.0734, ref_loss = -0.4416, perp_loss = 6.6315, entropy=13.0535, time=7.47
CLEAN TEXT
Probe Sought on Charges FDA Discredited Whistleblower The head of the Senate Finance Committee called on the US Department of Health and Human Services to launch a probe of allegations that the US Food and Drug Administration went out of its way to discredit a whistleblower.
ADVERSARIAL TEXT
vaindier tow tag Masksional attemptsloading Flintweight turnoutsional tag tag tag swaploaded concurrentlysionalwright contact Flint towjer vain richestjer Hood Nominated tow Mask Mask ok Maskwright wwwyer concurrently promotions Maskurer tow tow Mask Maskjeryer Maskjer attempts circuitjer attempts Mask harness Mask Mask Mask tow tow vainël

CLEAN LOGITS
tensor([[-2.1848, -4.7745,  3.3532,  2.7685]])
ADVERSARIAL LOGITS
tensor([[-3.2027, -3.0679,  0.1766,  5.4273]])
LABEL
1
TEXT
[CLS] Xabi Reckons England Are Great Xabi Alonso is prepared for a hard battle when Spain meet England in the Bernabeu on Wednesday having experienced the build - up from the other side. [SEP]
LOGITS
tensor([[-1.0027,  7.5215, -3.0827, -2.1767]])
Iteration 1: loss = 23.4866, adv_loss = 13.6264, ref_loss = -0.9855, perp_loss = 10.8457, entropy=5.7690, time=0.06
Iteration 11: loss = 19.6452, adv_loss = 9.9358, ref_loss = -0.8939, perp_loss = 10.6034, entropy=23.9755, time=0.68
Iteration 21: loss = 10.8847, adv_loss = 0.0000, ref_loss = -0.2194, perp_loss = 11.1041, entropy=97.7081, time=1.30
Iteration 31: loss = 10.1947, adv_loss = 0.0000, ref_loss = -0.4736, perp_loss = 10.6683, entropy=130.4885, time=1.91
Iteration 41: loss = 10.6569, adv_loss = 0.7915, ref_loss = -0.4975, perp_loss = 10.3629, entropy=124.6140, time=2.53
Iteration 51: loss = 9.2963, adv_loss = 0.0000, ref_loss = -0.5435, perp_loss = 9.8398, entropy=106.0713, time=3.14
Iteration 61: loss = 8.9033, adv_loss = 0.0575, ref_loss = -0.6227, perp_loss = 9.4685, entropy=88.4473, time=3.75
Iteration 71: loss = 8.5807, adv_loss = 0.0000, ref_loss = -0.5988, perp_loss = 9.1795, entropy=63.8366, time=4.37
Iteration 81: loss = 8.3054, adv_loss = 0.0000, ref_loss = -0.6096, perp_loss = 8.9150, entropy=50.5876, time=4.98
Iteration 91: loss = 8.1985, adv_loss = 0.0000, ref_loss = -0.6232, perp_loss = 8.8217, entropy=41.5482, time=5.60
CLEAN TEXT
Xabi Reckons England Are Great Xabi Alonso is prepared for a hard battle when Spain meet England in the Bernabeu on Wednesday having experienced the build - up from the other side.
ADVERSARIAL TEXT
##ppedley Gracieccienne Down Marley Goa X ʻ Oro is pinnedgni a formal Words Mega Doloresnso Borneo Marilynupe vaseaphu onmma havingescu the buildache up from the embarrassing side overlooked

CLEAN LOGITS
tensor([[-1.0027,  7.5215, -3.0827, -2.1767]])
ADVERSARIAL LOGITS
tensor([[ 4.4845,  1.9850, -2.9387, -1.9943]])
LABEL
1
TEXT
[CLS] Australia conquer their final frontier Adam Gilchrist boldly went where no Australian captain since Bill Lawry has gone before at the VCA Stadium in Nagpur yesterday. His team # 39 ; s 342 - run win gave them an invincible 2 - 0 [SEP]
LOGITS
tensor([[-2.0565,  7.6078, -2.5399, -2.1302]])
Iteration 1: loss = 24.5866, adv_loss = 14.5897, ref_loss = -0.9885, perp_loss = 10.9854, entropy=7.8796, time=0.07
Iteration 11: loss = 23.4350, adv_loss = 13.9750, ref_loss = -0.9229, perp_loss = 10.3830, entropy=104.3903, time=0.83
Iteration 21: loss = 11.1778, adv_loss = 0.0647, ref_loss = 0.0252, perp_loss = 11.0878, entropy=299.4271, time=1.59
Iteration 31: loss = 11.1664, adv_loss = 0.0000, ref_loss = 0.1965, perp_loss = 10.9699, entropy=318.3294, time=2.34
Iteration 41: loss = 10.5005, adv_loss = 0.0000, ref_loss = 0.1650, perp_loss = 10.3355, entropy=291.3884, time=3.09
Iteration 51: loss = 9.0656, adv_loss = 0.1136, ref_loss = -0.5448, perp_loss = 9.4968, entropy=210.7797, time=3.84
Iteration 61: loss = 8.4076, adv_loss = 0.2052, ref_loss = -0.7424, perp_loss = 8.9447, entropy=145.5416, time=4.59
Iteration 71: loss = 7.6190, adv_loss = 0.0988, ref_loss = -0.7289, perp_loss = 8.2492, entropy=95.8481, time=5.34
Iteration 81: loss = 7.1514, adv_loss = 0.0000, ref_loss = -0.7636, perp_loss = 7.9151, entropy=72.1016, time=6.09
Iteration 91: loss = 6.9795, adv_loss = 0.0000, ref_loss = -0.7158, perp_loss = 7.6954, entropy=52.7548, time=6.84
CLEAN TEXT
Australia conquer their final frontier Adam Gilchrist boldly went where no Australian captain since Bill Lawry has gone before at the VCA Stadium in Nagpur yesterday. His team # 39 ; s 342 - run win gave them an invincible 2 - 0
ADVERSARIAL TEXT
turnout styled turnout swap Circuitdance circuit swap concurrently tag concurrently concurrently concurrently cylinder concurrentlyloading Mask turnout concurrently concurrentlyreckypeformerpable length compilationomer swapoy swap Bold wrestler Sharp. selections Troy Medal defensevist concurrently assistant hoping Radcliffe Phillips win offence Gwenoy chorusype chorus concurrently Achievement turnout

CLEAN LOGITS
tensor([[-2.0565,  7.6078, -2.5399, -2.1302]])
ADVERSARIAL LOGITS
tensor([[-3.9174, -0.3359, -0.8962,  4.4816]])
LABEL
1
TEXT
[CLS] Tigers # 39 ; challenge : Win out or lose out Satchel Paige said don # 39 ; t look back because something might be gaining on you. Satch was a baseball pitcher, not a football coach. [SEP]
LOGITS
tensor([[-1.9668,  7.3419, -2.1852, -2.2085]])
Iteration 1: loss = 24.3777, adv_loss = 14.3924, ref_loss = -0.9961, perp_loss = 10.9814, entropy=6.3318, time=0.07
Iteration 11: loss = 23.8788, adv_loss = 14.1753, ref_loss = -0.9786, perp_loss = 10.6821, entropy=27.0092, time=0.76
Iteration 21: loss = 10.6556, adv_loss = 0.0000, ref_loss = -0.2875, perp_loss = 10.9432, entropy=107.0949, time=1.44
Iteration 31: loss = 10.4727, adv_loss = 0.0000, ref_loss = -0.2452, perp_loss = 10.7178, entropy=168.5147, time=2.13
Iteration 41: loss = 9.5662, adv_loss = 0.0023, ref_loss = -0.5793, perp_loss = 10.1433, entropy=174.4588, time=2.81
Iteration 51: loss = 8.8307, adv_loss = 0.0000, ref_loss = -0.6846, perp_loss = 9.5153, entropy=154.5869, time=3.49
Iteration 61: loss = 8.0026, adv_loss = 0.0000, ref_loss = -0.6988, perp_loss = 8.7014, entropy=102.7332, time=4.17
Iteration 71: loss = 7.4821, adv_loss = 0.0000, ref_loss = -0.7332, perp_loss = 8.2153, entropy=61.8487, time=4.86
Iteration 81: loss = 7.3169, adv_loss = 0.0000, ref_loss = -0.6178, perp_loss = 7.9348, entropy=41.3540, time=5.54
Iteration 91: loss = 7.0375, adv_loss = 0.0000, ref_loss = -0.7002, perp_loss = 7.7378, entropy=29.9709, time=6.22
CLEAN TEXT
Tigers # 39 ; challenge : Win out or lose out Satchel Paige said don # 39 ; t look back because something might be gaining on you. Satch was a baseball pitcher, not a football coach.
ADVERSARIAL TEXT
concurrently compensateformer crossover concurrently crossover thief promotionsoy tag Mask efficiency crossing concurrently Trial Trial turnout chorus tag tag compensate concurrentlyoy chorus comic comic concurrently compensate comic begoki compensate Punch swap comic motions pitcherumour pump a quarterback coachmarine

CLEAN LOGITS
tensor([[-1.9668,  7.3419, -2.1852, -2.2085]])
ADVERSARIAL LOGITS
tensor([[-3.3481, -2.1234, -0.2306,  5.0984]])
LABEL
0
TEXT
[CLS] New Spasm of Violence Sweeps Iraq, Killing 110 BAGHDAD ( Reuters ) - At least 110 people were killed across Iraq on Sunday in a sharp escalation of violence that saw gun battles, car bombs and bombardments rock the capital. [SEP]
LOGITS
tensor([[ 7.1228, -2.1518, -1.5138, -2.0404]])
Iteration 1: loss = 23.8470, adv_loss = 13.6759, ref_loss = -0.9983, perp_loss = 11.1693, entropy=7.8796, time=0.07
Iteration 11: loss = 23.2671, adv_loss = 13.6229, ref_loss = -0.9720, perp_loss = 10.6161, entropy=81.3339, time=0.83
Iteration 21: loss = 11.0668, adv_loss = 0.0000, ref_loss = -0.2351, perp_loss = 11.3019, entropy=212.8598, time=1.59
Iteration 31: loss = 10.6105, adv_loss = 0.0000, ref_loss = -0.4733, perp_loss = 11.0838, entropy=245.2207, time=2.34
Iteration 41: loss = 10.0051, adv_loss = 0.0994, ref_loss = -0.7276, perp_loss = 10.6333, entropy=241.3534, time=3.09
Iteration 51: loss = 9.6409, adv_loss = 0.0000, ref_loss = -0.7026, perp_loss = 10.3436, entropy=216.8521, time=3.84
Iteration 61: loss = 9.0085, adv_loss = 0.0000, ref_loss = -0.7573, perp_loss = 9.7657, entropy=168.8080, time=4.59
Iteration 71: loss = 8.3009, adv_loss = 0.0000, ref_loss = -0.8175, perp_loss = 9.1184, entropy=109.4595, time=5.34
Iteration 81: loss = 7.8119, adv_loss = 0.0000, ref_loss = -0.7942, perp_loss = 8.6061, entropy=67.0757, time=6.09
Iteration 91: loss = 7.4687, adv_loss = 0.0000, ref_loss = -0.7502, perp_loss = 8.2189, entropy=43.4239, time=6.84
CLEAN TEXT
New Spasm of Violence Sweeps Iraq, Killing 110 BAGHDAD ( Reuters ) - At least 110 people were killed across Iraq on Sunday in a sharp escalation of violence that saw gun battles, car bombs and bombardments rock the capital.
ADVERSARIAL TEXT
tautlionger www comic ego alloy Rourkes Iraq tautrankgable ″sional cometrang manually www Achievement Flint lens Seeing least cent Meijillah Tokugawaqa Yemen PM Islamichyavyn lensyncffington hood Barlow Flintrang Clerk gun vertex vertex richestđ contact Flintyncsham Rockykin Yong

CLEAN LOGITS
tensor([[ 7.1228, -2.1518, -1.5138, -2.0404]])
ADVERSARIAL LOGITS
tensor([[-2.0560, -3.3440, -0.5908,  5.4743]])
LABEL
1
TEXT
[CLS] Devil Rays thumbnails at Fenway Park Records : Boston is 86 - 56 ( second in the AL East ) ; Tampa Bay is 61 - 80 ( fourth in AL East ). Tonight ( 7 : 05, NESN, WEEI ) : LHP Scott Kazmir ( 1 - 1, 5. 62 ) vs. [SEP]
LOGITS
tensor([[-1.8214,  7.5205, -2.5073, -2.2032]])
Iteration 1: loss = 24.2518, adv_loss = 14.3272, ref_loss = -0.9976, perp_loss = 10.9221, entropy=9.9902, time=0.09
Iteration 11: loss = 23.4674, adv_loss = 13.9275, ref_loss = -0.9706, perp_loss = 10.5105, entropy=90.2427, time=0.99
Iteration 21: loss = 20.6964, adv_loss = 11.4242, ref_loss = -0.9455, perp_loss = 10.2177, entropy=174.7794, time=1.89
Iteration 31: loss = 10.2300, adv_loss = 0.0000, ref_loss = -0.5640, perp_loss = 10.7940, entropy=226.1369, time=2.79
Iteration 41: loss = 9.3306, adv_loss = 0.0000, ref_loss = -0.8425, perp_loss = 10.1732, entropy=235.7765, time=3.68
Iteration 51: loss = 9.0481, adv_loss = 0.0000, ref_loss = -0.8477, perp_loss = 9.8959, entropy=235.3172, time=4.57
Iteration 61: loss = 8.3512, adv_loss = 0.0000, ref_loss = -0.8756, perp_loss = 9.2268, entropy=195.5739, time=5.46
Iteration 71: loss = 8.0383, adv_loss = 0.0000, ref_loss = -0.8199, perp_loss = 8.8582, entropy=146.8780, time=6.36
Iteration 81: loss = 7.8179, adv_loss = 0.2535, ref_loss = -0.8568, perp_loss = 8.4213, entropy=104.7863, time=7.25
Iteration 91: loss = 8.5254, adv_loss = 1.1920, ref_loss = -0.8418, perp_loss = 8.1751, entropy=76.2560, time=8.14
CLEAN TEXT
Devil Rays thumbnails at Fenway Park Records : Boston is 86 - 56 ( second in the AL East ) ; Tampa Bay is 61 - 80 ( fourth in AL East ). Tonight ( 7 : 05, NESN, WEEI ) : LHP Scott Kazmir ( 1 - 1, 5. 62 ) vs.
ADVERSARIAL TEXT
Bean Pierceglibbegli fancy Percy Wilde Angelina Beau Records Percy Gracientin punchose Curtis suitedBI grace Peacock Double Scholarsssie Houston punch Carey Marinokovic Primera Apostolic Bureau flu opener Shine Lakshmibulanik Royalphic Lesley sprawling fluBI lashes Few remaining lashesnchen punch ) Rodrigo Cara Bahamas Kingston Cristinaramarine Gracie 1 Curtis Ever Blue 5.CsН Š.

CLEAN LOGITS
tensor([[-1.8214,  7.5205, -2.5073, -2.2032]])
ADVERSARIAL LOGITS
tensor([[ 4.8660,  1.7448, -2.5563, -2.3421]])
LABEL
1
TEXT
[CLS] UPDATE 1 - Australia survive NZ flurry to square series Australia withstood a late flurry of exciting strokeplay from pace bowler Kyle Mills to beat New Zealand by 17 runs in Wednesday # 39 ; s second limited - overs international to square their best - of - three series at 1 - 1. [SEP]
LOGITS
tensor([[-1.9898,  7.5383, -2.6239, -2.1044]])
Iteration 1: loss = 24.2490, adv_loss = 14.5527, ref_loss = -0.9977, perp_loss = 10.6940, entropy=9.0053, time=0.08
Iteration 11: loss = 23.3337, adv_loss = 14.0216, ref_loss = -0.9673, perp_loss = 10.2795, entropy=76.3808, time=0.91
Iteration 21: loss = 22.0111, adv_loss = 12.9548, ref_loss = -0.9176, perp_loss = 9.9739, entropy=233.3673, time=1.73
Iteration 31: loss = 11.2851, adv_loss = 0.0000, ref_loss = 0.1629, perp_loss = 11.1222, entropy=281.0912, time=2.56
Iteration 41: loss = 10.8794, adv_loss = 0.0000, ref_loss = 0.1505, perp_loss = 10.7288, entropy=276.3898, time=3.38
Iteration 51: loss = 9.8103, adv_loss = 0.0000, ref_loss = -0.1574, perp_loss = 9.9677, entropy=205.3651, time=4.20
Iteration 61: loss = 9.0206, adv_loss = 0.0000, ref_loss = -0.3977, perp_loss = 9.4184, entropy=161.6494, time=5.02
Iteration 71: loss = 8.5629, adv_loss = 0.0000, ref_loss = -0.4236, perp_loss = 8.9864, entropy=110.4805, time=5.84
Iteration 81: loss = 7.9470, adv_loss = 0.0000, ref_loss = -0.6528, perp_loss = 8.5998, entropy=78.2459, time=6.66
Iteration 91: loss = 7.6990, adv_loss = 0.0000, ref_loss = -0.7227, perp_loss = 8.4216, entropy=56.3260, time=7.48
CLEAN TEXT
UPDATE 1 - Australia survive NZ flurry to square series Australia withstood a late flurry of exciting strokeplay from pace bowler Kyle Mills to beat New Zealand by 17 runs in Wednesday # 39 ; s second limited - overs international to square their best - of - three series at 1 - 1.
ADVERSARIAL TEXT
##ousDA concurrentlyoy concurrently nomination concurrently Appearance punches Punch refer punchespable Holloway with crossover punches stealing late flurry Born crest earn punch distraction drains bowler Kyle Rap correction Shortreckrankoy tag Report review refer www swap Bold swapvistpable responseliography marker enhancing response attemptou wise Signal concurrentlyokiype effortous voluéreck

CLEAN LOGITS
tensor([[-1.9898,  7.5383, -2.6239, -2.1044]])
ADVERSARIAL LOGITS
tensor([[-4.0367,  0.4838, -1.2155,  4.2491]])
LABEL
0
TEXT
[CLS] Jet lands in UK after bomb alert An Olympic Airlines flight on its way from Athens to New York is diverted to Stansted Airport after a security alert. [SEP]
LOGITS
tensor([[ 6.0452, -2.4227, -1.8176, -0.3573]])
Iteration 1: loss = 21.7502, adv_loss = 11.3005, ref_loss = -0.9938, perp_loss = 11.4435, entropy=4.5026, time=0.06
Iteration 11: loss = 11.0761, adv_loss = 0.0000, ref_loss = -0.1025, perp_loss = 11.1786, entropy=61.3237, time=0.61
Iteration 21: loss = 10.8894, adv_loss = 0.0000, ref_loss = 0.0436, perp_loss = 10.8458, entropy=148.7118, time=1.15
Iteration 31: loss = 10.2116, adv_loss = 0.0000, ref_loss = 0.0568, perp_loss = 10.1547, entropy=172.0139, time=1.70
Iteration 41: loss = 9.3849, adv_loss = 0.0000, ref_loss = -0.0095, perp_loss = 9.3944, entropy=155.5572, time=2.25
Iteration 51: loss = 8.5325, adv_loss = 0.0000, ref_loss = -0.0035, perp_loss = 8.5360, entropy=124.9528, time=2.80
Iteration 61: loss = 7.7615, adv_loss = 0.0000, ref_loss = -0.0141, perp_loss = 7.7756, entropy=73.2917, time=3.35
Iteration 71: loss = 7.1749, adv_loss = 0.0000, ref_loss = -0.0411, perp_loss = 7.2160, entropy=35.1997, time=3.90
Iteration 81: loss = 6.7165, adv_loss = 0.0000, ref_loss = -0.0036, perp_loss = 6.7202, entropy=17.4673, time=4.44
Iteration 91: loss = 6.5433, adv_loss = 0.0000, ref_loss = -0.0202, perp_loss = 6.5635, entropy=9.2219, time=4.99
CLEAN TEXT
Jet lands in UK after bomb alert An Olympic Airlines flight on its way from Athens to New York is diverted to Stansted Airport after a security alert.
ADVERSARIAL TEXT
##sional Mask concurrencyync Mask Flintloadedsional intersectionrangsional Wonsional Won Wonsional Wonficgable Wonsionalsional Mask Wonoom Hood intersection swapsional Won

CLEAN LOGITS
tensor([[ 6.0452, -2.4227, -1.8176, -0.3573]])
ADVERSARIAL LOGITS
tensor([[-2.0107, -3.3584, -0.5005,  5.3559]])
LABEL
1
TEXT
[CLS] USC Fires Basketball Coach Henry Bibby LOS ANGELES - Henry Bibby was fired as Southern California # 39 ; s basketball coach Monday, just four games into his ninth season. The Trojans, beset by some player dissension, are 2 - 2. [SEP]
LOGITS
tensor([[-1.7110,  7.5741, -2.6356, -2.3274]])
Iteration 1: loss = 24.0813, adv_loss = 14.3255, ref_loss = -0.9954, perp_loss = 10.7512, entropy=8.5832, time=0.08
Iteration 11: loss = 23.3233, adv_loss = 13.9257, ref_loss = -0.9583, perp_loss = 10.3559, entropy=60.7024, time=0.89
Iteration 21: loss = 20.7287, adv_loss = 11.2388, ref_loss = -0.7982, perp_loss = 10.2880, entropy=151.9548, time=1.70
Iteration 31: loss = 10.3078, adv_loss = 0.0000, ref_loss = -0.5041, perp_loss = 10.8119, entropy=211.3871, time=2.51
Iteration 41: loss = 9.8195, adv_loss = 0.0000, ref_loss = -0.6486, perp_loss = 10.4681, entropy=239.2760, time=3.32
Iteration 51: loss = 9.3620, adv_loss = 0.1722, ref_loss = -0.7342, perp_loss = 9.9240, entropy=223.0613, time=4.12
Iteration 61: loss = 8.6680, adv_loss = 0.0136, ref_loss = -0.7180, perp_loss = 9.3724, entropy=178.2640, time=4.93
Iteration 71: loss = 8.1254, adv_loss = 0.0180, ref_loss = -0.7741, perp_loss = 8.8816, entropy=135.1739, time=5.74
Iteration 81: loss = 7.8709, adv_loss = 0.0000, ref_loss = -0.7476, perp_loss = 8.6185, entropy=104.3893, time=6.54
Iteration 91: loss = 7.9102, adv_loss = 0.4080, ref_loss = -0.7900, perp_loss = 8.2922, entropy=73.8218, time=7.35
CLEAN TEXT
USC Fires Basketball Coach Henry Bibby LOS ANGELES - Henry Bibby was fired as Southern California # 39 ; s basketball coach Monday, just four games into his ninth season. The Trojans, beset by some player dissension, are 2 - 2.
ADVERSARIAL TEXT
Ritalean overlooked Albaniannji Gracienae Cream Una Ititis ANularnose derivedPM Heidelberg Palm Beatles Mauddela Down penned extended punchuxe punchuxe s basketball diploma Monday punch punch lucky come sore draft 0 Angelina. Wilkins Nobel Gracie Scholars Gracie Eva Curtis Marilynnstßessen Nationale Pauline Down Agatha Ceciliaharine Nancy

CLEAN LOGITS
tensor([[-1.7110,  7.5741, -2.6356, -2.3274]])
ADVERSARIAL LOGITS
tensor([[ 4.9010,  0.4330, -2.8257, -0.9221]])
LABEL
0
TEXT
[CLS] AU Issues Deadline to Khartoum and Darfur Rebels ABUJA ( Reuters ) - The African Union issued a 24 - hour deadline to the Sudanese government and Darfur rebels on Friday to end fighting after a massive military build - up in the region over the last two weeks. [SEP]
LOGITS
tensor([[ 7.1549, -2.1042, -1.5286, -2.1224]])
Iteration 1: loss = 24.0086, adv_loss = 13.6780, ref_loss = -0.9993, perp_loss = 11.3300, entropy=9.1460, time=0.08
Iteration 11: loss = 21.4595, adv_loss = 11.6400, ref_loss = -0.8998, perp_loss = 10.7194, entropy=110.9852, time=0.93
Iteration 21: loss = 11.1319, adv_loss = 0.0000, ref_loss = 0.1215, perp_loss = 11.0104, entropy=220.0869, time=1.78
Iteration 31: loss = 10.9099, adv_loss = 0.7053, ref_loss = -0.3943, perp_loss = 10.5989, entropy=242.3338, time=2.62
Iteration 41: loss = 9.7702, adv_loss = 0.1190, ref_loss = -0.5307, perp_loss = 10.1819, entropy=251.9188, time=3.46
Iteration 51: loss = 9.0463, adv_loss = 0.0000, ref_loss = -0.6709, perp_loss = 9.7172, entropy=229.7835, time=4.31
Iteration 61: loss = 8.7515, adv_loss = 0.1232, ref_loss = -0.6531, perp_loss = 9.2814, entropy=182.8830, time=5.15
Iteration 71: loss = 8.1184, adv_loss = 0.0000, ref_loss = -0.7194, perp_loss = 8.8378, entropy=129.3166, time=5.99
Iteration 81: loss = 7.6842, adv_loss = 0.0000, ref_loss = -0.6905, perp_loss = 8.3747, entropy=85.6110, time=6.84
Iteration 91: loss = 7.4488, adv_loss = 0.0000, ref_loss = -0.6942, perp_loss = 8.1429, entropy=66.9053, time=7.68
CLEAN TEXT
AU Issues Deadline to Khartoum and Darfur Rebels ABUJA ( Reuters ) - The African Union issued a 24 - hour deadline to the Sudanese government and Darfur rebels on Friday to end fighting after a massive military build - up in the region over the last two weeks.
ADVERSARIAL TEXT
Percyilde Salford successors signatureerus Freddie PercymKO swellingFA signaturenesia JoelFAJFAFA abbreviated clock Doubleilde TheFA omitted issued abbreviatedFAbula positive Cristina to oath 1755ese government Clock slipsgli relaxation cumnesia Gracieệuxe EasternFAFAwritten notchuxe Double soreFA Beau Royal strict surname Curtis Scholars time Penn

CLEAN LOGITS
tensor([[ 7.1549, -2.1042, -1.5286, -2.1224]])
ADVERSARIAL LOGITS
tensor([[ 1.2974,  6.2432, -3.1138, -2.8466]])
LABEL
2
TEXT
[CLS] Cisco # 39 ; s Q1 Profit Leaps 29 Percent Cisco Systems has reported first - quarter profits of \ $ 1. 4 on sales of \ $ 6 billion. Despite cautious spending by its corporate customers, softness in the global economy and a lingering uncertainty over whether [SEP]
LOGITS
tensor([[-3.8955, -4.3502,  3.1161,  3.9913]])
Iteration 1: loss = 14.1255, adv_loss = 4.3895, ref_loss = -0.9965, perp_loss = 10.7325, entropy=8.4424, time=0.08
Iteration 11: loss = 11.0739, adv_loss = 1.1795, ref_loss = -0.9112, perp_loss = 10.8056, entropy=68.5164, time=0.88
Iteration 21: loss = 9.8112, adv_loss = 0.0053, ref_loss = -0.8410, perp_loss = 10.6469, entropy=176.0927, time=1.69
Iteration 31: loss = 9.1260, adv_loss = 0.0000, ref_loss = -0.8410, perp_loss = 9.9671, entropy=231.5849, time=2.49
Iteration 41: loss = 8.4884, adv_loss = 0.0424, ref_loss = -0.8477, perp_loss = 9.2938, entropy=231.4568, time=3.29
Iteration 51: loss = 7.7636, adv_loss = 0.0000, ref_loss = -0.8217, perp_loss = 8.5853, entropy=211.2431, time=4.09
Iteration 61: loss = 7.0463, adv_loss = 0.0210, ref_loss = -0.8233, perp_loss = 7.8486, entropy=133.1727, time=4.89
Iteration 71: loss = 6.6629, adv_loss = 0.1054, ref_loss = -0.8071, perp_loss = 7.3646, entropy=72.0063, time=5.69
Iteration 81: loss = 6.2165, adv_loss = 0.0000, ref_loss = -0.8173, perp_loss = 7.0338, entropy=40.8497, time=6.49
Iteration 91: loss = 6.0459, adv_loss = 0.0071, ref_loss = -0.8243, perp_loss = 6.8631, entropy=25.9697, time=7.29
CLEAN TEXT
Cisco # 39 ; s Q1 Profit Leaps 29 Percent Cisco Systems has reported first - quarter profits of \ $ 1. 4 on sales of \ $ 6 billion. Despite cautious spending by its corporate customers, softness in the global economy and a lingering uncertainty over whether
ADVERSARIAL TEXT
vain Maskloading Mask Mask Mask harnessloading attempts attemptsync Mask Mask Maskloaded Bold header www tag swap gang attemptsweightyer comicaper Maskweight attempts Nominated vain compensaterankformerweightyer quartervic vainweight salesman attemptsyer dealer progress, earnings bosshoe attempts richest economy quarterrank vain pen Mask Mask

CLEAN LOGITS
tensor([[-3.8955, -4.3502,  3.1161,  3.9913]])
ADVERSARIAL LOGITS
tensor([[-3.4403, -3.3129,  0.6528,  5.3470]])
LABEL
3
TEXT
[CLS] McData offers SAN consolidation McData plans to introduce a new SAN router this week designed to connect the growing number of isolated SAN networks in corporations. & lt ; p & gt ; ADVERTISEMENT & lt ; / p & gt ; & lt ; p & gt ; & lt ; img src = " http : / / ad. doubleclick. net / ad / idg. us. ifw. general / sbcspotrssfeed ; sz = 1x1 ; ord = 200301151450? " width = " 1 " height = " 1 " border = " 0 " / & gt ; & lt ; a href = " http : / / ad. doubleclick. net / clk ; 9228975 ; 9651165 ; a? http : / / www. infoworld. com / spotlights / sbc / main. html? lpid0103035400730000idlp " & gt ; SBC Case Study : Crate Barrel & lt ; / a & gt ; & lt ; [SEP]
LOGITS
tensor([[-3.7824, -3.1677,  1.0160,  5.1017]])
Iteration 1: loss = 19.1049, adv_loss = 9.1151, ref_loss = -0.9981, perp_loss = 10.9879, entropy=36.0211, time=0.27
Iteration 11: loss = 18.0424, adv_loss = 8.1777, ref_loss = -0.9666, perp_loss = 10.8313, entropy=192.9343, time=3.03
Iteration 21: loss = 9.9508, adv_loss = 0.0661, ref_loss = -0.8403, perp_loss = 10.7250, entropy=443.1228, time=5.78
Iteration 31: loss = 9.6431, adv_loss = 0.0000, ref_loss = -0.8702, perp_loss = 10.5134, entropy=635.6525, time=8.51
Iteration 41: loss = 9.0954, adv_loss = 0.0133, ref_loss = -0.9116, perp_loss = 9.9937, entropy=773.2130, time=11.23
Iteration 51: loss = 8.3905, adv_loss = 0.0000, ref_loss = -0.9046, perp_loss = 9.2951, entropy=757.3611, time=13.96
Iteration 61: loss = 7.6495, adv_loss = 0.0000, ref_loss = -0.8976, perp_loss = 8.5471, entropy=595.7054, time=16.69
Iteration 71: loss = 7.0971, adv_loss = 0.0224, ref_loss = -0.8905, perp_loss = 7.9652, entropy=377.7002, time=19.41
Iteration 81: loss = 6.7638, adv_loss = 0.0000, ref_loss = -0.8851, perp_loss = 7.6489, entropy=252.6855, time=22.14
Iteration 91: loss = 6.4643, adv_loss = 0.0226, ref_loss = -0.9032, perp_loss = 7.3448, entropy=171.9573, time=24.87
CLEAN TEXT
McData offers SAN consolidation McData plans to introduce a new SAN router this week designed to connect the growing number of isolated SAN networks in corporations. & lt ; p & gt ; ADVERTISEMENT & lt ; / p & gt ; & lt ; p & gt ; & lt ; img src = " http : / / ad. doubleclick. net / ad / idg. us. ifw. general / sbcspotrssfeed ; sz = 1x1 ; ord = 200301151450? " width = " 1 " height = " 1 " border = " 0 " / & gt ; & lt ; a href = " http : / / ad. doubleclick. net / clk ; 9228975 ; 9651165 ; a? http : / / www. infoworld. com / spotlights / sbc / main. html? lpid0103035400730000idlp " & gt ; SBC Case Study : Crate Barrel & lt ; / a & gt ; & lt ;
ADVERSARIAL TEXT
##lumber performer Boss microphone Boss sum Runner employs blacksmithax circuitmel employ Boss introduce circuit employ harness safety ¢ boxer boxer inventor italics boxer inventor boxer inventor Bold Bold Bold Bold blacksmith bargain vainloaded italics blacksmithweighterativeficvicwrightformerweightficwrightweight bondwrightakerwrightformerficweight Boss Makes Makesweight Weight blacksmithwrightweightweightyerficweight blacksmithfall bidmerweight employsmillharfharfwrightrupwright bid engagedjererativeudgeerativeright Buck. cereal Broslumberpar summaryaper labor not Carlumberirk Castro. Burteley. Millwright robinweight bondpotwrightparparweightvirwright labor bond carpenterwrightweight blacksmith willingnessweight willingness 2003weight bargainvir labor diver Makesweight blacksmith inventor blacksmith blacksmith Weight inventor blacksmith blacksmithweight engages blacksmith Makes blacksmithweight Makesweight inventor blacksmith Makes blacksmitherative Boss bidpar Boss sumfyer engaged effort finances verb bid Katzak laborrup summarymillset summarywrightptonquestfeldEIweight shareholderspar winteriti cash operatorzar Castro summary Guo engaged robinssel overhaul quick summary Continuingbark com continuing sum strugglesrup sb expansion / expandedlormer? profityrpar0sselplied robinftpar30weight0parwrightfiteleypar bidened robinistan taxes finances doubledsignrup declining Brewster retail industries laborparydroquest robinmer furwrightzervirweight laborudge

CLEAN LOGITS
tensor([[-3.7824, -3.1677,  1.0160,  5.1017]])
ADVERSARIAL LOGITS
tensor([[-2.9933, -4.0750,  5.4050,  0.5397]])
LABEL
1
TEXT
[CLS] Fleisher Surges Clear Bruce Fleisher carded a seven - under - par 65 to take a three - shot lead after the second round of the Greater Hickory Classic in North Carolina. [SEP]
LOGITS
tensor([[-1.3822,  7.6127, -2.9368, -2.1718]])
Iteration 1: loss = 24.3094, adv_loss = 14.0232, ref_loss = -0.9934, perp_loss = 11.2796, entropy=6.3318, time=0.07
Iteration 11: loss = 23.5541, adv_loss = 13.8331, ref_loss = -0.9155, perp_loss = 10.6365, entropy=49.2764, time=0.76
Iteration 21: loss = 21.8733, adv_loss = 12.4398, ref_loss = -0.8374, perp_loss = 10.2709, entropy=118.6002, time=1.45
Iteration 31: loss = 10.5695, adv_loss = 0.0000, ref_loss = -0.4025, perp_loss = 10.9720, entropy=167.2896, time=2.13
Iteration 41: loss = 9.9584, adv_loss = 0.0000, ref_loss = -0.6203, perp_loss = 10.5787, entropy=179.1412, time=2.82
Iteration 51: loss = 9.4594, adv_loss = 0.0000, ref_loss = -0.5978, perp_loss = 10.0572, entropy=164.7707, time=3.50
Iteration 61: loss = 9.0528, adv_loss = 0.1881, ref_loss = -0.6640, perp_loss = 9.5287, entropy=117.1563, time=4.18
Iteration 71: loss = 8.4900, adv_loss = 0.0000, ref_loss = -0.6336, perp_loss = 9.1235, entropy=95.5350, time=4.87
Iteration 81: loss = 8.1379, adv_loss = 0.0000, ref_loss = -0.6735, perp_loss = 8.8115, entropy=69.5176, time=5.55
Iteration 91: loss = 8.1227, adv_loss = 0.0000, ref_loss = -0.5673, perp_loss = 8.6900, entropy=55.5797, time=6.23
CLEAN TEXT
Fleisher Surges Clear Bruce Fleisher carded a seven - under - par 65 to take a three - shot lead after the second round of the Greater Hickory Classic in North Carolina.
ADVERSARIAL TEXT
derived Butterfly Downntin Ceciliatius Marilyn Reginald Rodrigo celebritiespent Nobel Till Nobel Una Olga Hillary Hague - immunity Pepper Curtismile punch XIII'shotyuan acclaimedkovic second best of Ivy Marpiesrseolin Classic in Lana Carolinabula

CLEAN LOGITS
tensor([[-1.3822,  7.6127, -2.9368, -2.1718]])
ADVERSARIAL LOGITS
tensor([[ 4.7128,  1.4737, -3.0763, -1.2335]])
LABEL
2
TEXT
[CLS] SEC Charges Hollinger's Black with Fraud ( Reuters ) Reuters - U. S. regulators filed fraud charges \ on Monday against former Hollinger International Inc. \ Chairman Conrad Black and his deputy, David Radler, moving to \ bar the two from serving as officers of a public company. [SEP]
LOGITS
tensor([[ 0.2130, -4.9076,  4.7098, -1.0079]])
Iteration 1: loss = 19.1125, adv_loss = 9.6862, ref_loss = -0.9844, perp_loss = 10.4107, entropy=9.5681, time=0.08
Iteration 11: loss = 17.6646, adv_loss = 8.3631, ref_loss = -0.9430, perp_loss = 10.2445, entropy=46.1332, time=0.95
Iteration 21: loss = 10.9068, adv_loss = 0.0000, ref_loss = -0.4003, perp_loss = 11.3071, entropy=143.2967, time=1.82
Iteration 31: loss = 10.7346, adv_loss = 0.2135, ref_loss = -0.4881, perp_loss = 11.0091, entropy=181.0055, time=2.69
Iteration 41: loss = 9.9430, adv_loss = 0.0798, ref_loss = -0.6373, perp_loss = 10.5005, entropy=183.7730, time=3.55
Iteration 51: loss = 9.3627, adv_loss = 0.0000, ref_loss = -0.6793, perp_loss = 10.0420, entropy=181.0395, time=4.41
Iteration 61: loss = 8.9530, adv_loss = 0.0938, ref_loss = -0.6966, perp_loss = 9.5558, entropy=155.3430, time=5.28
Iteration 71: loss = 8.5110, adv_loss = 0.0000, ref_loss = -0.6816, perp_loss = 9.1926, entropy=114.1847, time=6.14
Iteration 81: loss = 8.3408, adv_loss = 0.0000, ref_loss = -0.6240, perp_loss = 8.9647, entropy=92.4378, time=7.00
Iteration 91: loss = 8.0336, adv_loss = 0.0000, ref_loss = -0.6066, perp_loss = 8.6402, entropy=62.1261, time=7.87
CLEAN TEXT
SEC Charges Hollinger's Black with Fraud ( Reuters ) Reuters - U. S. regulators filed fraud charges \ on Monday against former Hollinger International Inc. \ Chairman Conrad Black and his deputy, David Radler, moving to \ bar the two from serving as officers of a public company.
ADVERSARIAL TEXT
ʻ Brennans Everllinger bread s Basel with drugs mud Paveldh Hague ) Graf Patel - Cheryl imºpts sanctionsgno Gerhardbiotains Ravi on Hague againstḳchanllinger International institutionalanu AugustineĽ Stephan Kuala and evangelical Highnessstan UAE Lankandler deposeddesturnảfen Guru reforms ʻdh Pavel ʻelaces Highness Christi grip

CLEAN LOGITS
tensor([[ 0.2130, -4.9076,  4.7098, -1.0079]])
ADVERSARIAL LOGITS
tensor([[ 5.0332, -2.9605,  0.4201, -1.2265]])
LABEL
2
TEXT
[CLS] Stocks in Motion : Claire # 39 ; s Shares of Claire # 39 ; s Stores ( CLE : NYSE - news - research ) were among the NYSE # 39 ; s losers Thursday, falling 15 after the company posted third - quarter results that missed analysts # 39 ; expectations and warning about the fourth quarter. [SEP]
LOGITS
tensor([[-0.7876, -3.8255,  5.4646, -2.1254]])
Iteration 1: loss = 21.2988, adv_loss = 11.3386, ref_loss = -0.9971, perp_loss = 10.9573, entropy=9.8495, time=0.09
Iteration 11: loss = 20.4525, adv_loss = 10.8547, ref_loss = -0.9701, perp_loss = 10.5679, entropy=86.3588, time=0.96
Iteration 21: loss = 11.4622, adv_loss = 0.0000, ref_loss = 0.1535, perp_loss = 11.3087, entropy=213.5006, time=1.84
Iteration 31: loss = 11.0698, adv_loss = 0.0000, ref_loss = 0.1728, perp_loss = 10.8970, entropy=268.0562, time=2.71
Iteration 41: loss = 10.3065, adv_loss = 0.0000, ref_loss = 0.1471, perp_loss = 10.1594, entropy=266.0259, time=3.58
Iteration 51: loss = 9.2998, adv_loss = 0.0000, ref_loss = 0.0614, perp_loss = 9.2383, entropy=224.2166, time=4.45
Iteration 61: loss = 8.6745, adv_loss = 0.0992, ref_loss = -0.0824, perp_loss = 8.6576, entropy=176.3652, time=5.33
Iteration 71: loss = 8.2498, adv_loss = 0.0000, ref_loss = 0.0094, perp_loss = 8.2404, entropy=131.7151, time=6.20
Iteration 81: loss = 7.8371, adv_loss = 0.0484, ref_loss = -0.0991, perp_loss = 7.8878, entropy=85.8173, time=7.07
Iteration 91: loss = 7.7397, adv_loss = 0.3219, ref_loss = -0.2221, perp_loss = 7.6399, entropy=54.1427, time=7.94
CLEAN TEXT
Stocks in Motion : Claire # 39 ; s Shares of Claire # 39 ; s Stores ( CLE : NYSE - news - research ) were among the NYSE # 39 ; s losers Thursday, falling 15 after the company posted third - quarter results that missed analysts # 39 ; expectations and warning about the fourth quarter.
ADVERSARIAL TEXT
Sinowami renovatedwamiwamigro Evangelical complexes NGO Dubai Evangelicalphereristo of Sino HagueristokelΚ MacKenzie HagueckerwamiΚwamigroΚ Jubilee Colombo Dhakaugs mudfell HagueΚ GulfOH Penangitis Hague Colombo Fathers Geneva Albuquerque Kuala Kuala Hague Physicians Kuala Haguember HaguewamidesckercumČ UAE Kuala Colombo valuesdden Kuala coated slippery Colombo Penangpher

CLEAN LOGITS
tensor([[-0.7876, -3.8255,  5.4646, -2.1254]])
ADVERSARIAL LOGITS
tensor([[ 5.8290, -1.9679, -0.7738, -1.5967]])
LABEL
1
TEXT
[CLS] Carter finishes fourth in 400 hurdles James Carter of Baltimore finished fourth in the finals of the 400 - meter hurdles today, missing out on a medal. Felix Sanchez, of the Dominican Republic, won the gold medal. [SEP]
LOGITS
tensor([[-1.0263,  7.6208, -2.9711, -2.3881]])
Iteration 1: loss = 23.4743, adv_loss = 13.6967, ref_loss = -0.9979, perp_loss = 10.7756, entropy=6.1911, time=0.06
Iteration 11: loss = 23.0133, adv_loss = 13.5453, ref_loss = -0.9750, perp_loss = 10.4431, entropy=38.0128, time=0.70
Iteration 21: loss = 21.2926, adv_loss = 11.9365, ref_loss = -0.9131, perp_loss = 10.2692, entropy=86.7867, time=1.34
Iteration 31: loss = 10.9923, adv_loss = 0.0000, ref_loss = -0.0989, perp_loss = 11.0912, entropy=158.6627, time=1.97
Iteration 41: loss = 10.4373, adv_loss = 0.5098, ref_loss = -0.4855, perp_loss = 10.4130, entropy=186.6087, time=2.61
Iteration 51: loss = 9.9837, adv_loss = 0.3152, ref_loss = -0.4497, perp_loss = 10.1182, entropy=182.1788, time=3.24
Iteration 61: loss = 9.0924, adv_loss = 0.0000, ref_loss = -0.5125, perp_loss = 9.6049, entropy=143.0163, time=3.87
Iteration 71: loss = 8.5301, adv_loss = 0.0316, ref_loss = -0.5397, perp_loss = 9.0381, entropy=93.0270, time=4.50
Iteration 81: loss = 8.1165, adv_loss = 0.0000, ref_loss = -0.4902, perp_loss = 8.6066, entropy=62.4935, time=5.14
Iteration 91: loss = 7.7768, adv_loss = 0.1291, ref_loss = -0.5778, perp_loss = 8.2255, entropy=36.4993, time=5.77
CLEAN TEXT
Carter finishes fourth in 400 hurdles James Carter of Baltimore finished fourth in the finals of the 400 - meter hurdles today, missing out on a medal. Felix Sanchez, of the Dominican Republic, won the gold medal.
ADVERSARIAL TEXT
##nea Gracie fourthpf blank Antrimnea Gracieuil Gracie Gracie punchni Una nose knot citation obituaryille Nobel Elaine Heidelbergße Pius out contaminated a gramslace Pius Gracie punch Etonểziaraphyuses Singles Marilyn Gracie Mayo Palm

CLEAN LOGITS
tensor([[-1.0263,  7.6208, -2.9711, -2.3881]])
ADVERSARIAL LOGITS
tensor([[ 4.4658,  2.7343, -3.0274, -2.3606]])
LABEL
2
TEXT
[CLS] Farallon to Sell \ $ 16. 3 Million in Stock Canadian mining firm Farallon Resources Ltd. on Wednesday said it agreed to privately sell about \ $ 20 million Canadian ( \ $ 16. 3 million ) worth of stock to accredited investors and company insiders. [SEP]
LOGITS
tensor([[-0.9438, -4.1802,  5.4992, -1.4770]])
Iteration 1: loss = 21.1770, adv_loss = 11.4487, ref_loss = -0.9963, perp_loss = 10.7246, entropy=8.1610, time=0.08
Iteration 11: loss = 19.9515, adv_loss = 10.4629, ref_loss = -0.9412, perp_loss = 10.4298, entropy=59.3293, time=0.87
Iteration 21: loss = 13.1339, adv_loss = 2.5264, ref_loss = -0.3562, perp_loss = 10.9637, entropy=144.4454, time=1.67
Iteration 31: loss = 11.1323, adv_loss = 0.0000, ref_loss = 0.0339, perp_loss = 11.0985, entropy=202.6599, time=2.46
Iteration 41: loss = 10.4340, adv_loss = 0.0000, ref_loss = -0.1718, perp_loss = 10.6058, entropy=211.7092, time=3.25
Iteration 51: loss = 9.7645, adv_loss = 0.0144, ref_loss = -0.2969, perp_loss = 10.0470, entropy=193.4608, time=4.04
Iteration 61: loss = 9.1644, adv_loss = 0.0000, ref_loss = -0.2945, perp_loss = 9.4588, entropy=153.1423, time=4.83
Iteration 71: loss = 8.4315, adv_loss = 0.0089, ref_loss = -0.3671, perp_loss = 8.7897, entropy=103.2291, time=5.62
Iteration 81: loss = 8.1314, adv_loss = 0.0000, ref_loss = -0.3222, perp_loss = 8.4536, entropy=67.6053, time=6.42
Iteration 91: loss = 7.7739, adv_loss = 0.0000, ref_loss = -0.4241, perp_loss = 8.1980, entropy=52.4054, time=7.21
CLEAN TEXT
Farallon to Sell \ $ 16. 3 Million in Stock Canadian mining firm Farallon Resources Ltd. on Wednesday said it agreed to privately sell about \ $ 20 million Canadian ( \ $ 16. 3 million ) worth of stock to accredited investors and company insiders.
ADVERSARIAL TEXT
potassium Saudi Kamalatusckerdden Saudi wheelchairpherkel Doctorate Adolfpher DOSuriongade firm sugar InternationaleΚwamismosath on Kualadden ʻcenscens Paulafscker gramsrned towardsmpushales Kuala Hague Tito Indo Lankan Tito Cobranged Medical of finds stridesglia investors sick Tito Highnessscent.

CLEAN LOGITS
tensor([[-0.9438, -4.1802,  5.4992, -1.4770]])
ADVERSARIAL LOGITS
tensor([[ 6.1817, -2.3219, -0.8169, -1.5430]])
LABEL
3
TEXT
[CLS] # 39 ; Kind of a creepy thing # 39 ; : Clues to human origins turn up in head & lt ; b & gt ;... & lt ; / b & gt ; Lice genes have been a head - scratcher for experts in human origins who now suspect that we humans picked up some parasites from our more primitive ancestors. [SEP]
LOGITS
tensor([[-3.2528, -2.0567, -0.3603,  5.3479]])
Iteration 1: loss = 20.8185, adv_loss = 10.6799, ref_loss = -0.9921, perp_loss = 11.1307, entropy=10.9752, time=0.09
Iteration 11: loss = 19.4028, adv_loss = 9.4813, ref_loss = -0.8868, perp_loss = 10.8084, entropy=113.2129, time=1.04
Iteration 21: loss = 10.6007, adv_loss = 0.0000, ref_loss = -0.0961, perp_loss = 10.6968, entropy=219.1237, time=1.99
Iteration 31: loss = 9.8888, adv_loss = 0.0000, ref_loss = -0.3693, perp_loss = 10.2582, entropy=262.2462, time=2.93
Iteration 41: loss = 9.4731, adv_loss = 0.0000, ref_loss = -0.4330, perp_loss = 9.9061, entropy=268.1317, time=3.88
Iteration 51: loss = 8.9393, adv_loss = 0.0000, ref_loss = -0.4976, perp_loss = 9.4369, entropy=249.7944, time=4.82
Iteration 61: loss = 8.3454, adv_loss = 0.0439, ref_loss = -0.5759, perp_loss = 8.8773, entropy=202.7703, time=5.76
Iteration 71: loss = 7.7327, adv_loss = 0.0000, ref_loss = -0.5372, perp_loss = 8.2698, entropy=138.7687, time=6.70
Iteration 81: loss = 7.3539, adv_loss = 0.0000, ref_loss = -0.5561, perp_loss = 7.9100, entropy=89.3055, time=7.65
Iteration 91: loss = 7.1641, adv_loss = 0.1042, ref_loss = -0.5887, perp_loss = 7.6486, entropy=65.2695, time=8.59
CLEAN TEXT
# 39 ; Kind of a creepy thing # 39 ; : Clues to human origins turn up in head & lt ; b & gt ;... & lt ; / b & gt ; Lice genes have been a head - scratcher for experts in human origins who now suspect that we humans picked up some parasites from our more primitive ancestors.
ADVERSARIAL TEXT
Rapid bond earningiza plans gross treasury Buy overhaulios attempted engages broadficlying summary cleverizagoing summaryf Growing goods Revivalpetfarivirficmer boss goal vainudge verbpet doll contractinglumber raised shop carpenter braperent directorce cereal attemptficficaving attemptsierronzer lawyer din bargainrupformerwrightficsightficputfic attempt engagedwrightpar attemptsizaier labor cereallumber

CLEAN LOGITS
tensor([[-3.2528, -2.0567, -0.3603,  5.3479]])
ADVERSARIAL LOGITS
tensor([[-1.7790, -4.4489,  5.5364, -0.2586]])
LABEL
2
TEXT
[CLS] British industry at best in 10 years Manufacturing industry is enjoying its strongest performance for almost 10 years, according to a survey by the Engineering Employers Federation. [SEP]
LOGITS
tensor([[-0.7404, -4.2664,  4.3116,  0.6814]])
Iteration 1: loss = 18.3851, adv_loss = 9.2606, ref_loss = -0.9931, perp_loss = 10.1176, entropy=4.7841, time=0.06
Iteration 11: loss = 12.0520, adv_loss = 1.6551, ref_loss = -0.6361, perp_loss = 11.0330, entropy=25.4835, time=0.64
Iteration 21: loss = 10.8316, adv_loss = 0.0000, ref_loss = -0.3087, perp_loss = 11.1404, entropy=79.0394, time=1.22
Iteration 31: loss = 10.2478, adv_loss = 0.0000, ref_loss = -0.2759, perp_loss = 10.5237, entropy=113.9077, time=1.79
Iteration 41: loss = 9.4636, adv_loss = 0.0000, ref_loss = -0.2894, perp_loss = 9.7531, entropy=131.9231, time=2.37
Iteration 51: loss = 8.5865, adv_loss = 0.0000, ref_loss = -0.2554, perp_loss = 8.8419, entropy=122.0567, time=2.95
Iteration 61: loss = 7.6582, adv_loss = 0.0000, ref_loss = -0.2365, perp_loss = 7.8947, entropy=72.4655, time=3.52
Iteration 71: loss = 7.0115, adv_loss = 0.0000, ref_loss = -0.2578, perp_loss = 7.2693, entropy=32.0005, time=4.10
Iteration 81: loss = 6.7343, adv_loss = 0.0000, ref_loss = -0.2661, perp_loss = 7.0003, entropy=13.2068, time=4.68
Iteration 91: loss = 6.6233, adv_loss = 0.0000, ref_loss = -0.2662, perp_loss = 6.8896, entropy=9.3233, time=5.25
CLEAN TEXT
British industry at best in 10 years Manufacturing industry is enjoying its strongest performance for almost 10 years, according to a survey by the Engineering Employers Federation.
ADVERSARIAL TEXT
auto Mask verticesloaded attempts tow efficiency www attempts attempts attempting intersectionhoeweight attempts intersectionweight intersectionsionalsional concurrently concurrently Flintdier efficiency volsionalitive intersectionsional concurrently www

CLEAN LOGITS
tensor([[-0.7404, -4.2664,  4.3116,  0.6814]])
ADVERSARIAL LOGITS
tensor([[-2.6469, -3.3484, -0.0699,  5.5039]])
LABEL
0
TEXT
[CLS] Pakistan arrests key Al - Qaeda operative ( AFP ) AFP - Pakistani security forces have arrested a key Al - Qaeda operative wanted in connection with attacks on Christian targets and a failed bid to kill President Pervez Musharraf, an official said. [SEP]
LOGITS
tensor([[ 7.0916, -2.5372, -1.8318, -1.4927]])
Iteration 1: loss = 24.1053, adv_loss = 13.5880, ref_loss = -0.9994, perp_loss = 11.5167, entropy=7.4575, time=0.07
Iteration 11: loss = 22.2578, adv_loss = 12.4357, ref_loss = -0.9484, perp_loss = 10.7705, entropy=126.0582, time=0.81
Iteration 21: loss = 10.9695, adv_loss = 0.0000, ref_loss = -0.1493, perp_loss = 11.1187, entropy=260.4991, time=1.55
Iteration 31: loss = 10.2199, adv_loss = 0.0000, ref_loss = -0.4423, perp_loss = 10.6622, entropy=287.0720, time=2.28
Iteration 41: loss = 9.3854, adv_loss = 0.0000, ref_loss = -0.6640, perp_loss = 10.0495, entropy=258.1249, time=3.01
Iteration 51: loss = 8.7084, adv_loss = 0.0000, ref_loss = -0.6634, perp_loss = 9.3718, entropy=196.8508, time=3.75
Iteration 61: loss = 8.0241, adv_loss = 0.0000, ref_loss = -0.7588, perp_loss = 8.7830, entropy=132.4901, time=4.48
Iteration 71: loss = 7.6271, adv_loss = 0.0000, ref_loss = -0.7139, perp_loss = 8.3410, entropy=87.4800, time=5.21
Iteration 81: loss = 7.2293, adv_loss = 0.0000, ref_loss = -0.7968, perp_loss = 8.0261, entropy=55.8604, time=5.95
Iteration 91: loss = 6.8545, adv_loss = 0.0000, ref_loss = -0.7327, perp_loss = 7.5872, entropy=33.0044, time=6.68
CLEAN TEXT
Pakistan arrests key Al - Qaeda operative ( AFP ) AFP - Pakistani security forces have arrested a key Al - Qaeda operative wanted in connection with attacks on Christian targets and a failed bid to kill President Pervez Musharraf, an official said.
ADVERSARIAL TEXT
Turboweight Metacriticalssional vainloaded vainloadedyer contact tow convey Yongmiya penël auto vainsionalloadedaper comicloaded Using Mask comic referaperaper cartapersionalël wwwaper penffington vain pen penriz Abudek Taliban Taliban → Duo willingly topped Yong

CLEAN LOGITS
tensor([[ 7.0916, -2.5372, -1.8318, -1.4927]])
ADVERSARIAL LOGITS
tensor([[-2.4677, -3.5276, -0.2384,  5.5217]])
LABEL
1
TEXT
[CLS] Manchester United the only team for me, says Rooney Teenage striker Wayne Rooney says Manchester United were the only team he wanted to join once they he knew the club were interested in him. [SEP]
LOGITS
tensor([[-1.3070,  7.6166, -2.7429, -2.3980]])
Iteration 1: loss = 23.5910, adv_loss = 13.9767, ref_loss = -0.9936, perp_loss = 10.6078, entropy=5.3469, time=0.06
Iteration 11: loss = 23.0159, adv_loss = 13.6094, ref_loss = -0.9774, perp_loss = 10.3840, entropy=25.8056, time=0.66
Iteration 21: loss = 15.4177, adv_loss = 5.9185, ref_loss = -0.8349, perp_loss = 10.3342, entropy=67.1614, time=1.26
Iteration 31: loss = 9.9996, adv_loss = 0.0016, ref_loss = -0.5605, perp_loss = 10.5585, entropy=102.4551, time=1.86
Iteration 41: loss = 9.5047, adv_loss = 0.0000, ref_loss = -0.6781, perp_loss = 10.1828, entropy=108.6775, time=2.45
Iteration 51: loss = 9.1272, adv_loss = 0.0000, ref_loss = -0.7123, perp_loss = 9.8394, entropy=110.2882, time=3.05
Iteration 61: loss = 8.8558, adv_loss = 0.1331, ref_loss = -0.7341, perp_loss = 9.4568, entropy=97.9392, time=3.65
Iteration 71: loss = 9.6244, adv_loss = 1.1437, ref_loss = -0.7287, perp_loss = 9.2093, entropy=69.2057, time=4.24
Iteration 81: loss = 8.2581, adv_loss = 0.1688, ref_loss = -0.7625, perp_loss = 8.8518, entropy=53.3166, time=4.84
Iteration 91: loss = 7.9017, adv_loss = 0.0000, ref_loss = -0.6985, perp_loss = 8.6002, entropy=37.4466, time=5.44
CLEAN TEXT
Manchester United the only team for me, says Rooney Teenage striker Wayne Rooney says Manchester United were the only team he wanted to join once they he knew the club were interested in him.
ADVERSARIAL TEXT
Lenin Fiji thenik best punch Unandy says Downescu penaltiescrates Rooney Witness Braziliankovic sanctions Alfredo punch giantsnik Nobel penetrate Lotus punch improvised he knewh club punch names xssie.

CLEAN LOGITS
tensor([[-1.3070,  7.6166, -2.7429, -2.3980]])
ADVERSARIAL LOGITS
tensor([[ 5.5402,  0.1206, -2.4733, -1.7256]])
LABEL
0
TEXT
[CLS] China's inflation rate slows sharply but problems remain ( AFP ) AFP - China's inflation rate eased sharply in October as government efforts to cool the economy began to really bite, with food prices, one of the main culprits, showing some signs of slowing, official data showed. [SEP]
LOGITS
tensor([[ 2.8601, -4.1165,  3.2645, -1.9986]])
Iteration 1: loss = 14.6473, adv_loss = 5.0882, ref_loss = -0.9943, perp_loss = 10.5534, entropy=9.0053, time=0.08
Iteration 11: loss = 11.2143, adv_loss = 1.8586, ref_loss = -0.8645, perp_loss = 10.2201, entropy=52.0993, time=0.91
Iteration 21: loss = 10.0885, adv_loss = 0.7183, ref_loss = -0.6858, perp_loss = 10.0561, entropy=147.7752, time=1.73
Iteration 31: loss = 9.4754, adv_loss = 0.0934, ref_loss = -0.5807, perp_loss = 9.9627, entropy=177.2979, time=2.56
Iteration 41: loss = 8.9323, adv_loss = 0.1083, ref_loss = -0.6121, perp_loss = 9.4362, entropy=178.0971, time=3.38
Iteration 51: loss = 8.3361, adv_loss = 0.0304, ref_loss = -0.6008, perp_loss = 8.9065, entropy=175.0028, time=4.20
Iteration 61: loss = 7.8449, adv_loss = 0.0159, ref_loss = -0.5819, perp_loss = 8.4109, entropy=143.5364, time=5.02
Iteration 71: loss = 7.3933, adv_loss = 0.0285, ref_loss = -0.5832, perp_loss = 7.9479, entropy=92.4855, time=5.85
Iteration 81: loss = 6.9747, adv_loss = 0.0000, ref_loss = -0.5738, perp_loss = 7.5485, entropy=52.5998, time=6.67
Iteration 91: loss = 6.6961, adv_loss = 0.0206, ref_loss = -0.5705, perp_loss = 7.2461, entropy=26.0930, time=7.49
CLEAN TEXT
China's inflation rate slows sharply but problems remain ( AFP ) AFP - China's inflation rate eased sharply in October as government efforts to cool the economy began to really bite, with food prices, one of the main culprits, showing some signs of slowing, official data showed.
ADVERSARIAL TEXT
China termscorn notputputputhold Canalyrpar consider regardsvir Mainmostviring China Das Wet surplusput retailholdadesbayseeyerier goal believewhere economy accepting not planszerirkparierwhereyrent ofgardparyrparopyputyrpareryr ofadesed of waking prouder

CLEAN LOGITS
tensor([[ 2.8601, -4.1165,  3.2645, -1.9986]])
ADVERSARIAL LOGITS
tensor([[-0.5901, -4.6511,  5.1994, -0.6323]])
LABEL
3
TEXT
[CLS] Nonnative Goats Bunking at Yellowstone ( AP ) AP - A new study shows mountain goats are taking hold in Yellowstone National Park, but park officials aren't sure how to handle the presence of the nonnative animals. [SEP]
LOGITS
tensor([[-1.7101, -3.1500, -1.1509,  5.6997]])
Iteration 1: loss = 21.9974, adv_loss = 11.8398, ref_loss = -0.9973, perp_loss = 11.1549, entropy=7.3168, time=0.07
Iteration 11: loss = 20.9654, adv_loss = 11.4977, ref_loss = -0.9404, perp_loss = 10.4082, entropy=131.8112, time=0.81
Iteration 21: loss = 19.4340, adv_loss = 10.3456, ref_loss = -0.8791, perp_loss = 9.9676, entropy=281.2764, time=1.54
Iteration 31: loss = 18.1614, adv_loss = 9.3909, ref_loss = -0.8642, perp_loss = 9.6346, entropy=293.6855, time=2.27
Iteration 41: loss = 10.7672, adv_loss = 0.0607, ref_loss = -0.0530, perp_loss = 10.7595, entropy=267.1940, time=3.01
Iteration 51: loss = 9.8863, adv_loss = 0.0229, ref_loss = -0.2716, perp_loss = 10.1350, entropy=231.4175, time=3.73
Iteration 61: loss = 9.1956, adv_loss = 0.1587, ref_loss = -0.4266, perp_loss = 9.4635, entropy=174.8157, time=4.46
Iteration 71: loss = 8.8170, adv_loss = 0.3856, ref_loss = -0.4815, perp_loss = 8.9129, entropy=123.2622, time=5.19
Iteration 81: loss = 8.2111, adv_loss = 0.1025, ref_loss = -0.5181, perp_loss = 8.6266, entropy=93.1888, time=5.92
Iteration 91: loss = 7.8104, adv_loss = 0.0286, ref_loss = -0.6447, perp_loss = 8.4265, entropy=62.7591, time=6.65
CLEAN TEXT
Nonnative Goats Bunking at Yellowstone ( AP ) AP - A new study shows mountain goats are taking hold in Yellowstone National Park, but park officials aren't sure how to handle the presence of the nonnative animals.
ADVERSARIAL TEXT
##olisvirputierfic shareholder Planningeva enjoyingyerlumberpton gross ) AP - rang gearsdier Continuing earning counting Winningizaweight willingnessmerwright sewage grossed Bros absorbing investing negotiatingstickvir continuingyrizabic Worshipeleyizaizaformervic rearizaputfeld

CLEAN LOGITS
tensor([[-1.7101, -3.1500, -1.1509,  5.6997]])
ADVERSARIAL LOGITS
tensor([[-0.7587, -4.0884,  5.3258, -1.4915]])
LABEL
1
TEXT
[CLS] Real eager to silence doubting supporters NO SPECTATORS will be watching in the ground, but the eyes of Europe will be trained on Romes Olympic Stadium tonight as Real Madrid seek the win they probably need to avoid a humiliating, early exit from the Champions League. [SEP]
LOGITS
tensor([[-1.5513,  7.6355, -2.7536, -2.1680]])
Iteration 1: loss = 24.3621, adv_loss = 14.2972, ref_loss = -0.9971, perp_loss = 11.0620, entropy=8.3017, time=0.08
Iteration 11: loss = 23.8156, adv_loss = 14.1654, ref_loss = -0.9705, perp_loss = 10.6207, entropy=53.0603, time=0.88
Iteration 21: loss = 19.5425, adv_loss = 9.8327, ref_loss = -0.8039, perp_loss = 10.5137, entropy=151.2243, time=1.68
Iteration 31: loss = 10.9231, adv_loss = 0.0000, ref_loss = -0.1679, perp_loss = 11.0909, entropy=247.9557, time=2.48
Iteration 41: loss = 10.1139, adv_loss = 0.1801, ref_loss = -0.5760, perp_loss = 10.5098, entropy=265.2493, time=3.28
Iteration 51: loss = 9.4157, adv_loss = 0.0000, ref_loss = -0.6343, perp_loss = 10.0500, entropy=220.1953, time=4.07
Iteration 61: loss = 8.7141, adv_loss = 0.0000, ref_loss = -0.7129, perp_loss = 9.4270, entropy=151.1299, time=4.87
Iteration 71: loss = 8.1747, adv_loss = 0.0000, ref_loss = -0.7342, perp_loss = 8.9089, entropy=104.8008, time=5.67
Iteration 81: loss = 7.8440, adv_loss = 0.0000, ref_loss = -0.7562, perp_loss = 8.6002, entropy=74.9302, time=6.47
Iteration 91: loss = 7.6276, adv_loss = 0.0000, ref_loss = -0.7431, perp_loss = 8.3708, entropy=63.6746, time=7.27
CLEAN TEXT
Real eager to silence doubting supporters NO SPECTATORS will be watching in the ground, but the eyes of Europe will be trained on Romes Olympic Stadium tonight as Real Madrid seek the win they probably need to avoid a humiliating, early exit from the Champions League.
ADVERSARIAL TEXT
em XIII outstretched Heidelberg knot shakentony malariansoEChora Paulineicides Cobra Lankan outstretched nose grams Katrina immunity Piusrene Hawke Hussein TNA grams swollen Downnst aluminium punch volleyball suitesạ as Real Paulourous the America theyescu miss Gracie I nose evangelicalcinibula Eton Nobel Apostolic Gracie Maud Witness Benedictße

CLEAN LOGITS
tensor([[-1.5513,  7.6355, -2.7536, -2.1680]])
ADVERSARIAL LOGITS
tensor([[ 4.7407,  1.6553, -3.0114, -1.7470]])
LABEL
3
TEXT
[CLS] Blackberry shrinks phone keyboard The latest Blackberry mobile device packs a traditional Qwerty keyboard into 20 keys. [SEP]
LOGITS
tensor([[-1.6556, -3.8302, -0.0908,  4.7755]])
Iteration 1: loss = 19.9607, adv_loss = 9.9634, ref_loss = -0.9970, perp_loss = 10.9944, entropy=3.5177, time=0.05
Iteration 11: loss = 19.2568, adv_loss = 9.7189, ref_loss = -0.9745, perp_loss = 10.5125, entropy=29.6628, time=0.56
Iteration 21: loss = 18.3244, adv_loss = 8.9692, ref_loss = -0.9180, perp_loss = 10.2732, entropy=67.8150, time=1.07
Iteration 31: loss = 11.6232, adv_loss = 1.5666, ref_loss = -0.5368, perp_loss = 10.5935, entropy=85.4436, time=1.58
Iteration 41: loss = 10.0893, adv_loss = 0.0046, ref_loss = -0.3841, perp_loss = 10.4688, entropy=94.0341, time=2.09
Iteration 51: loss = 9.6583, adv_loss = 0.2872, ref_loss = -0.4705, perp_loss = 9.8417, entropy=88.7514, time=2.60
Iteration 61: loss = 9.0362, adv_loss = 0.0000, ref_loss = -0.3832, perp_loss = 9.4194, entropy=72.6890, time=3.11
Iteration 71: loss = 8.5336, adv_loss = 0.0752, ref_loss = -0.5093, perp_loss = 8.9677, entropy=48.1745, time=3.61
Iteration 81: loss = 8.2811, adv_loss = 0.0000, ref_loss = -0.4789, perp_loss = 8.7600, entropy=35.6540, time=4.12
Iteration 91: loss = 8.2003, adv_loss = 0.0000, ref_loss = -0.4344, perp_loss = 8.6348, entropy=27.6375, time=4.63
CLEAN TEXT
Blackberry shrinks phone keyboard The latest Blackberry mobile device packs a traditional Qwerty keyboard into 20 keys.
ADVERSARIAL TEXT
##holding Goodmanlov whose chicken keyboardper today Suburbanbay mobile shop dealingirk todayrup cerealcornroadsgman gross Labor summary

CLEAN LOGITS
tensor([[-1.6556, -3.8302, -0.0908,  4.7755]])
ADVERSARIAL LOGITS
tensor([[-2.1425, -4.2809,  4.3683,  1.4901]])
LABEL
1
TEXT
[CLS] Another Major Non - Factor Another major, another disappointment for Tiger Woods, the No. 1 ranked player in the world who has not won a major championship since his triumph at the 2002 U. S. Open. [SEP]
LOGITS
tensor([[-1.3311,  7.5195, -2.7607, -2.3277]])
Iteration 1: loss = 24.0474, adv_loss = 13.9689, ref_loss = -0.9943, perp_loss = 11.0728, entropy=6.1911, time=0.06
Iteration 11: loss = 23.4648, adv_loss = 13.5766, ref_loss = -0.9689, perp_loss = 10.8571, entropy=25.8035, time=0.70
Iteration 21: loss = 20.7265, adv_loss = 10.8712, ref_loss = -0.8458, perp_loss = 10.7010, entropy=64.4068, time=1.34
Iteration 31: loss = 11.0148, adv_loss = 0.0000, ref_loss = 0.1001, perp_loss = 10.9147, entropy=126.0984, time=1.97
Iteration 41: loss = 10.0658, adv_loss = 0.0006, ref_loss = -0.4600, perp_loss = 10.5253, entropy=137.7143, time=2.60
Iteration 51: loss = 9.5866, adv_loss = 0.0455, ref_loss = -0.6085, perp_loss = 10.1496, entropy=131.1004, time=3.24
Iteration 61: loss = 9.0872, adv_loss = 0.0000, ref_loss = -0.5947, perp_loss = 9.6819, entropy=104.7047, time=3.87
Iteration 71: loss = 8.5548, adv_loss = 0.0000, ref_loss = -0.6748, perp_loss = 9.2296, entropy=72.6200, time=4.50
Iteration 81: loss = 8.5247, adv_loss = 0.3741, ref_loss = -0.7266, perp_loss = 8.8771, entropy=44.7501, time=5.14
Iteration 91: loss = 7.9904, adv_loss = 0.0000, ref_loss = -0.6345, perp_loss = 8.6248, entropy=32.0750, time=5.77
CLEAN TEXT
Another Major Non - Factor Another major, another disappointment for Tiger Woods, the No. 1 ranked player in the world who has not won a major championship since his triumph at the 2002 U. S. Open.
ADVERSARIAL TEXT
Walker Maiden dollrer pension Another toy tag another Copper flick Won doll messenger Bold minously medleyfrey scene in Penelope doll harness has Trying won cumulative winupe since saving punching at Angelina 2002 U! S Whilst Open beg

CLEAN LOGITS
tensor([[-1.3311,  7.5195, -2.7607, -2.3277]])
ADVERSARIAL LOGITS
tensor([[-3.1868, -0.8476, -0.4712,  4.3390]])
LABEL
0
TEXT
[CLS] Car Bomb Kills Three in Mosul ( AP ) AP - A car bomb exploded in the northern Iraq city of Mosul on Monday, killing three people, hospital police said. [SEP]
LOGITS
tensor([[ 7.1547, -2.2557, -1.9395, -1.5826]])
Iteration 1: loss = 24.3282, adv_loss = 13.7071, ref_loss = -0.9998, perp_loss = 11.6208, entropy=5.3469, time=0.06
Iteration 11: loss = 22.3402, adv_loss = 12.5064, ref_loss = -0.9575, perp_loss = 10.7913, entropy=106.4894, time=0.66
Iteration 21: loss = 11.3333, adv_loss = 0.0000, ref_loss = 0.2276, perp_loss = 11.1057, entropy=208.8462, time=1.26
Iteration 31: loss = 10.8464, adv_loss = 0.0000, ref_loss = 0.2076, perp_loss = 10.6388, entropy=229.5277, time=1.85
Iteration 41: loss = 9.9546, adv_loss = 0.0000, ref_loss = 0.1336, perp_loss = 9.8210, entropy=204.9225, time=2.45
Iteration 51: loss = 9.0401, adv_loss = 0.0000, ref_loss = -0.0423, perp_loss = 9.0824, entropy=153.2239, time=3.04
Iteration 61: loss = 8.2115, adv_loss = 0.0000, ref_loss = -0.4470, perp_loss = 8.6585, entropy=100.7160, time=3.64
Iteration 71: loss = 7.5546, adv_loss = 0.0000, ref_loss = -0.6154, perp_loss = 8.1700, entropy=61.6052, time=4.23
Iteration 81: loss = 7.0598, adv_loss = 0.0000, ref_loss = -0.6782, perp_loss = 7.7380, entropy=35.5078, time=4.83
Iteration 91: loss = 6.7860, adv_loss = 0.0000, ref_loss = -0.6840, perp_loss = 7.4700, entropy=22.9182, time=5.42
CLEAN TEXT
Car Bomb Kills Three in Mosul ( AP ) AP - A car bomb exploded in the northern Iraq city of Mosul on Monday, killing three people, hospital police said.
ADVERSARIAL TEXT
ok vertices vertices alloy ″sional < Flint vertex swap swap Flintliptic contact httpliptic alloylipticicidal Oswald Cunninghammented 」 detentionicidal Darrell Darrell Flint ₚ Wolfgang Daphne ¶ cardiac epithetkkerlante

CLEAN LOGITS
tensor([[ 7.1547, -2.2557, -1.9395, -1.5826]])
ADVERSARIAL LOGITS
tensor([[-1.1763, -3.1628, -1.3594,  5.3867]])
LABEL
0
TEXT
[CLS] Kerry assails Bush troop withdrawal plan ( AFP ) AFP - Democratic White House hopeful Senator John Kerry warned that President George W. Bush's plan to withdraw 70, 000 troops from Europe and Asia would hinder the war on terrorism and embolden North Korea. [SEP]
LOGITS
tensor([[ 7.0491, -2.7403, -1.6500, -1.4938]])
Iteration 1: loss = 24.0278, adv_loss = 13.5393, ref_loss = -0.9980, perp_loss = 11.4865, entropy=8.0203, time=0.07
Iteration 11: loss = 22.3854, adv_loss = 12.6521, ref_loss = -0.9499, perp_loss = 10.6832, entropy=147.6078, time=0.84
Iteration 21: loss = 11.2691, adv_loss = 0.0000, ref_loss = 0.1531, perp_loss = 11.1160, entropy=304.8757, time=1.60
Iteration 31: loss = 10.6185, adv_loss = 0.0000, ref_loss = -0.0557, perp_loss = 10.6742, entropy=311.7726, time=2.36
Iteration 41: loss = 9.6355, adv_loss = 0.0000, ref_loss = -0.4210, perp_loss = 10.0565, entropy=277.0940, time=3.12
Iteration 51: loss = 8.7387, adv_loss = 0.0000, ref_loss = -0.6598, perp_loss = 9.3985, entropy=218.3616, time=3.88
Iteration 61: loss = 7.8564, adv_loss = 0.0000, ref_loss = -0.7754, perp_loss = 8.6318, entropy=136.8731, time=4.64
Iteration 71: loss = 7.2115, adv_loss = 0.0000, ref_loss = -0.7827, perp_loss = 7.9942, entropy=68.8790, time=5.40
Iteration 81: loss = 6.8027, adv_loss = 0.0000, ref_loss = -0.8132, perp_loss = 7.6159, entropy=39.5409, time=6.16
Iteration 91: loss = 6.6311, adv_loss = 0.0000, ref_loss = -0.8174, perp_loss = 7.4485, entropy=27.4995, time=6.92
CLEAN TEXT
Kerry assails Bush troop withdrawal plan ( AFP ) AFP - Democratic White House hopeful Senator John Kerry warned that President George W. Bush's plan to withdraw 70, 000 troops from Europe and Asia would hinder the war on terrorism and embolden North Korea.
ADVERSARIAL TEXT
″sionalsionalloadingrang intersection pen hood FlintFP Flintsional Flint contact ″sionalsionalaper vain vain ″ Garry Chow collects Vincenzo XVI. Kerry 'ك Jai Achilles hoodmented narration ″ compartment Flintsional contactync contactffington Metacritic vainël Yong vain contactgable Oswalddier pen www vain

CLEAN LOGITS
tensor([[ 7.0491, -2.7403, -1.6500, -1.4938]])
ADVERSARIAL LOGITS
tensor([[-1.8301, -3.4243, -0.5723,  5.4309]])
LABEL
1
TEXT
[CLS] Group E : Arsenal mystery continues Arsenal wasted a golden opportunity to virtually guarantee themselves a place in the knockout phase of the Champions League when they were held to a 1 - 1 draw by Panathinaikos at Highbury on Tuesday. [SEP]
LOGITS
tensor([[-1.3245,  7.6943, -2.9174, -2.2411]])
Iteration 1: loss = 23.9008, adv_loss = 14.0514, ref_loss = -0.9983, perp_loss = 10.8478, entropy=6.7540, time=0.07
Iteration 11: loss = 23.3613, adv_loss = 13.7814, ref_loss = -0.9672, perp_loss = 10.5470, entropy=33.0802, time=0.78
Iteration 21: loss = 22.7274, adv_loss = 13.4079, ref_loss = -0.9315, perp_loss = 10.2510, entropy=84.0696, time=1.48
Iteration 31: loss = 10.5947, adv_loss = 0.0790, ref_loss = -0.2810, perp_loss = 10.7967, entropy=135.1474, time=2.19
Iteration 41: loss = 10.6141, adv_loss = 0.0000, ref_loss = -0.1816, perp_loss = 10.7957, entropy=173.5834, time=2.89
Iteration 51: loss = 9.7551, adv_loss = 0.3498, ref_loss = -0.6284, perp_loss = 10.0337, entropy=165.1637, time=3.59
Iteration 61: loss = 8.8759, adv_loss = 0.0000, ref_loss = -0.5761, perp_loss = 9.4520, entropy=142.3920, time=4.29
Iteration 71: loss = 8.2905, adv_loss = 0.0000, ref_loss = -0.6252, perp_loss = 8.9158, entropy=101.9150, time=4.99
Iteration 81: loss = 7.8903, adv_loss = 0.0000, ref_loss = -0.6868, perp_loss = 8.5771, entropy=69.6330, time=5.69
Iteration 91: loss = 7.7734, adv_loss = 0.0000, ref_loss = -0.6117, perp_loss = 8.3850, entropy=53.6832, time=6.39
CLEAN TEXT
Group E : Arsenal mystery continues Arsenal wasted a golden opportunity to virtually guarantee themselves a place in the knockout phase of the Champions League when they were held to a 1 - 1 draw by Panathinaikos at Highbury on Tuesday.
ADVERSARIAL TEXT
Obama Wilde Gracie Gracie Gracie Apostolic Martial Percywine Hussein nose Maud Gracie Gracie themselves slappeduti Nobel Hussain XII bearer Cyprus ♠ Reginald Stone crumpledtony Gracie Graciegio Plata 1gging 1 Miracle by Greek Gracienza Love sore Scholars Marilynanne Love.

CLEAN LOGITS
tensor([[-1.3245,  7.6943, -2.9174, -2.2411]])
ADVERSARIAL LOGITS
tensor([[ 6.1783, -0.4265, -2.3749, -1.6979]])
LABEL
0
TEXT
[CLS] Turkey confirms death of engineer in Afghanistan ANKARA, Dec 15 ( AFP ) - The Turkish ambassador in Afghanistan has confirmed the death of a Turkish engineer kidnapped Tuesday in Afghanistan # 39 ; s eastern Kunar province, the Anatolia news agency reported Wednesday. [SEP]
LOGITS
tensor([[ 6.9799, -1.6960, -1.6002, -2.1281]])
Iteration 1: loss = 23.8158, adv_loss = 13.6124, ref_loss = -0.9994, perp_loss = 11.2028, entropy=7.4575, time=0.07
Iteration 11: loss = 23.0937, adv_loss = 13.3914, ref_loss = -0.9854, perp_loss = 10.6877, entropy=74.3653, time=0.81
Iteration 21: loss = 10.9921, adv_loss = 0.0000, ref_loss = -0.0009, perp_loss = 10.9930, entropy=208.5840, time=1.55
Iteration 31: loss = 10.4174, adv_loss = 0.0000, ref_loss = -0.3208, perp_loss = 10.7382, entropy=256.9579, time=2.28
Iteration 41: loss = 9.4991, adv_loss = 0.0000, ref_loss = -0.7168, perp_loss = 10.2159, entropy=249.0957, time=3.02
Iteration 51: loss = 9.0091, adv_loss = 0.1403, ref_loss = -0.7830, perp_loss = 9.6518, entropy=199.3448, time=3.75
Iteration 61: loss = 8.4134, adv_loss = 0.0000, ref_loss = -0.7611, perp_loss = 9.1745, entropy=151.9348, time=4.48
Iteration 71: loss = 8.0231, adv_loss = 0.0000, ref_loss = -0.7736, perp_loss = 8.7967, entropy=105.6386, time=5.22
Iteration 81: loss = 7.7144, adv_loss = 0.1522, ref_loss = -0.8175, perp_loss = 8.3797, entropy=69.5384, time=5.95
Iteration 91: loss = 7.3110, adv_loss = 0.0000, ref_loss = -0.8184, perp_loss = 8.1294, entropy=46.7721, time=6.68
CLEAN TEXT
Turkey confirms death of engineer in Afghanistan ANKARA, Dec 15 ( AFP ) - The Turkish ambassador in Afghanistan has confirmed the death of a Turkish engineer kidnapped Tuesday in Afghanistan # 39 ; s eastern Kunar province, the Anatolia news agency reported Wednesday.
ADVERSARIAL TEXT
##onic confirms dies EverKO in Afghanistan imaginary Gracie CurtisFAFAFAFA number Curtis Brookephy Graciempomma Pradeshriad smellingilde Curtis flu remaining dear Time singleose Gracieгtitis sanctionsntin Hooker s Curtis Olivia grace quality recall Gracie exclusive exclusive stretchFA Angelica.

CLEAN LOGITS
tensor([[ 6.9799, -1.6960, -1.6002, -2.1281]])
ADVERSARIAL LOGITS
tensor([[-0.7781,  7.2841, -2.6969, -2.6598]])
LABEL
0
TEXT
[CLS] How Deadly Are Scorpions? A Malaysian woman has broken the world record for time spent living in a scorpion - filled box. Nur Malena Hassan, 27, has so far endured 32 days in a glass case with 6, 069 scorpions ; she [SEP]
LOGITS
tensor([[ 5.0522, -1.6217, -2.5423,  0.8789]])
Iteration 1: loss = 20.0889, adv_loss = 9.6129, ref_loss = -0.9944, perp_loss = 11.4704, entropy=8.5832, time=0.08
Iteration 11: loss = 10.4622, adv_loss = 0.0000, ref_loss = -0.4937, perp_loss = 10.9559, entropy=94.1308, time=0.89
Iteration 21: loss = 10.2265, adv_loss = 0.0000, ref_loss = -0.4680, perp_loss = 10.6945, entropy=193.7569, time=1.69
Iteration 31: loss = 9.7155, adv_loss = 0.0000, ref_loss = -0.5454, perp_loss = 10.2609, entropy=231.2263, time=2.50
Iteration 41: loss = 9.1151, adv_loss = 0.0000, ref_loss = -0.4967, perp_loss = 9.6118, entropy=244.1659, time=3.30
Iteration 51: loss = 8.4094, adv_loss = 0.0000, ref_loss = -0.4889, perp_loss = 8.8983, entropy=210.6737, time=4.11
Iteration 61: loss = 7.6828, adv_loss = 0.0000, ref_loss = -0.5309, perp_loss = 8.2138, entropy=137.4299, time=4.91
Iteration 71: loss = 6.9446, adv_loss = 0.0000, ref_loss = -0.5797, perp_loss = 7.5244, entropy=67.9109, time=5.72
Iteration 81: loss = 6.6079, adv_loss = 0.0000, ref_loss = -0.4983, perp_loss = 7.1062, entropy=35.9786, time=6.52
Iteration 91: loss = 6.3405, adv_loss = 0.0000, ref_loss = -0.5847, perp_loss = 6.9252, entropy=21.8856, time=7.33
CLEAN TEXT
How Deadly Are Scorpions? A Malaysian woman has broken the world record for time spent living in a scorpion - filled box. Nur Malena Hassan, 27, has so far endured 32 days in a glass case with 6, 069 scorpions ; she
ADVERSARIAL TEXT
wwwël Nominatedyuki www wwwsional www comic inventorpetëlpet inventor ok www Flint compensate Flint okëlweightpet chorus ok www comic ok www comic Jamesurer Raja Linnaeus Hassan XVI ok comic comicurerhoeëlhoe scorerpetël ok Metacritic scorer comic concurrentlyweight ok scorer Drama Hoodmers Cicero www

CLEAN LOGITS
tensor([[ 5.0522, -1.6217, -2.5423,  0.8789]])
ADVERSARIAL LOGITS
tensor([[-2.9282, -2.2124, -0.6776,  5.3132]])
LABEL
2
TEXT
[CLS] LVMH Plans to Buy Glenmorangie French luxury goods company LVMH Moet Hennessy Louis said Wednesday it plans to buy whisky maker Glenmorangie PLC for about 300 million pounds ( euro430. [SEP]
LOGITS
tensor([[ 0.1952, -3.6743,  4.9570, -2.6028]])
Iteration 1: loss = 19.5809, adv_loss = 9.8281, ref_loss = -0.9973, perp_loss = 10.7500, entropy=7.3168, time=0.07
Iteration 11: loss = 18.9534, adv_loss = 9.6323, ref_loss = -0.9779, perp_loss = 10.2991, entropy=46.1191, time=0.80
Iteration 21: loss = 11.0542, adv_loss = 0.0676, ref_loss = -0.3285, perp_loss = 11.3152, entropy=146.3230, time=1.54
Iteration 31: loss = 10.7922, adv_loss = 0.0000, ref_loss = -0.2820, perp_loss = 11.0742, entropy=193.6327, time=2.26
Iteration 41: loss = 10.0004, adv_loss = 0.0378, ref_loss = -0.4966, perp_loss = 10.4592, entropy=195.6344, time=2.99
Iteration 51: loss = 9.3063, adv_loss = 0.0284, ref_loss = -0.5219, perp_loss = 9.7998, entropy=176.4941, time=3.72
Iteration 61: loss = 8.4754, adv_loss = 0.0840, ref_loss = -0.6008, perp_loss = 8.9922, entropy=134.6245, time=4.45
Iteration 71: loss = 7.7925, adv_loss = 0.0000, ref_loss = -0.5137, perp_loss = 8.3062, entropy=87.3859, time=5.18
Iteration 81: loss = 7.2589, adv_loss = 0.0000, ref_loss = -0.5712, perp_loss = 7.8301, entropy=57.9394, time=5.90
Iteration 91: loss = 6.9875, adv_loss = 0.0000, ref_loss = -0.6136, perp_loss = 7.6011, entropy=41.0844, time=6.63
CLEAN TEXT
LVMH Plans to Buy Glenmorangie French luxury goods company LVMH Moet Hennessy Louis said Wednesday it plans to buy whisky maker Glenmorangie PLC for about 300 million pounds ( euro430.
ADVERSARIAL TEXT
ʻwamick lifelong Titopher Lalwamicenscker sniffed Malaysian Cooper saturated company HagueddenristoΚ ʻfflesΚwami KualaΚnged Islamic Khmer saturatedlasticphereggs behavioral mud LahoreCU Colombo Albuquerque Kuala Titockgro Albuquerqueße mud considers Sinongedcis Indo

CLEAN LOGITS
tensor([[ 0.1952, -3.6743,  4.9570, -2.6028]])
ADVERSARIAL LOGITS
tensor([[ 5.0579, -2.7606,  0.9268, -1.9713]])
LABEL
1
TEXT
[CLS] Notebook : USC, Sooners in control of BCS USC vs. Oklahoma in the Orange Bowl appears to be three victories away - two by USC and one by the Sooners. USC and Oklahoma held the top two spots in the Bowl Championship [SEP]
LOGITS
tensor([[-0.7363,  7.7375, -2.9788, -2.7634]])
Iteration 1: loss = 23.2321, adv_loss = 13.5716, ref_loss = -0.9985, perp_loss = 10.6590, entropy=7.1761, time=0.07
Iteration 11: loss = 22.8360, adv_loss = 13.4772, ref_loss = -0.9894, perp_loss = 10.3482, entropy=30.1346, time=0.80
Iteration 21: loss = 22.0558, adv_loss = 12.9008, ref_loss = -0.9579, perp_loss = 10.1130, entropy=81.6060, time=1.53
Iteration 31: loss = 18.7987, adv_loss = 9.5867, ref_loss = -0.9008, perp_loss = 10.1128, entropy=114.0251, time=2.26
Iteration 41: loss = 11.6458, adv_loss = 1.9754, ref_loss = -0.7522, perp_loss = 10.4226, entropy=161.2130, time=2.99
Iteration 51: loss = 9.7157, adv_loss = 0.0000, ref_loss = -0.7125, perp_loss = 10.4282, entropy=181.4669, time=3.71
Iteration 61: loss = 9.2529, adv_loss = 0.1488, ref_loss = -0.7903, perp_loss = 9.8944, entropy=167.6973, time=4.43
Iteration 71: loss = 9.0789, adv_loss = 0.2687, ref_loss = -0.7531, perp_loss = 9.5632, entropy=133.3228, time=5.16
Iteration 81: loss = 8.4553, adv_loss = 0.0000, ref_loss = -0.7653, perp_loss = 9.2206, entropy=97.3199, time=5.88
Iteration 91: loss = 8.5094, adv_loss = 0.2453, ref_loss = -0.6996, perp_loss = 8.9637, entropy=67.4374, time=6.60
CLEAN TEXT
Notebook : USC, Sooners in control of BCS USC vs. Oklahoma in the Orange Bowl appears to be three victories away - two by USC and one by the Sooners. USC and Oklahoma held the top two spots in the Bowl Championship
ADVERSARIAL TEXT
Elvis McGuire slips Manila Bahadur punchestion Trio Una Percy 10ScumDS. cents Tripletchesná Bowl Notes Bruins surrender Giants punch punch fornik Single punch Ever onenik sore Doubleckspina Una triple slips passport miss best punch Double unofficialates p Mayo

CLEAN LOGITS
tensor([[-0.7363,  7.7375, -2.9788, -2.7634]])
ADVERSARIAL LOGITS
tensor([[ 5.4764,  0.1425, -2.5128, -1.6048]])
LABEL
2
TEXT
[CLS] Starbucks CEO to Retire, Shares Fall Starbucks Corp. ( SBUX. O : Quote, Profile, Research ) on Tuesday said its chief executive, Orin Smith, will retire next year, surprising investors, who sent the coffee shop chain # 39 ; s shares lower in after - hours trading. [SEP]
LOGITS
tensor([[-0.6546, -3.6352,  5.4300, -2.3998]])
Iteration 1: loss = 20.7974, adv_loss = 11.0833, ref_loss = -0.9993, perp_loss = 10.7134, entropy=10.2716, time=0.09
Iteration 11: loss = 20.1115, adv_loss = 10.7183, ref_loss = -0.9882, perp_loss = 10.3814, entropy=90.5227, time=1.00
Iteration 21: loss = 11.2308, adv_loss = 0.0455, ref_loss = -0.1234, perp_loss = 11.3087, entropy=247.5420, time=1.91
Iteration 31: loss = 11.1626, adv_loss = 0.0000, ref_loss = 0.1278, perp_loss = 11.0348, entropy=333.3513, time=2.82
Iteration 41: loss = 10.3159, adv_loss = 0.0000, ref_loss = 0.0927, perp_loss = 10.2233, entropy=331.3088, time=3.72
Iteration 51: loss = 9.2823, adv_loss = 0.0000, ref_loss = -0.0920, perp_loss = 9.3744, entropy=256.3123, time=4.62
Iteration 61: loss = 8.4693, adv_loss = 0.1290, ref_loss = -0.3443, perp_loss = 8.6846, entropy=195.2878, time=5.53
Iteration 71: loss = 7.9164, adv_loss = 0.0000, ref_loss = -0.3479, perp_loss = 8.2643, entropy=135.2596, time=6.43
Iteration 81: loss = 7.3943, adv_loss = 0.0000, ref_loss = -0.4560, perp_loss = 7.8503, entropy=88.7817, time=7.33
Iteration 91: loss = 6.9934, adv_loss = 0.0000, ref_loss = -0.5661, perp_loss = 7.5595, entropy=61.2699, time=8.24
CLEAN TEXT
Starbucks CEO to Retire, Shares Fall Starbucks Corp. ( SBUX. O : Quote, Profile, Research ) on Tuesday said its chief executive, Orin Smith, will retire next year, surprising investors, who sent the coffee shop chain # 39 ; s shares lower in after - hours trading.
ADVERSARIAL TEXT
Thai̯ Kuala Hague toddenmberpherpherkelwamidden UAE NGO Down Hague HaguentopherscentġCUfflespherả mud Cheryl Kuala Hagueggspressivepher Lankankles renovated Hague Fathers Hagueġdden mud TitoХCUapawami KualaХ Dhakafers abusiveurerselo inheritedХ Casa shoes Co textile Internationale Internationale≡ Kuala Bayern Bayernße slipperyΚ Saudi Haguepher

CLEAN LOGITS
tensor([[-0.6546, -3.6352,  5.4300, -2.3998]])
ADVERSARIAL LOGITS
tensor([[ 5.4469, -2.4777, -0.2065, -1.4428]])
LABEL
2
TEXT
[CLS] Stocks Open Lower as Wall St. Pulls Back US stocks opened slightly lower on Monday as investors pause after a three - day rally last week, with interest rates and a weakening dollar gaining focus now that the presidential election is over. [SEP]
LOGITS
tensor([[-0.2421, -4.0863,  5.4091, -2.2344]])
Iteration 1: loss = 20.5142, adv_loss = 10.8546, ref_loss = -0.9909, perp_loss = 10.6506, entropy=7.0354, time=0.07
Iteration 11: loss = 19.4185, adv_loss = 10.0346, ref_loss = -0.9703, perp_loss = 10.3542, entropy=39.5026, time=0.79
Iteration 21: loss = 11.1268, adv_loss = 0.3550, ref_loss = -0.2030, perp_loss = 10.9748, entropy=120.2552, time=1.51
Iteration 31: loss = 10.5434, adv_loss = 0.0290, ref_loss = -0.2711, perp_loss = 10.7854, entropy=153.4021, time=2.23
Iteration 41: loss = 9.8537, adv_loss = 0.0015, ref_loss = -0.4957, perp_loss = 10.3479, entropy=152.1365, time=2.95
Iteration 51: loss = 9.4024, adv_loss = 0.0918, ref_loss = -0.6783, perp_loss = 9.9889, entropy=139.3629, time=3.66
Iteration 61: loss = 9.0903, adv_loss = 0.2534, ref_loss = -0.7214, perp_loss = 9.5583, entropy=121.4735, time=4.38
Iteration 71: loss = 8.4732, adv_loss = 0.0948, ref_loss = -0.7663, perp_loss = 9.1447, entropy=94.1728, time=5.10
Iteration 81: loss = 8.3674, adv_loss = 0.0000, ref_loss = -0.7328, perp_loss = 9.1002, entropy=71.2759, time=5.82
Iteration 91: loss = 8.0549, adv_loss = 0.0000, ref_loss = -0.7510, perp_loss = 8.8058, entropy=55.8625, time=6.53
CLEAN TEXT
Stocks Open Lower as Wall St. Pulls Back US stocks opened slightly lower on Monday as investors pause after a three - day rally last week, with interest rates and a weakening dollar gaining focus now that the presidential election is over.
ADVERSARIAL TEXT
engravedscame Marilyn triple broken unfinishedune broken touchess opens Bermuda surname outstretched palmvez onsmog exact 1823 after das proud 20th dream tea last nineteenth, with America oil and LDSEC ratings green inflation now changedcame presidential reformscame close.

CLEAN LOGITS
tensor([[-0.2421, -4.0863,  5.4091, -2.2344]])
ADVERSARIAL LOGITS
tensor([[ 4.9689, -0.8305, -0.9642, -2.0699]])
LABEL
0
TEXT
[CLS] Coal Mine Blast in China Kills 33 ( AP ) AP - A coal mine explosion in northern China killed 33 people in the latest disaster to strike the country's accident - prone mining industry, the official Xinhua News Agency reported Friday. [SEP]
LOGITS
tensor([[ 6.8160, -2.5687, -1.8567, -1.0836]])
Iteration 1: loss = 23.7188, adv_loss = 12.9587, ref_loss = -0.9989, perp_loss = 11.7590, entropy=7.3168, time=0.07
Iteration 11: loss = 13.1420, adv_loss = 2.1298, ref_loss = -0.4482, perp_loss = 11.4603, entropy=102.2217, time=0.80
Iteration 21: loss = 11.1566, adv_loss = 0.0000, ref_loss = 0.1582, perp_loss = 10.9985, entropy=247.7013, time=1.53
Iteration 31: loss = 10.4273, adv_loss = 0.0000, ref_loss = 0.1688, perp_loss = 10.2585, entropy=293.9751, time=2.26
Iteration 41: loss = 9.5114, adv_loss = 0.0000, ref_loss = 0.1175, perp_loss = 9.3939, entropy=271.9165, time=2.98
Iteration 51: loss = 8.6903, adv_loss = 0.0000, ref_loss = 0.0897, perp_loss = 8.6005, entropy=210.8489, time=3.71
Iteration 61: loss = 7.9884, adv_loss = 0.0000, ref_loss = 0.0758, perp_loss = 7.9126, entropy=123.1166, time=4.44
Iteration 71: loss = 7.3980, adv_loss = 0.0000, ref_loss = 0.0431, perp_loss = 7.3550, entropy=59.9018, time=5.16
Iteration 81: loss = 7.1674, adv_loss = 0.0000, ref_loss = 0.0429, perp_loss = 7.1245, entropy=27.2561, time=5.89
Iteration 91: loss = 6.9000, adv_loss = 0.0000, ref_loss = 0.0034, perp_loss = 6.8966, entropy=16.9949, time=6.61
CLEAN TEXT
Coal Mine Blast in China Kills 33 ( AP ) AP - A coal mine explosion in northern China killed 33 people in the latest disaster to strike the country's accident - prone mining industry, the official Xinhua News Agency reported Friday.
ADVERSARIAL TEXT
##sional Hood Flintliptic ″ Flint Makes Flint Flintliptic crossover Flintjer Flint Flintlet crossover Pursuitsional sediment vertex Flintël Yong Nominated Flint inventorlantelane penlante hood Need <sionalël refersionalsionalsionalsionalsional Carlsonnh convenienceyster crossoverfic Usingliptic

CLEAN LOGITS
tensor([[ 6.8160, -2.5687, -1.8567, -1.0836]])
ADVERSARIAL LOGITS
tensor([[-2.0952, -3.1729, -0.7028,  5.5279]])
LABEL
0
TEXT
[CLS]'Tensions high'in Nigeria state Anambra state in Nigeria is tense after gangs set fire to the governor's office and other buildings, local officials say. [SEP]
LOGITS
tensor([[ 6.7943, -2.7541, -1.4068, -1.5510]])
Iteration 1: loss = 23.3899, adv_loss = 13.2504, ref_loss = -0.9971, perp_loss = 11.1366, entropy=5.0655, time=0.06
Iteration 11: loss = 22.3729, adv_loss = 12.4969, ref_loss = -0.9479, perp_loss = 10.8239, entropy=30.4952, time=0.65
Iteration 21: loss = 10.8461, adv_loss = 0.0000, ref_loss = -0.2345, perp_loss = 11.0806, entropy=106.7728, time=1.23
Iteration 31: loss = 10.3694, adv_loss = 0.0462, ref_loss = -0.3536, perp_loss = 10.6768, entropy=134.0118, time=1.81
Iteration 41: loss = 9.7696, adv_loss = 0.0000, ref_loss = -0.3998, perp_loss = 10.1694, entropy=135.9175, time=2.39
Iteration 51: loss = 9.2085, adv_loss = 0.0000, ref_loss = -0.5274, perp_loss = 9.7360, entropy=121.7763, time=2.97
Iteration 61: loss = 8.7279, adv_loss = 0.0000, ref_loss = -0.5724, perp_loss = 9.3003, entropy=95.4803, time=3.56
Iteration 71: loss = 8.0264, adv_loss = 0.0000, ref_loss = -0.6423, perp_loss = 8.6687, entropy=69.3340, time=4.14
Iteration 81: loss = 7.7367, adv_loss = 0.0000, ref_loss = -0.6614, perp_loss = 8.3981, entropy=42.1301, time=4.72
Iteration 91: loss = 7.2335, adv_loss = 0.0000, ref_loss = -0.7592, perp_loss = 7.9927, entropy=25.7037, time=5.30
CLEAN TEXT
' Tensions high'in Nigeria state Anambra state in Nigeria is tense after gangs set fire to the governor's office and other buildings, local officials say.
ADVERSARIAL TEXT
< Usingweight high Wonmentsync intersection alloy cart contacturer tow contact Howurer celebrates gangs Karnataka steals toņ Obama'Meiji office ¨ other cardiacrang nominated grand finestrang

CLEAN LOGITS
tensor([[ 6.7943, -2.7541, -1.4068, -1.5510]])
ADVERSARIAL LOGITS
tensor([[-1.1803, -4.2915,  0.4886,  4.3667]])
Token Error Rate: 0.0936 (over 108 tokens)
